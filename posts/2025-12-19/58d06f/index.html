<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Tá»•ng há»£p kiáº¿n thá»©c liÃªn quan Ä‘áº¿n TrÃ¬nh mÃ£ hÃ³a vÄƒn báº£n v5- Äá»‹nh nghÄ©a mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n, cung cáº¥p nÄƒng lÆ°á»£ng cho há»‡ sinh thÃ¡i AI | AI Today - SkyAI</title>

<meta name="description" content="Tá»•ng há»£p kiáº¿n thá»©c liÃªn quan Ä‘áº¿n TrÃ¬nh mÃ£ hÃ³a vÄƒn báº£n v5, cung cáº¥p nÄƒng lÆ°á»£ng cho há»‡ sinh thÃ¡i AI">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['â¯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['â¯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">Tá»•ng há»£p kiáº¿n thá»©c liÃªn quan Ä‘áº¿n TrÃ¬nh mÃ£ hÃ³a vÄƒn báº£n v5- Äá»‹nh nghÄ©a mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n, cung cáº¥p nÄƒng lÆ°á»£ng cho há»‡ sinh thÃ¡i AI</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">Tá»•ng há»£p kiáº¿n thá»©c liÃªn quan Ä‘áº¿n TrÃ¬nh mÃ£ hÃ³a vÄƒn báº£n v5, cung cáº¥p nÄƒng lÆ°á»£ng cho há»‡ sinh thÃ¡i AI </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['â€¢'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-12-19T00:00:00&#43;00:00">December 19, 2025</time>
          </li>

          <li class="before:content-['â€¢'] before:mr-2 before:opacity-50 my-2">
            18 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="http://cdn-uploads.huggingface.co/production/uploads/688cf7e6026af0cf8ac969dd/6RiFGxMzn9Fmgml83fK8G.jpeg" alt="Tá»•ng há»£p kiáº¿n thá»©c liÃªn quan Ä‘áº¿n TrÃ¬nh mÃ£ hÃ³a vÄƒn báº£n v5- Äá»‹nh nghÄ©a mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n, cung cáº¥p nÄƒng lÆ°á»£ng cho há»‡ sinh thÃ¡i AI">
        <figcaption class="text-center italic text-xs">Tá»•ng há»£p kiáº¿n thá»©c liÃªn quan Ä‘áº¿n TrÃ¬nh mÃ£ hÃ³a vÄƒn báº£n v5, cung cáº¥p nÄƒng lÆ°á»£ng cho há»‡ sinh thÃ¡i AI</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="tokenization-in-transformers-v5-simpler-clearer-and-more-modular">Tokenization in Transformers v5: Simpler, Clearer, and More Modular</h1>
<p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<p>Transformers v5 mang Ä‘áº¿n má»™t cuá»™c cáº£i tá»• lá»›n vá» cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a tokenizers. Báº£n Ä‘á»‹nh dáº¡ng láº¡i tokenizers lá»›n nÃ y tÃ¡ch biá»‡t thiáº¿t káº¿ cá»§a tokenizer khá»i bá»™ tá»« vá»±ng Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n (tÆ°Æ¡ng tá»± nhÆ° cÃ¡ch PyTorch tÃ¡ch kiáº¿n trÃºc máº¡ng nÆ¡-ron khá»i trá»ng sá»‘ Ä‘Ã£ há»c). Káº¿t quáº£ lÃ  chÃºng ta cÃ³ cÃ¡c tokenizer mÃ  báº¡n cÃ³ thá»ƒ <!-- raw HTML omitted -->kiá»ƒm tra<!-- raw HTML omitted -->, <!-- raw HTML omitted -->tÃ¹y chá»‰nh<!-- raw HTML omitted --> vÃ  <!-- raw HTML omitted -->huáº¥n luyá»‡n<!-- raw HTML omitted --> tá»« Ä‘áº§u má»™t cÃ¡ch dá»… dÃ ng hÆ¡n nhiá»u.</p>
<blockquote>
<p><strong>TÃ³m táº¯t:</strong> BÃ i viáº¿t nÃ y giáº£i thÃ­ch cÃ¡ch tokenization hoáº¡t Ä‘á»™ng trong Transformers vÃ  táº¡i sao v5 láº¡i lÃ  má»™t báº£n thiáº¿t káº¿ láº¡i lá»›n, vá»›i ná»™i bá»™ rÃµ rÃ ng hÆ¡n, há»‡ thá»‘ng phÃ¢n cáº¥p lá»›p sáº¡ch sáº½ vÃ  má»™t backend nhanh duy nháº¥t. ÄÃ¢y lÃ  má»™t hÆ°á»›ng dáº«n thá»±c táº¿ cho báº¥t ká»³ ai muá»‘n hiá»ƒu, tÃ¹y chá»‰nh hoáº·c huáº¥n luyá»‡n cÃ¡c tokenizer dÃ nh riÃªng cho mÃ´ hÃ¬nh thay vÃ¬ coi chÃºng nhÆ° nhá»¯ng há»™p Ä‘en.</p></blockquote>
<h2 id="báº£ng-má»¥c-lá»¥c">Báº£ng Má»¥c Lá»¥c</h2>
<ul>
<li><a href="#what-is-tokenization">What is Tokenization?</a></li>
<li><a href="#the-tokenization-pipeline">The Tokenization Pipeline</a></li>
<li><a href="#tokenization-algorithms">Tokenization Algorithms</a></li>
<li><a href="#accessing-tokenizers-through-transformers">Accessing <code>tokenizers</code> through <code>transformers</code></a></li>
<li><a href="#the-tokenizer-class-hierarchy-in-transformers">The Tokenizer Class Hierarchy in <code>transformers</code></a></li>
<li><a href="#autotokenizer-automatically-selects-the-correct-tokenizer-class"><code>AutoTokenizer</code> Automatically Selects the Correct Tokenizer Class</a></li>
<li><a href="#v5-separates-tokenizer-architecture-from-trained-vocab">v5 Separates Tokenizer Architecture from Trained Vocab</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
<blockquote>
<p><strong>DÃ nh cho chuyÃªn gia:</strong> Náº¿u báº¡n Ä‘Ã£ quen thuá»™c vá»›i cÃ¡c khÃ¡i niá»‡m vÃ  muá»‘n hiá»ƒu nhá»¯ng thay Ä‘á»•i trong v5, hÃ£y chuyá»ƒn Ä‘áº¿n <a href="#v5-separates-tokenizer-architecture-from-trained-vocab">v5 Separates Tokenizer Architecture from Trained Vocab</a></p></blockquote>
<p>TrÆ°á»›c khi Ä‘i sÃ¢u vÃ o cÃ¡c thay Ä‘á»•i, hÃ£y cÃ¹ng xem láº¡i nhanh vá» tokenization lÃ m gÃ¬ vÃ  cÃ¡c bá»™ pháº­n khá»›p vá»›i nhau nhÆ° tháº¿ nÃ o.</p>
<h2 id="what-is-tokenization">What is tokenization?</h2>
<p>CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n khÃ´ng Ä‘á»c vÄƒn báº£n thÃ´. ChÃºng tiÃªu thá»¥ cÃ¡c chuá»—i sá»‘ nguyÃªn thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  <!-- raw HTML omitted -->token IDs hoáº·c input IDs<!-- raw HTML omitted -->. Tokenization lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i vÄƒn báº£n thÃ´ thÃ nh cÃ¡c token ID nÃ y. (HÃ£y thá»­ playground tokenization <a href="#">á»Ÿ Ä‘Ã¢y</a> Ä‘á»ƒ hÃ¬nh dung tokenization.)</p>
<p>Tokenization lÃ  má»™t khÃ¡i niá»‡m rá»™ng Ä‘Æ°á»£c sá»­ dá»¥ng trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  xá»­ lÃ½ vÄƒn báº£n nÃ³i chung. BÃ i viáº¿t nÃ y táº­p trung Ä‘áº·c biá»‡t vÃ o tokenization cho cÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLMs) báº±ng cÃ¡ch sá»­ dá»¥ng thÆ° viá»‡n <a href="#"><!-- raw HTML omitted -->transformers<!-- raw HTML omitted --></a> vÃ  <a href="#"><!-- raw HTML omitted -->tokenizers<!-- raw HTML omitted --></a>.</p>
<p>python
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(&ldquo;HuggingFaceTB/SmolLM3-3B&rdquo;)</p>
<p>text = &ldquo;Hello world&rdquo;
tokens = tokenizer(text)</p>
<p>print(tokens[&ldquo;input_ids&rdquo;])</p>
<h1 id="9906-1917">[9906, 1917]</h1>
<p>print(tokenizer.convert_ids_to_tokens(tokens[&ldquo;input_ids&rdquo;]))</p>
<h1 id="hello-Ä¡world">[&lsquo;Hello&rsquo;, &lsquo;Ä world&rsquo;]</h1>
<blockquote>
<p><code>Ä world</code> (á»Ÿ trÃªn) lÃ  má»™t token duy nháº¥t Ä‘áº¡i diá»‡n cho chuá»—i kÃ½ tá»± &quot; world&quot; (cÃ³ khoáº£ng tráº¯ng).</p></blockquote>
<p>Má»™t <!-- raw HTML omitted -->token<!-- raw HTML omitted --> lÃ  Ä‘Æ¡n vá»‹ chuá»—i nhá» nháº¥t mÃ  mÃ´ hÃ¬nh nhÃ¬n tháº¥y. NÃ³ cÃ³ thá»ƒ lÃ  má»™t kÃ½ tá»±, má»™t tá»«, hoáº·c má»™t Ä‘oáº¡n tá»« con nhÆ° &ldquo;play&rdquo; hoáº·c &ldquo;##ing&rdquo; (&quot;##&quot; lÃ  má»™t máº«u, Ä‘á»«ng lo láº¯ng náº¿u báº¡n chÆ°a hiá»ƒu rÃµ láº¯m ğŸ¤—). <!-- raw HTML omitted -->Bá»™ tá»« vá»±ng<!-- raw HTML omitted --> (vocabulary) Ã¡nh xáº¡ má»—i token duy nháº¥t sang token ID.</p>
<p>python
from transformers import AutoTokenizer</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;HuggingFaceTB/SmolLM3-3B&rdquo;)
print(tokenizer.vocab)</p>
<h1 id="Ã®ÄºÃ®Ä¾-106502-Ä¡peel-89694-languages-91078-">{&lsquo;ÃÄ¹ÃÄ¾&rsquo;: 106502, &lsquo;Ä Peel&rsquo;: 89694, &lsquo;.languages&rsquo;: 91078, &hellip;}</h1>
<p>Má»™t tokenizer tá»‘t <!-- raw HTML omitted -->nÃ©n<!-- raw HTML omitted --> vÄƒn báº£n thÃ nh lÆ°á»£ng token nhá» nháº¥t. Ãt token hÆ¡n cÃ³ nghÄ©a lÃ  ngá»¯ cáº£nh sá»­ dá»¥ng nhiá»u hÆ¡n mÃ  khÃ´ng lÃ m tÄƒng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh. Viá»‡c huáº¥n luyá»‡n má»™t tokenizer vá» cÆ¡ báº£n lÃ  tÃ¬m ra cÃ¡c quy táº¯c nÃ©n tá»‘t nháº¥t cho táº­p dá»¯ liá»‡u cá»§a báº¡n. VÃ­ dá»¥, náº¿u báº¡n lÃ m viá»‡c vá»›i má»™t kho ngá»¯ liá»‡u tiáº¿ng Trung, Ä‘Ã´i khi báº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y nhá»¯ng Ä‘iá»u báº¥t ngá» thÃº vá»‹ ğŸ˜‰.</p>
<h2 id="the-tokenization-pipeline">The tokenization pipeline</h2>
<p>Tokenization diá»…n ra theo tá»«ng giai Ä‘oáº¡n. Má»—i giai Ä‘oáº¡n biáº¿n Ä‘á»•i vÄƒn báº£n trÆ°á»›c khi chuyá»ƒn nÃ³ sang giai Ä‘oáº¡n tiáº¿p theo:</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Stage</th>
          <th style="text-align: left">Purpose</th>
          <th style="text-align: left">Example</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>Normalizer</strong></td>
          <td style="text-align: left">TiÃªu chuáº©n hÃ³a vÄƒn báº£n (chá»¯ thÆ°á»ng, chuáº©n hÃ³a unicode, lÃ m sáº¡ch khoáº£ng tráº¯ng)</td>
          <td style="text-align: left"><code>&quot;HELLO World&quot;</code> â†’ <code>&quot;hello world&quot;</code></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Pre-tokenizer</strong></td>
          <td style="text-align: left">TÃ¡ch vÄƒn báº£n thÃ nh cÃ¡c khá»‘i sÆ¡ bá»™</td>
          <td style="text-align: left"><code>&quot;hello world&quot;</code> â†’ <code>[&quot;hello&quot;, &quot; world&quot;]</code></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Model</strong></td>
          <td style="text-align: left">Ãp dá»¥ng thuáº­t toÃ¡n tokenization (BPE, Unigram, v.v.)</td>
          <td style="text-align: left"><code>[&quot;hello&quot;, &quot; world&quot;]</code> â†’ <code>[9906, 1917]</code></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Post-processor</strong></td>
          <td style="text-align: left">ThÃªm cÃ¡c token Ä‘áº·c biá»‡t (BOS, EOS, padding)</td>
          <td style="text-align: left"><code>[9906, 1917]</code> â†’ <code>[1, 9906, 1917, 2]</code></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Decoder</strong></td>
          <td style="text-align: left">Chuyá»ƒn Ä‘á»•i token IDs trá»Ÿ láº¡i vÄƒn báº£n</td>
          <td style="text-align: left"><code>[9906, 1917]</code> â†’ <code>&quot;hello world&quot;</code></td>
      </tr>
  </tbody>
</table>
<p>Má»—i thÃ nh pháº§n lÃ  <!-- raw HTML omitted -->Ä‘á»™c láº­p<!-- raw HTML omitted -->. Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i <!-- raw HTML omitted -->normalizers<!-- raw HTML omitted --> hoáº·c thay Ä‘á»•i <!-- raw HTML omitted -->algorithm<!-- raw HTML omitted --> mÃ  khÃ´ng cáº§n viáº¿t láº¡i má»i thá»© khÃ¡c.</p>
<blockquote>
<p>Báº¡n cÃ³ thá»ƒ truy cáº­p tokenizer dá»±a trÃªn rust thÃ´ng qua <code>_tokenizer</code>. ChÃºng tÃ´i sáº½ Ä‘i sÃ¢u hÆ¡n vá» nÃ³ trong <a href="#tokenizersbackend-wraps-the-tokenizers-library">pháº§n nÃ y</a>.</p></blockquote>
<p>python
from transformers import AutoTokenizer</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;google/gemma-3-270m-it&rdquo;)</p>
<p>print(f&quot;{tokenizer._tokenizer.normalizer=}&quot;)</p>
<h1 id="replace">Replace(&hellip;)</h1>
<p>print(f&quot;{tokenizer._tokenizer.pre_tokenizer=}&quot;)</p>
<h1 id="split">Split(&hellip;)</h1>
<p>print(f&quot;{tokenizer._tokenizer.model=}&quot;)</p>
<h1 id="bpe">BPE(&hellip;)</h1>
<p>print(f&quot;{tokenizer._tokenizer.post_processor=}&quot;)</p>
<h1 id="templateprocessing">TemplateProcessing(&hellip;)</h1>
<p>print(f&quot;{tokenizer._tokenizer.decoder=}&quot;)</p>
<h1 id="sequencedecodersreplace-bytefallback-fuse">Sequence(decoders=[Replace(&hellip;), ByteFallback(), Fuse()])</h1>
<h2 id="tokenization-algorithms">Tokenization algorithms</h2>
<p>CÃ¡c thuáº­t toÃ¡n tokenization sau Ä‘Ã¢y chiáº¿m Æ°u tháº¿ trong cÃ¡c tokenizer mÃ´ hÃ¬nh ngÃ´n ngá»¯ hiá»‡n Ä‘áº¡i:</p>
<ol>
<li>
<p><!-- raw HTML omitted -->Byte Pair Encoding (BPE)<!-- raw HTML omitted --> láº·p Ä‘i láº·p láº¡i viá»‡c há»£p nháº¥t cÃ¡c cáº·p kÃ½ tá»± xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn nháº¥t. Thuáº­t toÃ¡n nÃ y cÃ³ tÃ­nh xÃ¡c Ä‘á»‹nh vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i. (Äá»c thÃªm vá» <!-- raw HTML omitted -->BPE<!-- raw HTML omitted -->)</p>
<p>python
from transformers import AutoTokenizer</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;openai/gpt-oss-20b&rdquo;)
print(tokenizer._tokenizer.model)</p>
<h1 id="bpe-1">BPE(&hellip;)</h1>
</li>
<li>
<p><!-- raw HTML omitted -->Unigram<!-- raw HTML omitted --> sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p xÃ¡c suáº¥t, chá»n cÃ¡ch phÃ¢n tÃ¡ch cÃ³ kháº£ nÄƒng xáº£y ra nháº¥t tá»« má»™t bá»™ tá»« vá»±ng ban Ä‘áº§u lá»›n. Äiá»u nÃ y linh hoáº¡t hÆ¡n BPE nghiÃªm ngáº·t. (Äá»c thÃªm vá» <!-- raw HTML omitted -->Unigram<!-- raw HTML omitted -->)</p>
<p>python
from transformers import AutoTokenizer</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;google-t5/t5-base&rdquo;)
print(tokenizer._tokenizer.model)</p>
<h1 id="unigram">Unigram(&hellip;)</h1>
</li>
<li>
<p><!-- raw HTML omitted -->WordPiece<!-- raw HTML omitted --> tÆ°Æ¡ng tá»± BPE nhÆ°ng sá»­ dá»¥ng cÃ¡c tiÃªu chÃ­ há»£p nháº¥t khÃ¡c nhau dá»±a trÃªn kháº£ nÄƒng xáº£y ra. (Äá»c thÃªm vá» <!-- raw HTML omitted -->WordPiece<!-- raw HTML omitted -->)</p>
<p>python
from transformers import AutoTokenizer</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;bert-base-uncased&rdquo;)
print(tokenizer._tokenizer.model)</p>
<h1 id="wordpiece">WordPiece(&hellip;)</h1>
</li>
</ol>
<h2 id="accessing-tokenizers-through-transformers">Accessing <code>tokenizers</code> through <code>transformers</code></h2>
<p>ThÆ° viá»‡n <a href="#"><!-- raw HTML omitted -->tokenizers<!-- raw HTML omitted --></a> lÃ  má»™t cÃ´ng cá»¥ tokenization dá»±a trÃªn Rust. NÃ³ nhanh, hiá»‡u quáº£ vÃ  hoÃ n toÃ n Ä‘á»™c láº­p vá»›i mÃ´ hÃ¬nh ngÃ´n ngá»¯. ThÆ° viá»‡n nÃ y xá»­ lÃ½ cÃ¡c cÆ¡ cháº¿ chuyá»ƒn Ä‘á»•i vÄƒn báº£n thÃ nh token IDs vÃ  ngÆ°á»£c láº¡i. ThÆ° viá»‡n <code>tokenizers</code> lÃ  má»™t cÃ´ng cá»¥ Ä‘a dá»¥ng triá»ƒn khai cÃ¡c thuáº­t toÃ¡n tokenization, nhÆ°ng khÃ´ng triá»ƒn khai cÃ¡c quy Æ°á»›c káº¿t ná»‘i cÃ¡c thuáº­t toÃ¡n Ä‘Ã³ vá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»¥ thá»ƒ.</p>
<p>HÃ£y xem xÃ©t nhá»¯ng gÃ¬ xáº£y ra khi báº¡n sá»­ dá»¥ng <code>tokenizers</code> trá»±c tiáº¿p vá»›i mÃ´ hÃ¬nh <a href="#"><!-- raw HTML omitted -->SmolLM3-3B<!-- raw HTML omitted --></a>:</p>
<p>python
from tokenizers import Tokenizer</p>
<p>tokenizer = Tokenizer.from_pretrained(&ldquo;HuggingFaceTB/SmolLM3-3B&rdquo;)
text = &ldquo;Hello world&rdquo;
encodings = tokenizer.encode(text)</p>
<p>print(encodings.ids)</p>
<h1 id="9906-1917-1">[9906, 1917]</h1>
<p>print(encodings.tokens)</p>
<h1 id="hello-Ä¡world-1">[&lsquo;Hello&rsquo;, &lsquo;Ä world&rsquo;]</h1>
<p>Káº¿t quáº£ lÃ  tokenization thÃ´. Báº¡n nháº­n Ä‘Æ°á»£c token IDs vÃ  cÃ¡c Ä‘oáº¡n chuá»—i tÆ°Æ¡ng á»©ng. KhÃ´ng cÃ³ gÃ¬ khÃ¡c.</p>
<p>BÃ¢y giá» hÃ£y xem xÃ©t nhá»¯ng gÃ¬ cÃ²n thiáº¿u. <code>SmolLM3-3B</code> lÃ  má»™t <!-- raw HTML omitted -->mÃ´ hÃ¬nh há»™i thoáº¡i<!-- raw HTML omitted -->. Khi báº¡n tÆ°Æ¡ng tÃ¡c vá»›i nÃ³, báº¡n thÆ°á»ng cáº¥u trÃºc Ä‘áº§u vÃ o cá»§a mÃ¬nh dÆ°á»›i dáº¡ng má»™t cuá»™c trÃ² chuyá»‡n vá»›i cÃ¡c vai trÃ² nhÆ° &ldquo;user&rdquo; vÃ  &ldquo;assistant&rdquo;. MÃ´ hÃ¬nh ngÃ´n ngá»¯ mong Ä‘á»£i cÃ¡c token Ä‘á»‹nh dáº¡ng Ä‘áº·c biá»‡t Ä‘á»ƒ biá»ƒu thá»‹ cÃ¡c vai trÃ² nÃ y. ThÆ° viá»‡n <code>tokenizers</code> thÃ´ khÃ´ng cÃ³ khÃ¡i niá»‡m nÃ o vá» Ä‘iá»u nÃ y.</p>
<h3 id="how-do-you-bridge-the-gap-between-raw-tokenization-and-model-requirements">How do you bridge the gap between raw tokenization and model requirements?</h3>
<p>ThÆ° viá»‡n <code>transformers</code> thu háº¹p khoáº£ng cÃ¡ch nÃ y. ThÆ° viá»‡n nÃ y chá»§ yáº¿u Ä‘Æ°á»£c biáº¿t Ä‘áº¿n nhÆ° má»™t thÆ° viá»‡n Ä‘á»‹nh nghÄ©a mÃ´ hÃ¬nh, nhÆ°ng nÃ³ cÅ©ng cung cáº¥p má»™t lá»›p trá»«u tÆ°á»£ng tokenizer gÃ³i gá»n backend <code>tokenizers</code> thÃ´ vÃ  thÃªm chá»©c nÄƒng nháº­n biáº¿t mÃ´ hÃ¬nh.</p>
<p>ÄÃ¢y lÃ  cÃ¹ng má»™t tokenization vá»›i wrapper <code>transformers</code>:</p>
<p>python
from transformers import AutoTokenizer</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;HuggingFaceTB/SmolLM3-3B&rdquo;)</p>
<h1 id="Ä‘á»‹nh-dáº¡ng-má»™t-cuá»™c-trÃ²-chuyá»‡n-báº±ng-cÃ¡ch-sá»­-dá»¥ng-máº«u-chat-cá»§a-mÃ´-hÃ¬nh">Äá»‹nh dáº¡ng má»™t cuá»™c trÃ² chuyá»‡n báº±ng cÃ¡ch sá»­ dá»¥ng máº«u chat cá»§a mÃ´ hÃ¬nh</h1>
<p>prompt = &ldquo;Give me a brief explanation of gravity in simple terms.&rdquo;
messages = [{&ldquo;role&rdquo;: &ldquo;user&rdquo;, &ldquo;content&rdquo;: prompt}]
text = tokenizer.apply_chat_template(
messages,
tokenize=False,
add_generation_prompt=True,
)</p>
<p>print(text)</p>
<h1 id="im_startsystem">&lt;|im_start|&gt;system</h1>
<h1 id="heading">&hellip;</h1>
<h1 id="im_startuser">&lt;|im_start|&gt;user</h1>
<h1 id="give-me-a-brief-explanation-of-gravity-in-simple-termsim_end">Give me a brief explanation of gravity in simple terms.&lt;|im_end|&gt;</h1>
<h1 id="im_startassistant">&lt;|im_start|&gt;assistant</h1>
<p>model_inputs = tokenizer([text], return_tensors=&ldquo;pt&rdquo;)</p>
<p>LÆ°u Ã½ cÃ¡ch cÃ¡c token Ä‘áº·c biá»‡t nhÆ° <code>&amp;lt;|im_start|&amp;gt;</code> vÃ  <code>&amp;lt;|im_end|&amp;gt;</code> Ä‘Æ°á»£c Ã¡p dá»¥ng cho prompt trÆ°á»›c khi tokenization. Äiá»u nÃ y há»¯u Ã­ch Ä‘á»ƒ mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c vá»‹ trÃ­ báº¯t Ä‘áº§u vÃ  káº¿t thÃºc cá»§a má»™t chuá»—i má»›i.</p>
<p>Tokenizer <code>transformers</code> bá»• sung má»i thá»© mÃ  thÆ° viá»‡n thÃ´ cÃ²n thiáº¿u:</p>
<ul>
<li><!-- raw HTML omitted -->Ãp dá»¥ng máº«u chat.<!-- raw HTML omitted --> PhÆ°Æ¡ng thá»©c <code>apply_chat_template</code> Ä‘á»‹nh dáº¡ng cÃ¡c cuá»™c trÃ² chuyá»‡n theo cÃ¡c máº«u Jinja Ä‘Æ°á»£c lÆ°u trá»¯ trong cáº¥u hÃ¬nh tokenizer, chÃ¨n cÃ¡c token vÃ  dáº¥u phÃ¢n cÃ¡ch Ä‘áº·c biá»‡t chÃ­nh xÃ¡c.</li>
<li><!-- raw HTML omitted -->ChÃ¨n token Ä‘áº·c biá»‡t tá»± Ä‘á»™ng.<!-- raw HTML omitted --> CÃ¡c token báº¯t Ä‘áº§u chuá»—i vÃ  káº¿t thÃºc chuá»—i Ä‘Æ°á»£c thÃªm vÃ o nhá»¯ng nÆ¡i mÃ´ hÃ¬nh mong Ä‘á»£i chÃºng.</li>
<li><!-- raw HTML omitted -->Cáº¯t bá»›t Ä‘áº¿n Ä‘á»™ dÃ i ngá»¯ cáº£nh.<!-- raw HTML omitted --> Báº¡n cÃ³ thá»ƒ chá»‰ Ä‘á»‹nh <code>truncation=True</code> vÃ  tokenizer sáº½ tÃ´n trá»ng Ä‘á»™ dÃ i chuá»—i tá»‘i Ä‘a cá»§a mÃ´ hÃ¬nh.</li>
<li><!-- raw HTML omitted -->MÃ£ hÃ³a theo lÃ´ vá»›i padding.<!-- raw HTML omitted --> Nhiá»u Ä‘áº§u vÃ o cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘á»‡m Ä‘áº¿n cÃ¹ng má»™t Ä‘á»™ dÃ i vá»›i token padding vÃ  hÆ°á»›ng chÃ­nh xÃ¡c.</li>
<li><!-- raw HTML omitted -->TÃ¹y chá»n Ä‘á»‹nh dáº¡ng tráº£ vá».<!-- raw HTML omitted --> Báº¡n cÃ³ thá»ƒ yÃªu cáº§u cÃ¡c tensor PyTorch (<code>return_tensors=&quot;pt&quot;</code>) , máº£ng NumPy vÃ  cÃ¡c Ä‘á»‹nh dáº¡ng khÃ¡c.</li>
</ul>
<blockquote>
<p><code>transformers</code> triá»ƒn khai API tokenization Ä‘Æ°á»£c sá»­ dá»¥ng phá»• biáº¿n nháº¥t trong toÃ n bá»™ cá»™ng Ä‘á»“ng ML (<code>encode</code>, <code>decode</code>, <code>convert_tokens_to_ids</code>, v.v.)</p></blockquote>
<h2 id="the-tokenizer-class-hierarchy-in-transformers">The Tokenizer Class Hierarchy in <code>transformers</code></h2>
<p>ThÆ° viá»‡n <code>transformers</code> tá»• chá»©c cÃ¡c tokenizer thÃ nh má»™t há»‡ thá»‘ng phÃ¢n cáº¥p lá»›p. á» trÃªn cÃ¹ng lÃ  má»™t lá»›p cÆ¡ sá»Ÿ Ä‘á»‹nh nghÄ©a giao diá»‡n chung. BÃªn dÆ°á»›i nÃ³, cÃ¡c lá»›p backend xá»­ lÃ½ tokenization thá»±c táº¿ báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c engine khÃ¡c nhau. á» dÆ°á»›i cÃ¹ng, cÃ¡c lá»›p dÃ nh riÃªng cho mÃ´ hÃ¬nh cáº¥u hÃ¬nh cÃ¡c backend cho cÃ¡c mÃ´ hÃ¬nh cá»¥ thá»ƒ.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Layer</th>
          <th style="text-align: left">Component</th>
          <th style="text-align: left">Responsibility</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Entry Point</td>
          <td style="text-align: left"><code>AutoTokenizer</code></td>
          <td style="text-align: left">Tá»± Ä‘á»™ng chá»n vÃ  khá»Ÿi táº¡o lá»›p tokenizer chÃ­nh xÃ¡c</td>
      </tr>
      <tr>
          <td style="text-align: left">Model-Specific</td>
          <td style="text-align: left"><code>LlamaTokenizer</code>, <code>GPT2Tokenizer</code>, v.v.</td>
          <td style="text-align: left">Cáº¥u hÃ¬nh backend vá»›i kiáº¿n trÃºc chuáº©n hÃ³a, tiá»n xá»­ lÃ½, v.v., token Ä‘áº·c biá»‡t vÃ  cÃ i Ä‘áº·t dÃ nh riÃªng cho mÃ´ hÃ¬nh</td>
      </tr>
      <tr>
          <td style="text-align: left">Backend</td>
          <td style="text-align: left"><code>TokenizersBackend</code>, <code>PythonBackend</code>, <code>SentencePieceBackend</code></td>
          <td style="text-align: left">Thá»±c hiá»‡n tokenization thá»±c táº¿ báº±ng cÃ¡ch sá»­ dá»¥ng engine cá»¥ thá»ƒ</td>
      </tr>
      <tr>
          <td style="text-align: left">Base</td>
          <td style="text-align: left"><code>PreTrainedTokenizerBase</code></td>
          <td style="text-align: left">Äá»‹nh nghÄ©a giao diá»‡n chung vÃ  chá»©c nÄƒng Ä‘Æ°á»£c chia sáº»</td>
      </tr>
      <tr>
          <td style="text-align: left">Engine</td>
          <td style="text-align: left"><code>tokenizers</code> (Rust), SentencePiece, Pure Python</td>
          <td style="text-align: left">Thá»±c hiá»‡n tokenization thÃ´</td>
      </tr>
  </tbody>
</table>
<h3 id="pretrainedtokenizerbase-defines-the-common-interface-for-all-tokenizers"><code>PreTrainedTokenizerBase</code> defines the common interface for all tokenizers</h3>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->PreTrainedTokenizerBase<!-- raw HTML omitted --><!-- raw HTML omitted --> lÃ  lá»›p cÆ¡ sá»Ÿ trá»«u tÆ°á»£ng cho táº¥t cáº£ cÃ¡c tokenizer trong <code>transformers</code>. NÃ³ Ä‘á»‹nh nghÄ©a giao diá»‡n mÃ  má»i tokenizer pháº£i triá»ƒn khai.</p>
<p>Lá»›p cÆ¡ sá»Ÿ xá»­ lÃ½ cÃ¡c chá»©c nÄƒng khÃ´ng phá»¥ thuá»™c vÃ o backend tokenization:</p>
<ul>
<li><!-- raw HTML omitted -->Thuá»™c tÃ­nh token Ä‘áº·c biá»‡t.<!-- raw HTML omitted --> CÃ¡c thuá»™c tÃ­nh nhÆ° <code>bos_token</code>, <code>eos_token</code>, <code>pad_token</code> vÃ  <code>unk_token</code> Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a á»Ÿ Ä‘Ã¢y. CÃ¡c thuá»™c tÃ­nh nÃ y cung cáº¥p quyá»n truy cáº­p vÃ o cÃ¡c token Ä‘áº·c biá»‡t mÃ  mÃ´ hÃ¬nh sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh dáº¥u ranh giá»›i chuá»—i vÃ  xá»­ lÃ½ cÃ¡c Ä‘áº§u vÃ o khÃ´ng xÃ¡c Ä‘á»‹nh.</li>
<li><!-- raw HTML omitted -->Giao diá»‡n mÃ£ hÃ³a.<!-- raw HTML omitted --> CÃ¡c phÆ°Æ¡ng thá»©c <code>__call__</code>, <code>encode</code> vÃ  <code>encode_plus</code> Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a á»Ÿ Ä‘Ã¢y. CÃ¡c phÆ°Æ¡ng thá»©c nÃ y cháº¥p nháº­n Ä‘áº§u vÃ o vÄƒn báº£n vÃ  tráº£ vá» token IDs cÃ¹ng vá»›i máº·t náº¡ chÃº Ã½ vÃ  siÃªu dá»¯ liá»‡u khÃ¡c.</li>
<li><!-- raw HTML omitted -->Giao diá»‡n giáº£i mÃ£.<!-- raw HTML omitted --> CÃ¡c phÆ°Æ¡ng thá»©c <code>decode</code> vÃ  <code>batch_decode</code> chuyá»ƒn Ä‘á»•i token IDs trá»Ÿ láº¡i vÄƒn báº£n.</li>
<li><!-- raw HTML omitted -->Serialize.<!-- raw HTML omitted --> CÃ¡c phÆ°Æ¡ng thá»©c <code>save_pretrained</code> vÃ  <code>from_pretrained</code> xá»­ lÃ½ viá»‡c táº£i xuá»‘ng cÃ¡c tá»‡p chÃ­nh xÃ¡c, Ä‘á»c thÃ´ng tin, lÆ°u trá»¯ tokenizer vÃ o Ä‘Ä©a, v.v.</li>
<li><!-- raw HTML omitted -->Há»— trá»£ máº«u chat.<!-- raw HTML omitted --> PhÆ°Æ¡ng thá»©c <code>apply_chat_template</code> náº±m á»Ÿ Ä‘Ã¢y, Ä‘á»‹nh dáº¡ng cÃ¡c cuá»™c trÃ² chuyá»‡n theo máº«u Jinja Ä‘Æ°á»£c lÆ°u trá»¯ trong cáº¥u hÃ¬nh tokenizer.</li>
</ul>
<p>Má»i tokenizer trong <code>transformers</code> cuá»‘i cÃ¹ng Ä‘á»u káº¿ thá»«a tá»« <code>PreTrainedTokenizerBase</code>. Lá»›p cÆ¡ sá»Ÿ Ä‘áº£m báº£o hÃ nh vi nháº¥t quÃ¡n trÃªn táº¥t cáº£ cÃ¡c tokenizer, báº¥t ká»ƒ chÃºng sá»­ dá»¥ng backend nÃ o cho tokenization thá»±c táº¿.</p>
<h3 id="tokenizersbackend-wraps-the-tokenizers-library"><code>TokenizersBackend</code> wraps the <code>tokenizers</code> library</h3>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->TokenizersBackend<!-- raw HTML omitted --><!-- raw HTML omitted --> lÃ  lá»›p backend chÃ­nh cho háº§u háº¿t cÃ¡c tokenizer hiá»‡n Ä‘áº¡i. NÃ³ káº¿ thá»«a tá»« <code>PreTrainedTokenizerBase</code> vÃ  gÃ³i gá»n thÆ° viá»‡n <code>tokenizers</code> dá»±a trÃªn Rust.</p>
<p>Lá»›p nÃ y lÆ°u trá»¯ Ä‘á»‘i tÆ°á»£ng tokenizer Rust bÃªn trong:</p>
<p>python
class TokenizersBackend(PreTrainedTokenizerBase):
def <strong>init</strong>(self, tokenizer_object, &hellip;):
self._tokenizer = tokenizer_object  # The Rust tokenizer
&hellip;</p>
<p>Khi báº¡n gá»i cÃ¡c phÆ°Æ¡ng thá»©c mÃ£ hÃ³a trÃªn má»™t tokenizer <code>TokenizersBackend</code>, lá»›p nÃ y sáº½ á»§y quyá»n tokenization thá»±c táº¿ cho backend Rust:</p>
<p>python
def _batch_encode_plus(self, batch_text_or_text_pairs, &hellip;):
encodings = self._tokenizer.encode_batch(batch_text_or_text_pairs, &hellip;)
&hellip;</p>
<p>Backend Rust thá»±c hiá»‡n cÃ´ng viá»‡c tÃ­nh toÃ¡n chuyÃªn sÃ¢u, trong khi lá»›p wrapper Python thÃªm cÃ¡c tÃ­nh nÄƒng nháº­n biáº¿t mÃ´ hÃ¬nh á»Ÿ trÃªn.</p>
<p>Nhiá»u tokenizer dÃ nh riÃªng cho mÃ´ hÃ¬nh káº¿ thá»«a tá»« <code>TokenizersBackend</code>, vÃ­ dá»¥ bao gá»“m:</p>
<ul>
<li><code>LlamaTokenizer</code></li>
<li><code>GemmaTokenizer</code></li>
</ul>
<p>CÃ¡c lá»›p dÃ nh riÃªng cho mÃ´ hÃ¬nh nÃ y cáº¥u hÃ¬nh backend vá»›i bá»™ tá»« vá»±ng, quy táº¯c há»£p nháº¥t, token Ä‘áº·c biá»‡t vÃ  cÃ i Ä‘áº·t chÃ­nh xÃ¡c cho cÃ¡c mÃ´ hÃ¬nh tÆ°Æ¡ng á»©ng cá»§a chÃºng.</p>
<h3 id="pythonbackend-provides-a-pure-python-mixin"><code>PythonBackend</code> provides a pure-Python mixin</h3>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->PythonBackend<!-- raw HTML omitted --><!-- raw HTML omitted --> káº¿ thá»«a tá»« <code>PreTrainedTokenizerBase</code> vÃ  triá»ƒn khai tokenization báº±ng Python thuáº§n tÃºy. Lá»›p nÃ y Ä‘Æ°á»£c Ä‘áº·t tÃªn lÃ  <!-- raw HTML omitted --><!-- raw HTML omitted -->PreTrainedTokenizer<!-- raw HTML omitted --><!-- raw HTML omitted -->.</p>
<p>Backend Python thuáº§n tÃºy tá»“n táº¡i vÃ¬ má»™t sá»‘ lÃ½ do:</p>
<ul>
<li><!-- raw HTML omitted -->Logic tokenization tÃ¹y chá»‰nh.<!-- raw HTML omitted --> Má»™t sá»‘ mÃ´ hÃ¬nh yÃªu cáº§u hÃ nh vi tokenization khÃ´ng phÃ¹ há»£p vá»›i quy trÃ¬nh <code>tokenizers</code> tiÃªu chuáº©n.</li>
<li><!-- raw HTML omitted -->TÆ°Æ¡ng thÃ­ch di sáº£n.<!-- raw HTML omitted --> CÃ¡c triá»ƒn khai mÃ´ hÃ¬nh cÅ© hÆ¡n cÃ³ thá»ƒ dá»±a vÃ o hÃ nh vi dÃ nh riÃªng cho Python.</li>
</ul>
<blockquote>
<p>Backend Python cháº­m hÆ¡n backend Rust. Äá»‘i vá»›i háº§u háº¿t cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng, backend dá»±a trÃªn Rust <code>TokenizersBackend</code> Ä‘Æ°á»£c Æ°u tiÃªn.</p></blockquote>
<p>CÃ¡c tokenizer dÃ nh riÃªng cho mÃ´ hÃ¬nh káº¿ thá»«a tá»« <code>PythonBackend</code> (hoáº·c bÃ­ danh <code>PreTrainedTokenizer</code> cá»§a nÃ³) bao gá»“m má»™t sá»‘ mÃ´ hÃ¬nh cÅ© hoáº·c chuyÃªn biá»‡t, nhÆ°:</p>
<ul>
<li><code>CTRLTokenizer</code></li>
<li><code>CanineTokenizer</code></li>
</ul>
<h3 id="sentencepiecebackend-handles-sentencepiece-models"><code>SentencePieceBackend</code> handles SentencePiece models</h3>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->SentencePieceBackend<!-- raw HTML omitted --><!-- raw HTML omitted --> káº¿ thá»«a tá»« <code>PythonBackend</code> vÃ  cung cáº¥p tÃ­ch há»£p vá»›i thÆ° viá»‡n <!-- raw HTML omitted -->SentencePiece<!-- raw HTML omitted --> cá»§a Google. SentencePiece lÃ  má»™t thÆ° viá»‡n tokenization Ä‘á»™c láº­p mÃ  nhiá»u mÃ´ hÃ¬nh sá»­ dá»¥ng, Ä‘áº·c biá»‡t lÃ  nhá»¯ng mÃ´ hÃ¬nh Ä‘Æ°á»£c Google huáº¥n luyá»‡n.</p>
<p>Backend nÃ y gÃ³i gá»n má»™t bá»™ xá»­ lÃ½ SentencePiece:</p>
<p>python
class SentencePieceBackend(PythonBackend):
def <strong>init</strong>(self, vocab_file, &hellip;):
self.sp_model = spm.SentencePieceProcessor()
self.sp_model.Load(vocab_file)
&hellip;</p>
<p>CÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng SentencePiece tokenization káº¿ thá»«a tá»« backend nÃ y. VÃ­ dá»¥ bao gá»“m:</p>
<ul>
<li><code>SiglipTokenizer</code></li>
<li><code>BartphoTokenizer</code></li>
</ul>
<p>Backend SentencePiece káº¿ thá»«a tá»« <code>PythonBackend</code> thay vÃ¬ trá»±c tiáº¿p tá»« <code>PreTrainedTokenizerBase</code> vÃ¬ nÃ³ chia sáº» pháº§n lá»›n giao diá»‡n vÃ  logic padding/truncation tÆ°Æ¡ng tá»±.</p>
<h2 id="autotokenizer-automatically-selects-the-correct-tokenizer-class"><code>AutoTokenizer</code> Automatically Selects the Correct Tokenizer Class</h2>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->AutoTokenizer<!-- raw HTML omitted --><!-- raw HTML omitted --> lÃ  Ä‘iá»ƒm truy cáº­p Ä‘Æ°á»£c khuyáº¿n nghá»‹ Ä‘á»ƒ táº£i tokenizer. NÃ³ tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh lá»›p tokenizer nÃ o cáº§n sá»­ dá»¥ng cho má»™t mÃ´ hÃ¬nh nháº¥t Ä‘á»‹nh vÃ  tráº£ vá» má»™t instance cá»§a lá»›p Ä‘Ã³.</p>
<p>python
from transformers import AutoTokenizer</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;gpt2&rdquo;)</p>
<p>BÃªn dÆ°á»›i bá» máº·t, <code>AutoTokenizer</code> thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:</p>
<ol>
<li>
<p><!-- raw HTML omitted -->Táº£i xuá»‘ng cáº¥u hÃ¬nh tokenizer.<!-- raw HTML omitted --> PhÆ°Æ¡ng thá»©c <code>from_pretrained</code> láº¥y <code>tokenizer_config.json</code> tá»« Hub (hoáº·c tá»« thÆ° má»¥c cá»¥c bá»™).</p>
</li>
<li>
<p><!-- raw HTML omitted -->XÃ¡c Ä‘á»‹nh loáº¡i mÃ´ hÃ¬nh.<!-- raw HTML omitted --> Cáº¥u hÃ¬nh chá»©a siÃªu dá»¯ liá»‡u giÃºp <!-- raw HTML omitted -->xÃ¡c Ä‘á»‹nh loáº¡i mÃ´ hÃ¬nh<!-- raw HTML omitted --> (vÃ­ dá»¥: &ldquo;gpt2&rdquo;, &ldquo;llama&rdquo;, &ldquo;bert&rdquo;).</p>
</li>
<li>
<p><!-- raw HTML omitted -->Tra cá»©u lá»›p tokenizer.<!-- raw HTML omitted --> <code>AutoTokenizer</code> duy trÃ¬ má»™t Ã¡nh xáº¡ gá»i lÃ  <!-- raw HTML omitted --><!-- raw HTML omitted -->TOKENIZER_MAPPING_NAMES<!-- raw HTML omitted --><!-- raw HTML omitted --> Ã¡nh xáº¡ cÃ¡c loáº¡i mÃ´ hÃ¬nh vá»›i tÃªn lá»›p tokenizer:</p>
<p>python
TOKENIZER_MAPPING_NAMES = {
&ldquo;gpt2&rdquo;: &ldquo;GPT2Tokenizer&rdquo;,
&ldquo;llama&rdquo;: &ldquo;LlamaTokenizer&rdquo;,
&ldquo;bert&rdquo;: &ldquo;BertTokenizer&rdquo;,
&hellip;
}</p>
</li>
<li>
<p><!-- raw HTML omitted -->Khá»Ÿi táº¡o lá»›p chÃ­nh xÃ¡c.<!-- raw HTML omitted --> <code>AutoTokenizer</code> nháº­p lá»›p tokenizer phÃ¹ há»£p vÃ  gá»i phÆ°Æ¡ng thá»©c <code>from_pretrained</code> cá»§a nÃ³.</p>
</li>
<li>
<p><!-- raw HTML omitted -->Tráº£ vá» tokenizer Ä‘Ã£ cáº¥u hÃ¬nh.<!-- raw HTML omitted --> Báº¡n nháº­n Ä‘Æ°á»£c má»™t tokenizer dÃ nh riÃªng cho mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘áº§y Ä‘á»§, sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng.</p>
</li>
</ol>
<blockquote>
<p>Lá»£i Ã­ch cá»§a <code>AutoTokenizer</code> lÃ  báº¡n khÃ´ng cáº§n biáº¿t mÃ´ hÃ¬nh sá»­ dá»¥ng lá»›p tokenizer nÃ o. Cho dÃ¹ mÃ´ hÃ¬nh sá»­ dá»¥ng <code>LlamaTokenizer</code>, <code>GPT2Tokenizer</code> hay <code>BertTokenizer</code>, cÃ¹ng má»™t lá»‡nh gá»i <code>AutoTokenizer.from_pretrained(&quot;model-name&quot;)</code> Ä‘á»u hoáº¡t Ä‘á»™ng.</p></blockquote>
<p>Há»‡ thá»‘ng tokenizer trong <code>transformers</code> táº¡o thÃ nh má»™t kiáº¿n trÃºc phÃ¢n lá»›p:</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Layer</th>
          <th style="text-align: left">Component</th>
          <th style="text-align: left">Responsibility</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Entry Point</td>
          <td style="text-align: left"><code>AutoTokenizer</code></td>
          <td style="text-align: left">Tá»± Ä‘á»™ng chá»n vÃ  khá»Ÿi táº¡o lá»›p tokenizer chÃ­nh xÃ¡c</td>
      </tr>
      <tr>
          <td style="text-align: left">Model-Specific</td>
          <td style="text-align: left"><code>LlamaTokenizer</code>, <code>GPT2Tokenizer</code>, v.v.</td>
          <td style="text-align: left">Cáº¥u hÃ¬nh backend vá»›i kiáº¿n trÃºc chuáº©n hÃ³a, tiá»n xá»­ lÃ½, v.v., token Ä‘áº·c biá»‡t vÃ  cÃ i Ä‘áº·t dÃ nh riÃªng cho mÃ´ hÃ¬nh</td>
      </tr>
      <tr>
          <td style="text-align: left">Backend</td>
          <td style="text-align: left"><code>TokenizersBackend</code>, <code>PythonBackend</code>, <code>SentencePieceBackend</code></td>
          <td style="text-align: left">Thá»±c hiá»‡n tokenization thá»±c táº¿ báº±ng cÃ¡ch sá»­ dá»¥ng engine cá»¥ thá»ƒ</td>
      </tr>
      <tr>
          <td style="text-align: left">Base</td>
          <td style="text-align: left"><code>PreTrainedTokenizerBase</code></td>
          <td style="text-align: left">Äá»‹nh nghÄ©a giao diá»‡n chung vÃ  chá»©c nÄƒng Ä‘Æ°á»£c chia sáº»</td>
      </tr>
      <tr>
          <td style="text-align: left">Engine</td>
          <td style="text-align: left"><code>tokenizers</code> (Rust), SentencePiece, Pure Python</td>
          <td style="text-align: left">Thá»±c hiá»‡n tokenization thÃ´</td>
      </tr>
  </tbody>
</table>
<h2 id="v5-separates-tokenizer-architecture-from-trained-vocab">v5 Separates Tokenizer Architecture from Trained Vocab</h2>
<p>Thay Ä‘á»•i quan trá»ng nháº¥t trong Transformers v5 lÃ  sá»± thay Ä‘á»•i triáº¿t lÃ½ trong cÃ¡ch Ä‘á»‹nh nghÄ©a tokenizer. <!-- raw HTML omitted -->Tokenizer hiá»‡n hoáº¡t Ä‘á»™ng nhÆ° <!-- raw HTML omitted -->nn.Module<!-- raw HTML omitted --> cá»§a PyTorch<!-- raw HTML omitted -->: trÆ°á»›c tiÃªn báº¡n Ä‘á»‹nh nghÄ©a kiáº¿n trÃºc, sau Ä‘Ã³ Ä‘iá»n vÃ o nÃ³ cÃ¡c tham sá»‘ Ä‘Ã£ há»c.</p>
<h3 id="the-problem-with-v4-tokenizers-were-opaque-and-tightly-coupled">The problem with v4: tokenizers were opaque and tightly coupled</h3>
<p>Trong v4, tokenizer lÃ  nhá»¯ng há»™p Ä‘en gáº¯n liá»n vá»›i cÃ¡c tá»‡p checkpoint Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. Náº¿u báº¡n táº£i <code>LlamaTokenizerFast</code>, báº¡n khÃ´ng thá»ƒ dá»… dÃ ng tráº£ lá»i cÃ¡c cÃ¢u há»i cÆ¡ báº£n vá» nÃ³:</p>
<ul>
<li>NÃ³ lÃ  BPE hay Unigram?</li>
<li>NÃ³ chuáº©n hÃ³a vÄƒn báº£n nhÆ° tháº¿ nÃ o?</li>
<li>NÃ³ sá»­ dá»¥ng chiáº¿n lÆ°á»£c tiá»n xá»­ lÃ½ nÃ o?</li>
<li>CÃ¡c token Ä‘áº·c biá»‡t lÃ  gÃ¬ vÃ  vá»‹ trÃ­ cá»§a chÃºng á»Ÿ Ä‘Ã¢u?</li>
</ul>
<p>PhÆ°Æ¡ng thá»©c <code>__init__</code> khÃ´ng cung cáº¥p báº¥t ká»³ gá»£i Ã½ nÃ o. Báº¡n pháº£i Ä‘Ã o sÃ¢u vÃ o cÃ¡c tá»‡p Ä‘Æ°á»£c serialize hoáº·c tÃ i liá»‡u bÃªn ngoÃ i Ä‘á»ƒ hiá»ƒu tokenizer thá»±c sá»± lÃ m gÃ¬.</p>
<p>python
<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<p><code>LlamaTokenizerFast</code> nhÆ° trong <code>transformers</code> v4</p>
<p>V4 cÅ©ng duy trÃ¬ hai triá»ƒn khai song song cho má»—i mÃ´ hÃ¬nh:</p>
<ol>
<li>má»™t tokenizer Python &ldquo;cháº­m&rdquo; (<!-- raw HTML omitted -->LlamaTokenizer<!-- raw HTML omitted --> káº¿ thá»«a tá»« <code>PreTrainedTokenizer</code>) vÃ </li>
<li>má»™t tokenizer &ldquo;nhanh&rdquo; dá»±a trÃªn Rust (<!-- raw HTML omitted -->LlamaTokenizerFast<!-- raw HTML omitted --> káº¿ thá»«a tá»« <code>PreTrainedTokenizerFast</code>).</li>
</ol>
<p>Äiá»u nÃ y cÃ³ nghÄ©a lÃ :</p>
<ul>
<li><!-- raw HTML omitted -->Hai tá»‡p cho má»—i mÃ´ hÃ¬nh<!-- raw HTML omitted --> (vÃ­ dá»¥: <code>tokenization_llama.py</code> vÃ  <code>tokenization_llama_fast.py</code>)</li>
<li><!-- raw HTML omitted -->Sao chÃ©p mÃ£<!-- raw HTML omitted --> trÃªn hÃ ng trÄƒm mÃ´ hÃ¬nh</li>
<li><!-- raw HTML omitted -->Sá»± khÃ¡c biá»‡t vá» hÃ nh vi<!-- raw HTML omitted --> giá»¯a phiÃªn báº£n cháº­m vÃ  nhanh, dáº«n Ä‘áº¿n cÃ¡c lá»—i tinh vi</li>
<li><!-- raw HTML omitted -->Bá»™ kiá»ƒm thá»­ ngÃ y cÃ ng tÄƒng<!-- raw HTML omitted --> dÃ nh riÃªng cho viá»‡c xÃ¡c minh ráº±ng cÃ¡c tokenizer cháº­m vÃ  nhanh táº¡o ra káº¿t quáº£ giá»‘ng há»‡t nhau</li>
<li><!-- raw HTML omitted -->Sá»± nháº§m láº«n cá»§a ngÆ°á»i dÃ¹ng<!-- raw HTML omitted --> vá» viá»‡c nÃªn sá»­ dá»¥ng tokenizer nÃ o vÃ  khi nÃ o</li>
</ul>
<p>Quan trá»ng nháº¥t, báº¡n khÃ´ng thá»ƒ táº¡o má»™t kiáº¿n trÃºc tokenizer trá»‘ng. Náº¿u báº¡n muá»‘n huáº¥n luyá»‡n má»™t tokenizer kiá»ƒu LLaMA trÃªn dá»¯ liá»‡u dÃ nh riÃªng cho miá»n cá»§a mÃ¬nh, sáº½ khÃ´ng cÃ³ cÃ¡ch rÃµ rÃ ng nÃ o Ä‘á»ƒ khá»Ÿi táº¡o má»™t tokenizer LLaMA &ldquo;trá»‘ng&rdquo; vÃ  Ä‘iá»n vÃ o Ä‘Ã³ bá»™ tá»« vá»±ng vÃ  cÃ¡c quy táº¯c há»£p nháº¥t cá»§a báº¡n. Tokenizer chá»‰ tá»“n táº¡i dÆ°á»›i dáº¡ng cÃ¡c checkpoint Ä‘Ã£ táº£i, khÃ´ng pháº£i dÆ°á»›i dáº¡ng cÃ¡c máº«u cÃ³ thá»ƒ cáº¥u hÃ¬nh.</p>
<h3 id="the-v5-solution-architecture-and-parameters-are-now-separate">The v5 solution: architecture and parameters are now separate</h3>
<p>V5 coi kiáº¿n trÃºc tokenizer (normalizer, pre-tokenizer, loáº¡i mÃ´ hÃ¬nh, post-processor, decoder) lÃ  riÃªng biá»‡t vá»›i cÃ¡c tham sá»‘ Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n (bá»™ tá»« vá»±ng, quy táº¯c há»£p nháº¥t). Äiá»u nÃ y pháº£n Ã¡nh cÃ¡ch PyTorch tÃ¡ch kiáº¿n trÃºc mÃ´ hÃ¬nh khá»i trá»ng sá»‘ Ä‘Ã£ há»c.</p>
<p><!-- raw HTML omitted -->Vá»›i <!-- raw HTML omitted -->nn.Module<!-- raw HTML omitted -->, báº¡n Ä‘á»‹nh nghÄ©a cÃ¡c lá»›p trÆ°á»›c:<!-- raw HTML omitted --></p>
<p>python
from torch import nn</p>
<p>model = nn.Sequential(
nn.Embedding(vocab_size, embed_dim),
nn.Linear(embed_dim, hidden_dim),
)</p>
<h1 id="kiáº¿n-trÃºc-Ä‘Ã£-Ä‘Æ°á»£c-Ä‘á»‹nh-nghÄ©a-trá»ng-sá»‘-Ä‘Æ°á»£c-khá»Ÿi-táº¡o-ngáº«u-nhiÃªn-hoáº·c-táº£i-sau">Kiáº¿n trÃºc Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a; trá»ng sá»‘ Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn hoáº·c táº£i sau</h1>
<p><!-- raw HTML omitted -->Tokenizer v5 tuÃ¢n theo cÃ¹ng má»™t máº«u:<!-- raw HTML omitted --></p>
<p>python
from transformers import LlamaTokenizer</p>
<h1 id="khá»Ÿi-táº¡o-tokenizer-trá»‘ng">Khá»Ÿi táº¡o tokenizer trá»‘ng</h1>
<p>tokenizer = LlamaTokenizer()</p>
<h1 id="huáº¥n-luyá»‡n-trÃªn-dá»¯-liá»‡u-cá»§a-riÃªng-báº¡n-Ä‘á»ƒ-Ä‘iá»n-vÃ o-bá»™-tá»«-vá»±ng-vÃ -quy-táº¯c-há»£p-nháº¥t">Huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u cá»§a riÃªng báº¡n Ä‘á»ƒ Ä‘iá»n vÃ o bá»™ tá»« vá»±ng vÃ  quy táº¯c há»£p nháº¥t</h1>
<p>tokenizer.train(files=[&ldquo;my_corpus.txt&rdquo;])</p>
<p>Lá»›p tokenizer hiá»‡n khai bÃ¡o rÃµ rÃ ng cáº¥u trÃºc cá»§a nÃ³. NhÃ¬n vÃ o <code>LlamaTokenizer</code> trong v5, báº¡n cÃ³ thá»ƒ tháº¥y ngay:</p>
<ul>
<li><!-- raw HTML omitted -->NÃ³ sá»­ dá»¥ng <!-- raw HTML omitted -->BPE<!-- raw HTML omitted --><!-- raw HTML omitted --> lÃ m loáº¡i mÃ´ hÃ¬nh tokenization cá»§a nÃ³</li>
<li>NÃ³ cÃ³ thá»ƒ thÃªm má»™t <!-- raw HTML omitted -->tiá»n tá»‘ khoáº£ng tráº¯ng<!-- raw HTML omitted --> trÆ°á»›c vÄƒn báº£n</li>
<li>CÃ¡c token Ä‘áº·c biá»‡t cá»§a nÃ³ ( <code>unk</code>, <code>bos</code>, <code>eos</code>) náº±m á»Ÿ cÃ¡c vá»‹ trÃ­ bá»™ tá»« vá»±ng cá»¥ thá»ƒ</li>
<li><!-- raw HTML omitted -->NÃ³ <!-- raw HTML omitted -->khÃ´ng chuáº©n hÃ³a<!-- raw HTML omitted --><!-- raw HTML omitted --> vÄƒn báº£n Ä‘áº§u vÃ o</li>
<li><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->
<code>LlamaTokenizer</code> nhÆ° trong <code>transformers</code> v5</li>
</ul>
<p>Sá»± minh báº¡ch nÃ y lÃ  khÃ´ng thá»ƒ cÃ³ trong v4, nÆ¡i thÃ´ng tin tÆ°Æ¡ng tá»± Ä‘Æ°á»£c chÃ´n trong cÃ¡c tá»‡p Ä‘Æ°á»£c serialize.</p>
<h3 id="one-file-one-backend-one-recommended-path">One file, one backend, one recommended path</h3>
<p>V5 há»£p nháº¥t há»‡ thá»‘ng hai tá»‡p <!-- raw HTML omitted -->thÃ nh má»™t tá»‡p duy nháº¥t cho má»—i mÃ´ hÃ¬nh<!-- raw HTML omitted -->. <code>LlamaTokenizer</code> hiá»‡n káº¿ thá»«a tá»« <code>TokenizersBackend</code>, gÃ³i gá»n tokenizer dá»±a trÃªn Rust Ä‘Ã£ tá»«ng Ä‘Æ°á»£c hiá»ƒn thá»‹ dÆ°á»›i dáº¡ng triá»ƒn khai &ldquo;nhanh&rdquo; vÃ  hiá»‡n lÃ  máº·c Ä‘á»‹nh.</p>
<p>Triá»ƒn khai Python &ldquo;cháº­m&rdquo; trÆ°á»›c Ä‘Ã¢y náº±m rÃµ rÃ ng phÃ­a sau <code>PythonBackend</code>, vÃ  <code>SentencePieceBackend</code> váº«n dÃ nh cho cÃ¡c mÃ´ hÃ¬nh yÃªu cáº§u nÃ³, nhÆ°ng <!-- raw HTML omitted -->tokenization dá»±a trÃªn Rust lÃ  máº·c Ä‘á»‹nh Ä‘Æ°á»£c Æ°u tiÃªn<!-- raw HTML omitted -->.</p>
<p>Thay Ä‘á»•i nÃ y loáº¡i bá»:</p>
<ul>
<li>MÃ£ trÃ¹ng láº·p giá»¯a cÃ¡c triá»ƒn khai cháº­m/nhanh</li>
<li>Quy Æ°á»›c Ä‘áº·t tÃªn khÃ³ hiá»ƒu <code>Tokenizer</code> so vá»›i <code>TokenizerFast</code></li>
<li>Bá»™ kiá»ƒm thá»­ dÃ nh riÃªng Ä‘á»ƒ kiá»ƒm tra sá»± tÆ°Æ¡ng Ä‘Æ°Æ¡ng cháº­m-nhanh</li>
</ul>
<p>NgÆ°á»i dÃ¹ng hiá»‡n cÃ³ má»™t Ä‘iá»ƒm vÃ o rÃµ rÃ ng. NgÆ°á»i dÃ¹ng nÃ¢ng cao cáº§n tÃ¹y chá»‰nh váº«n cÃ³ thá»ƒ truy cáº­p cÃ¡c thÃ nh pháº§n cáº¥p tháº¥p hÆ¡n, nhÆ°ng thÆ° viá»‡n khÃ´ng cÃ²n buá»™c má»i ngÆ°á»i pháº£i Ä‘iá»u hÆ°á»›ng hai triá»ƒn khai song song ná»¯a.</p>
<h3 id="you-can-now-train-model-specific-tokenizers-from-scratch">You can now train model specific tokenizers from scratch</h3>
<p>Giáº£ sá»­ báº¡n muá»‘n má»™t tokenizer hoáº¡t Ä‘á»™ng giá»‘ng há»‡t nhÆ° cá»§a LLaMA â€“ cÃ¹ng má»™t chuáº©n hÃ³a, cÃ¹ng má»™t tiá»n xá»­ lÃ½, cÃ¹ng má»™t loáº¡i mÃ´ hÃ¬nh BPE â€“ nhÆ°ng Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t kho ngá»¯ liá»‡u dÃ nh riÃªng cho miá»n (vÄƒn báº£n y táº¿, tÃ i liá»‡u phÃ¡p lÃ½, má»™t ngÃ´n ngá»¯ má»›i). Trong v4, Ä‘iá»u nÃ y Ä‘Ã²i há»i pháº£i xÃ¢y dá»±ng láº¡i thá»§ cÃ´ng quy trÃ¬nh tokenizer tá»« cÃ¡c nguyÃªn táº¯c cÆ¡ báº£n cá»§a thÆ° viá»‡n <code>tokenizers</code> cáº¥p tháº¥p. Trong v5, báº¡n cÃ³ thá»ƒ khá»Ÿi táº¡o kiáº¿n trÃºc trá»±c tiáº¿p vÃ  gá»i <code>train</code>:</p>
<p>python
from transformers import LlamaTokenizer
from datasets import load_dataset</p>
<h1 id="khá»Ÿi-táº¡o-tokenizer-trá»‘ng-1">Khá»Ÿi táº¡o tokenizer trá»‘ng</h1>
<p>tokenizer = LlamaTokenizer()</p>
<p>dataset = load_dataset(&ldquo;wikitext&rdquo;, &ldquo;wikitext-2-raw-v1&rdquo;, split=&ldquo;train&rdquo;)</p>
<p>def get_training_corpus():
batch = 1000
for i in range(0, len(dataset), batch):
yield dataset[i : i + batch][&ldquo;text&rdquo;]</p>
<p>trained_tokenizer = tokenizer.train_new_from_iterator(
text_iterator=get_training_corpus(),
vocab_size=32000,
length=len(dataset),
show_progress=True,
)</p>
<p>trained_tokenizer.push_to_hub(&ldquo;my_custom_tokenizer&rdquo;)</p>
<p>tokenizer = LlamaTokenizer.from_pretrained(&ldquo;my_custom_tokenizer&rdquo;)</p>
<p>Tokenizer káº¿t quáº£ sáº½ cÃ³ bá»™ tá»« vá»±ng vÃ  quy táº¯c há»£p nháº¥t tÃ¹y chá»‰nh cá»§a báº¡n, nhÆ°ng sáº½ xá»­ lÃ½ vÄƒn báº£n giá»‘ng nhÆ° cÃ¡ch tokenizer LLaMA tiÃªu chuáº©n sáº½ lÃ m vá»›i cÃ¹ng xá»­ lÃ½ khoáº£ng tráº¯ng, cÃ¹ng quy Æ°á»›c token Ä‘áº·c biá»‡t, cÃ¹ng hÃ nh vi giáº£i mÃ£.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Aspect</th>
          <th style="text-align: left">V4</th>
          <th style="text-align: left">V5</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Files per model</td>
          <td style="text-align: left">Two (<code>tokenization_X.py</code>, <code>tokenization_X_fast.py</code>)</td>
          <td style="text-align: left">One (<code>tokenization_X.py</code>)</td>
      </tr>
      <tr>
          <td style="text-align: left">Default backend</td>
          <td style="text-align: left">Split between Python and Rust</td>
          <td style="text-align: left">Rust (<code>TokenizersBackend</code>) preferred</td>
      </tr>
      <tr>
          <td style="text-align: left">Architecture visibility</td>
          <td style="text-align: left">Hidden in serialized files</td>
          <td style="text-align: left">Explicit in class definition</td>
      </tr>
      <tr>
          <td style="text-align: left">Training from scratch</td>
          <td style="text-align: left">Required manual pipeline construction</td>
          <td style="text-align: left"><code>tokenizer.train(files=[...])</code></td>
      </tr>
      <tr>
          <td style="text-align: left">Component inspection</td>
          <td style="text-align: left">Difficult, undocumented</td>
          <td style="text-align: left">Direct properties (<code>tokenizer.normalizer</code>, etc.)</td>
      </tr>
      <tr>
          <td style="text-align: left">Parent classes</td>
          <td style="text-align: left"><code>PreTrainedTokenizer</code>, <code>PreTrainedTokenizerFast</code></td>
          <td style="text-align: left"><code>TokenizersBackend</code> (or <code>SentencePieceBackend</code>, <code>PythonBackend</code>)</td>
      </tr>
  </tbody>
</table>
<p>Sá»± chuyá»ƒn Ä‘á»•i tá»« &ldquo;tokenizer nhÆ° cÃ¡c checkpoint Ä‘Ã£ táº£i&rdquo; sang &ldquo;tokenizer nhÆ° cÃ¡c kiáº¿n trÃºc cÃ³ thá»ƒ cáº¥u hÃ¬nh&rdquo; lÃ m cho thÆ° viá»‡n trá»Ÿ nÃªn mÃ´-Ä‘un hÆ¡n, minh báº¡ch hÆ¡n vÃ  phÃ¹ há»£p hÆ¡n vá»›i cÃ¡ch cÃ¡c chuyÃªn gia nghÄ© vá» viá»‡c xÃ¢y dá»±ng há»‡ thá»‘ng ML.</p>
<h2 id="summary">Summary</h2>
<p>Transformers v5 mang láº¡i ba cáº£i tiáº¿n cho tokenization:</p>
<ol>
<li><!-- raw HTML omitted -->Má»™t tá»‡p cho má»—i mÃ´ hÃ¬nh<!-- raw HTML omitted --> thay vÃ¬ cÃ¡c triá»ƒn khai cháº­m/nhanh riÃªng biá»‡t</li>
<li><!-- raw HTML omitted -->Kiáº¿n trÃºc hiá»ƒn thá»‹<!-- raw HTML omitted --> Ä‘á»ƒ báº¡n cÃ³ thá»ƒ kiá»ƒm tra normalizer, pre-tokenizer vÃ  decoder</li>
<li><!-- raw HTML omitted -->CÃ¡c máº«u cÃ³ thá»ƒ huáº¥n luyá»‡n<!-- raw HTML omitted --> cho phÃ©p báº¡n táº¡o cÃ¡c tokenizer tÃ¹y chá»‰nh phÃ¹ há»£p vá»›i thiáº¿t káº¿ cá»§a báº¥t ká»³ mÃ´ hÃ¬nh nÃ o</li>
</ol>
<p>Lá»›p wrapper giá»¯a <code>tokenizers</code> vÃ  Transformers váº«n ráº¥t cáº§n thiáº¿t. NÃ³ bá»• sung nháº­n biáº¿t mÃ´ hÃ¬nh, Ä‘á»™ dÃ i ngá»¯ cáº£nh, máº«u chat, token Ä‘áº·c biá»‡t mÃ  tokenization thÃ´ khÃ´ng cung cáº¥p. V5 chá»‰ lÃ m cho lá»›p Ä‘Ã³ rÃµ rÃ ng hÆ¡n vÃ  cÃ³ thá»ƒ tÃ¹y chá»‰nh hÆ¡n.</p>
<p>Náº¿u báº¡n muá»‘n tÃ¬m hiá»ƒu thÃªm vá» tokenization, Ä‘Ã¢y lÃ  má»™t sá»‘ tÃ i nguyÃªn:</p>
<ul>
<li><a href="https://youtu.be/zduSFxRajkE?si=ZAfCjZjpyPHsnyfF">Let&rsquo;s build the GPT Tokenizer</a></li>
<li><a href="https://huggingface.co/blog/qgallouedec/gotchas-in-tokenizer-behavior">Gotchas in Tokenizer Behavior Every Developer Should Know</a></li>
<li><a href="https://huggingface.co/blog/chat-templates">Chat Templates</a></li>
<li><a href="#">A list of resources we have gathered from the community!</a></li>
</ul>
<h3 id="link-bÃ i-viáº¿t-gá»‘c"><a href="https://huggingface.co/blog/tokenizers">Link bÃ i viáº¿t gá»‘c</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/december-18-2025/">December 18, 2025</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-19/90cd1c/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="http://www.microsoft.com/en-us/ai/blog/wp-content/uploads/2025/12/Windows-FY25-COMMR-LENOVO-TEAM-02-387-RGB-1024x768.jpg" alt="Chuyá»ƒn Ä‘á»•i AI trong dá»‹ch vá»¥ tÃ i chÃ­nh- 5 yáº¿u tá»‘ dá»± bÃ¡o thÃ nh cÃ´ng vÃ o nÄƒm 2026" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-12-19T00:00:00&#43;00:00">Dec 19, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Chuyá»ƒn Ä‘á»•i AI trong dá»‹ch vá»¥ tÃ i chÃ­nh- 5 yáº¿u tá»‘ dá»± bÃ¡o thÃ nh cÃ´ng vÃ o nÄƒm 2026</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">CÃ¡c doanh nghiá»‡p dá»‹ch vá»¥ tÃ i chÃ­nh Ä‘ang tÃ­ch cá»±c Ã¡p dá»¥ng AI dá»±a trÃªn tÃ¡c nhÃ¢n, vá»›i cÃ¡c CÃ´ng ty TiÃªn phong dáº«n Ä‘áº§u cÃ´ng cuá»™c chuyá»ƒn Ä‘á»•i. DÆ°á»›i Ä‘Ã¢y lÃ  nÄƒm yáº¿u tá»‘ dá»± bÃ¡o quan trá»ng sáº½ táº¡o nÃªn sá»± khÃ¡c biá»‡t cho cÃ¡c nhÃ  lÃ£nh Ä‘áº¡o vÃ o nÄƒm 2026.</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-19/157e2a/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="http://cdn-uploads.huggingface.co/production/uploads/62d648291fa3e4e7ae3fa6e8/oatOwf8Xqe5eDbCSuYqCd.png" alt="Codex Ä‘ang mÃ£ hÃ³a nguá»“n má»Ÿ cÃ¡c mÃ´ hÃ¬nh AI" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-12-19T00:00:00&#43;00:00">Dec 19, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Codex Ä‘ang mÃ£ hÃ³a nguá»“n má»Ÿ cÃ¡c mÃ´ hÃ¬nh AI</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Codex Ä‘ang mÃ£ hÃ³a nguá»“n má»Ÿ cÃ¡c mÃ´ hÃ¬nh AI</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2026-02-19/e7afe6/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6e00dbffcddc82df5e471c43453abfc74ca94e8d-1000x1000.svg" alt="Anthropic vÃ  ChÃ­nh phá»§ Rwanda kÃ½ biÃªn báº£n ghi nhá»› vá» AI trong y táº¿ vÃ  giÃ¡o dá»¥c" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Anthropic vÃ  ChÃ­nh phá»§ Rwanda kÃ½ biÃªn báº£n ghi nhá»› vá» AI trong y táº¿ vÃ  giÃ¡o dá»¥c</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2026-02-19/eeb824/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/62d648291fa3e4e7ae3fa6e8/oatOwf8Xqe5eDbCSuYqCd.png" alt="CÃ¡c kernel CUDA tÃ¹y chá»‰nh cho táº¥t cáº£ má»i ngÆ°á»i tá»« Codex vÃ  Claude" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">CÃ¡c kernel CUDA tÃ¹y chá»‰nh cho táº¥t cáº£ má»i ngÆ°á»i tá»« Codex vÃ  Claude</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2026-02-19/f475e7/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://image-link" alt="Giá»›i thiá»‡u Claude Sonnet 4.6" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Giá»›i thiá»‡u Claude Sonnet 4.6</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2026-02-19/259694/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1624431552569-noauth.jpeg" alt="Gradio gr.HTML- Má»™t á»©ng dá»¥ng web chá»‰ vá»›i má»™t láº§n nháº¥n báº±ng cÃ¡ch sá»­ dá»¥ng gr.HTML" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Gradio gr.HTML- Má»™t á»©ng dá»¥ng web chá»‰ vá»›i má»™t láº§n nháº¥n báº±ng cÃ¡ch sá»­ dá»¥ng gr.HTML</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2026-02-19/916c74/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/637bfdf60dc13843b468ac20/npxapKcW-cXX3J2JBl2vY.png" alt="IBM vÃ  UC Berkeley cháº©n Ä‘oÃ¡n lÃ½ do cÃ¡c tÃ¡c nhÃ¢n doanh nghiá»‡p tháº¥t báº¡i báº±ng cÃ¡ch sá»­ dá»¥ng IT-Bench vÃ  MAST" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">IBM vÃ  UC Berkeley cháº©n Ä‘oÃ¡n lÃ½ do cÃ¡c tÃ¡c nhÃ¢n doanh nghiá»‡p tháº¥t báº¡i báº±ng cÃ¡ch sá»­ dá»¥ng IT-Bench vÃ  MAST</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo dÃµi cÃ¡c tiáº¿n bá»™ má»›i nháº¥t vá» TrÃ­ tuá»‡ nhÃ¢n táº¡o.<br>Trá»±c tiáº¿p tá»« cÃ¡c nhÃ  phÃ¡t hÃ nh AI trÃªn tháº¿ giá»›i.
      </p>

      <p>Äem trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘áº¿n má»i ngÆ°á»i dÃ¢n, doanh nghiá»‡p Viá»‡t, gÃ³p pháº§n giÃºp Viá»‡t Nam phÃ¡t triá»ƒn máº¡nh máº½ trong ká»· nguyÃªn sá»‘. Ná»™i dung Ä‘Æ°á»£c cáº­p nháº­t tá»± Ä‘á»™ng báº±ng mÃ¡y.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright Â© 2026. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>