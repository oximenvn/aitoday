<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Căn chỉnh Mô hình Ngôn ngữ Thị giác trong TRL ⚡️ | AI Today - SkyAI</title>

<meta name="description" content="">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">Căn chỉnh Mô hình Ngôn ngữ Thị giác trong TRL ⚡️</h1>

      <div id="lead" class="my-6">

        <p class="font-bold"> </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-08-07T00:00:00&#43;00:00">August 7, 2025</time>
          </li>

          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2">
            15 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://huggingface.co/blog/assets/trl_vlm/thumbnail.png" alt="Căn chỉnh Mô hình Ngôn ngữ Thị giác trong TRL ⚡️">
        <figcaption class="text-center italic text-xs"></figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="căn-chỉnh-mô-hình-ngôn-ngữ-thị-giác-trong-trl-">Căn chỉnh Mô hình Ngôn ngữ Thị giác trong TRL ⚡️</h1>
<p>Bài viết này hướng dẫn cách căn chỉnh (alignment) các mô hình ngôn ngữ thị giác (VLMs) theo sở thích của con người, sử dụng các phương pháp mới được thêm vào thư viện TRL (Transformer Reinforcement Learning).</p>
<p><strong>Tóm tắt:</strong> TRL bổ sung hai phương pháp căn chỉnh đa phương thức mới: Tối ưu hóa Chính sách Tương đối theo Nhóm (GRPO), biến thể Tối ưu hóa Chính sách Chuỗi theo Nhóm (GSPO) và Tối ưu hóa Ưu tiên Hỗn hợp (MPO). Các phương pháp này giúp khai thác nhiều tín hiệu hơn từ dữ liệu sở thích và mở rộng quy mô tốt hơn với VLMs hiện đại. Bài viết cung cấp các tập lệnh huấn luyện và sổ tay demo để bắt đầu sử dụng chúng một cách dễ dàng.</p>
<h2 id="mục-lục">Mục lục</h2>
<ul>
<li><a href="#introduction">Giới thiệu</a></li>
<li><a href="#alignment-for-vision-language-models">Căn chỉnh cho Mô hình Ngôn ngữ Thị giác</a>
<ul>
<li><a href="#mixed-preference-optimization-mpo">Tối ưu hóa Ưu tiên Hỗn hợp (MPO)</a></li>
<li><a href="#multimodal-group-relative-policy-optimization-grpo">Tối ưu hóa Chính sách Tương đối theo Nhóm Đa phương thức (GRPO)</a></li>
<li><a href="#group-sequence-policy-optimization-gspo">Tối ưu hóa Chính sách Chuỗi theo Nhóm (GSPO)</a></li>
<li><a href="#comparison">So sánh</a></li>
</ul>
</li>
<li><a href="#vllm-integration-in-trl">Tích hợp vLLM trong TRL</a></li>
<li><a href="#useful-resources">Tài nguyên Hữu ích</a></li>
</ul>
<h2 id="giới-thiệu">Giới thiệu</h2>
<p>Các Mô hình Ngôn ngữ Thị giác (VLMs) ngày càng mạnh mẽ, nhưng việc <strong>căn chỉnh</strong> chúng theo sở thích của con người vẫn rất quan trọng. Trong TRL, bài viết đã trình bày cách tinh chỉnh VLMs sau huấn luyện với <strong>Tinh chỉnh có Giám sát (SFT)</strong> và <strong>Tối ưu hóa Ưu tiên Trực tiếp (DPO)</strong>.</p>
<p><strong>tl;dr</strong> Bài viết đã thêm hai phương pháp căn chỉnh đa phương thức mới vào TRL: <strong>Tối ưu hóa Chính sách Tương đối theo Nhóm (GRPO)</strong>, biến thể của nó <strong>Tối ưu hóa Chính sách Chuỗi theo Nhóm (GSPO)</strong> và <strong>Tối ưu hóa Ưu tiên Hỗn hợp (MPO)</strong>. Tất cả chúng cho phép bạn vượt ra ngoài DPO theo cặp, trích xuất nhiều tín hiệu hơn từ dữ liệu sở thích và mở rộng quy mô tốt hơn với VLMs hiện đại. Chúng tôi phát hành các tập lệnh huấn luyện và sổ tay demo để dễ dàng bắt đầu với chúng!</p>
<h2 id="căn-chỉnh-cho-mô-hình-ngôn-ngữ-thị-giác">Căn chỉnh cho Mô hình Ngôn ngữ Thị giác</h2>
<p>Theo truyền thống, bạn sẽ lấy một mô hình cơ sở, áp dụng SFT để tuân theo hướng dẫn, sau đó áp dụng DPO để căn chỉnh nó với dữ liệu ưu tiên. Trước đây, chúng tôi đã điều chỉnh phương pháp này cho Mô hình Ngôn ngữ Thị giác (VLMs) và xác thực nó trên IDEFICS2, cho thấy sự cải thiện trong phản hồi của mô hình.</p>
<p>DPO hoạt động bằng cách tối ưu hóa các ưu tiên giữa các cặp phản hồi của mô hình bằng cách sử dụng một hàm mất mát tương phản: bạn có một câu trả lời được chọn và một câu trả lời bị từ chối và bạn tối ưu hóa các ưu tiên của mình dựa trên những gì bạn muốn và không muốn.</p>
<p>Nhưng trong năm qua, các phương pháp căn chỉnh đa phương thức mới đã trở nên phổ biến, GRPO và MPO, có thể đẩy hiệu suất VLM đi xa hơn nữa. Ở cuối bài đăng trên blog, bạn có thể tìm thấy một bảng hiển thị sự khác biệt giữa các phản hồi của mô hình.</p>
<h3 id="tối-ưu-hóa-ưu-tiên-hỗn-hợp-mpo">Tối ưu hóa Ưu tiên Hỗn hợp (MPO)</h3>
<p>Việc căn chỉnh các mô hình đa phương thức với SFT để thực hiện các tác vụ suy luận còn thiếu sót do sự thay đổi phân phối. Trong khi đó, các mô hình được căn chỉnh với DPO không tạo ra các lý lẽ mạch lạc và có thể tạo ra các phản hồi lặp đi lặp lại. Để giải quyết vấn đề này, có một kỹ thuật mới gọi là <a href="https://huggingface.co/papers/2411.10442">Tối ưu hóa Ưu tiên Hỗn hợp</a> (MPO) được tạo ra đặc biệt cho các mô hình đa phương thức. Phương pháp này về cơ bản là một phần mở rộng của DPO với nhiều tổn thất: mất mát ưu tiên từ DPO (sigmoid), mất mát chất lượng từ Tối ưu hóa Bộ phân loại nhị phân (BCO) và mất mát tạo ra từ SFT. Theo <a href="https://huggingface.co/papers/2411.10442">bài báo</a>, chỉ cần chuyển sang tổn thất kết hợp này sẽ giúp cải thiện 6,2 điểm trong MathVista!</p>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/trl-vlm/image_1.png"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/trl-vlm/image_1.png" alt="MPO"></a></p>
<p>Vì điều này chỉ sửa đổi tổn thất, nên chúng tôi đã thêm hỗ trợ tổn thất kết hợp vào lớp <code>DPOTrainer</code> của TRL. Để sử dụng nó, bạn có thể khởi tạo <code>DPOConfig</code> như sau:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>mpo_config <span style="color:#f92672">=</span> DPOConfig(
</span></span><span style="display:flex;"><span>    output_dir<span style="color:#f92672">=</span>tmp_dir,
</span></span><span style="display:flex;"><span>    per_device_train_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">9e-1</span>,
</span></span><span style="display:flex;"><span>    loss_type<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;sigmoid&#34;</span>, <span style="color:#e6db74">&#34;bco_pair&#34;</span>, <span style="color:#e6db74">&#34;sft&#34;</span>], <span style="color:#75715e"># Các loại tổn thất để kết hợp, như được sử dụng trong bài báo MPO</span>
</span></span><span style="display:flex;"><span>    loss_weights<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">1.0</span>], <span style="color:#75715e"># Trọng số tương ứng, như được sử dụng trong bài báo MPO</span>
</span></span><span style="display:flex;"><span>    report_to<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;none&#34;</span>,
</span></span><span style="display:flex;"><span>    bf16<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    fp16<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    use_cpu<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    max_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>Sau đó, khởi tạo <code>DPOTrainer</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>mpo_trainer <span style="color:#f92672">=</span> DPOTrainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model_id,
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>mpo_config,
</span></span><span style="display:flex;"><span>    processing_class<span style="color:#f92672">=</span>tokenizer,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>dataset,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>mpo_trainer<span style="color:#f92672">.</span>train()
</span></span></code></pre></div><p>Chỉ có vậy thôi! Nếu bạn muốn khám phá thêm, bạn có thể tìm thấy một ví dụ về sổ tay hoàn chỉnh <a href="https://huggingface.co/learn/cookbook/fine_tuning_vlm_mpo">tại đây</a>.</p>
<h3 id="tối-ưu-hóa-chính-sách-tương-đối-theo-nhóm-đa-phương-thức-grpo">Tối ưu hóa Chính sách Tương đối theo Nhóm Đa phương thức (GRPO)</h3>
<p>Tối ưu hóa Chính sách Tương đối theo Nhóm (GRPO) là một phương pháp căn chỉnh tiên tiến ban đầu được giới thiệu trong <a href="https://huggingface.co/papers/2402.03300">bài báo DeepSeek Math</a> và sau đó được tích hợp vào DeepSeek R1, LLM đột phá. Đây là một bổ sung cho PPO, nơi các cập nhật chính sách được thực hiện trên các nhóm (lô quỹ đạo đại diện cho cách một cuộc đối thoại diễn ra). Tính năng này làm cho nó mạnh mẽ hơn đối với nhiễu phần thưởng, vì nhiễu được tính trung bình trong các nhóm. Vì mô hình học được ý nghĩa rộng hơn của một phản hồi tốt hơn là các mẫu phần thưởng cao đơn lẻ, phương pháp này cũng làm cho mô hình có hiệu suất cao.</p>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/trl-vlm/image_2.png"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/trl-vlm/image_2.png" alt="GRPO"></a></p>
<p>Trong TRL, chúng tôi hiện giới thiệu hỗ trợ GRPO cho các mô hình ngôn ngữ thị giác. Chúng tôi sẽ không cung cấp một ví dụ tập lệnh huấn luyện đầy đủ, vì bạn có thể tìm thấy nó trong sổ tay. Thay vào đó, chúng tôi sẽ tập trung vào việc làm nổi bật thành phần và khái niệm chính.</p>
<p>Để làm cho tập lệnh huấn luyện hoạt động hiệu quả, chúng ta cần xác thực rằng định dạng của câu trả lời là chính xác và bản thân giải pháp gần với các phần đã hoàn thành, vì vậy chúng ta viết hai hàm phần thưởng. Để thực sự thấy sự cải thiện trong phần thưởng sau, bạn sẽ cần một thiết lập tối đa, nơi bạn có các mô hình tương đối lớn hơn, rất nhiều thế hệ và một tập dữ liệu đa dạng, chất lượng cao.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> math_verify <span style="color:#f92672">import</span> LatexExtractionConfig, parse, verify
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">format_reward</span>(completions, <span style="color:#f92672">**</span>kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Hàm phần thưởng kiểm tra xem phần hoàn thành có định dạng cụ thể hay không.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    pattern <span style="color:#f92672">=</span> <span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;^&lt;think&gt;.*?&lt;\/think&gt;\s*&lt;answer&gt;.*?&lt;\/answer&gt;$&#34;</span>
</span></span><span style="display:flex;"><span>    matches <span style="color:#f92672">=</span> [re<span style="color:#f92672">.</span><span style="color:#66d9ef">match</span>(pattern, content) <span style="color:#66d9ef">for</span> content <span style="color:#f92672">in</span> completions]
</span></span><span style="display:flex;"><span>    rewards_list <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1.0</span> <span style="color:#66d9ef">if</span> <span style="color:#66d9ef">match</span> <span style="color:#66d9ef">else</span> <span style="color:#ae81ff">0.0</span> <span style="color:#66d9ef">for</span> <span style="color:#66d9ef">match</span> <span style="color:#f92672">in</span> matches]
</span></span><span style="display:flex;"><span>    rewards <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1.0</span> <span style="color:#66d9ef">if</span> <span style="color:#66d9ef">match</span> <span style="color:#66d9ef">else</span> <span style="color:#ae81ff">0.0</span> <span style="color:#66d9ef">for</span> <span style="color:#66d9ef">match</span> <span style="color:#f92672">in</span> matches]
</span></span><span style="display:flex;"><span>    print(completions)
</span></span><span style="display:flex;"><span>    print(rewards)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> rewards
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">accuracy_reward</span>(completions, <span style="color:#f92672">**</span>kwargs):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Hàm phần thưởng kiểm tra xem phần hoàn thành có giống với sự thật cơ bản hay không.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    solutions <span style="color:#f92672">=</span> kwargs[<span style="color:#e6db74">&#39;solution&#39;</span>]
</span></span><span style="display:flex;"><span>    completion_contents <span style="color:#f92672">=</span> [completion[<span style="color:#ae81ff">0</span>][<span style="color:#e6db74">&#34;content&#34;</span>] <span style="color:#66d9ef">for</span> completion <span style="color:#f92672">in</span> completions]
</span></span><span style="display:flex;"><span>    rewards <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> content, solution <span style="color:#f92672">in</span> zip(completion_contents, solutions):
</span></span><span style="display:flex;"><span>        gold_parsed <span style="color:#f92672">=</span> parse(solution, extraction_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;first_match&#34;</span>, extraction_config<span style="color:#f92672">=</span>[LatexExtractionConfig()])
</span></span><span style="display:flex;"><span>        answer_parsed <span style="color:#f92672">=</span> parse(content, extraction_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;first_match&#34;</span>, extraction_config<span style="color:#f92672">=</span>[LatexExtractionConfig()])
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(gold_parsed) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>                rewards<span style="color:#f92672">.</span>append(float(verify(answer_parsed, gold_parsed)))
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
</span></span><span style="display:flex;"><span>                rewards<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">0.0</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            rewards<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> rewards
</span></span></code></pre></div><p>Sau đó, bạn có thể khởi tạo GRPOConfig và GRPOTrainer, chuyển vào các hàm phần thưởng mà chúng tôi đã xác định ở trên và gọi train() để bắt đầu huấn luyện.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> trl <span style="color:#f92672">import</span> GRPOConfig
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args <span style="color:#f92672">=</span> GRPOConfig(
</span></span><span style="display:flex;"><span>    learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-5</span>,
</span></span><span style="display:flex;"><span>    remove_unused_columns<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    max_prompt_length<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">..</span> <span style="color:#75715e"># thiết lập các tham số khác mà bạn chọn ở đây</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> GRPOTrainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>    reward_funcs<span style="color:#f92672">=</span>[format_reward, accuracy_reward],
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>training_args,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>train_dataset,
</span></span><span style="display:flex;"><span>    processing_class<span style="color:#f92672">=</span>processor
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>train()
</span></span></code></pre></div><p>Khám phá ví dụ sổ tay đầy đủ <a href="https://huggingface.co/learn/cookbook/fine_tuning_vlm_grpo_trl">tại đây</a>.</p>
<h3 id="tối-ưu-hóa-chính-sách-chuỗi-theo-nhóm-gspo">Tối ưu hóa Chính sách Chuỗi theo Nhóm (GSPO)</h3>
<p><a href="https://huggingface.co/papers/2507.18071">Tối ưu hóa Chính sách Chuỗi theo Nhóm</a> (GSPO) là một thuật toán căn chỉnh RL gần đây được Qwen phát hành để khắc phục một số hạn chế của GRPO. Nó đạt được một tầm quan trọng tính toán huấn luyện ổn định hơn bằng cách lấy mẫu trọng số ở cấp chuỗi thay vì mỗi mã thông báo. Lợi ích của nó <a href="https://github.com/volcengine/verl/pull/2775#issuecomment-3134375131">liên quan hơn</a> trong các mô hình kiểu MoE.</p>
<p>TRL mới nhất cũng giới thiệu hỗ trợ cho GSPO và vì nó là một biến thể của mất mát GRPO, nó đi kèm với hỗ trợ đa phương thức. Để tạo huấn luyện viên, quy trình giống như với GRPO, nhưng thêm các tham số bổ sung sau (giá trị được trích xuất từ bài báo).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> trl <span style="color:#f92672">import</span> GRPOConfig
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args <span style="color:#f92672">=</span> GRPOConfig(
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">...</span>
</span></span><span style="display:flex;"><span>    importance_sampling_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sequence&#34;</span>,
</span></span><span style="display:flex;"><span>    epsilon<span style="color:#f92672">=</span><span style="color:#ae81ff">3e-4</span>,
</span></span><span style="display:flex;"><span>    epsilon_high<span style="color:#f92672">=</span><span style="color:#ae81ff">4e-4</span>,
</span></span><span style="display:flex;"><span>    beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>,
</span></span><span style="display:flex;"><span>    loss_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;grpo&#34;</span>,
</span></span><span style="display:flex;"><span>    steps_per_generation<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>    steps_per_generation<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="so-sánh">So sánh</h3>
<p>Dưới đây là bảng tóm tắt các kết quả đầu ra của mô hình cho Qwen2.5VL-3B được tinh chỉnh với các kỹ thuật được thảo luận ở trên. Lưu ý rằng chúng tôi đã thực hiện các lần chạy tối thiểu trên các tập hợp con của bộ dữ liệu và các mô hình được tinh chỉnh trên các bộ dữ liệu khác nhau, vì vậy so sánh được thực hiện để kiểm tra rung cảm.</p>
<!-- raw HTML omitted -->
<p><strong>Hình ảnh:</strong> <a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vlm_math_question.png">[Ảnh]</a></p>
<p><strong>Câu hỏi:</strong> Trong hình đã cho, nếu góc APO là 25,0 độ, thì số đo của góc AOB là bao nhiêu? Các lựa chọn: A: 140° B: 130° C: 120° D: 110°</p>
<p><strong>Câu trả lời trong Bộ dữ liệu:</strong> Để tìm số đo của góc AOB, chúng ta có thể sử dụng thuộc tính tổng của các góc bên trong của một tứ giác bằng 360 độ. Áp dụng thuộc tính này, chúng ta có thể tính góc AOB là 360 - góc OAP - góc OBP - góc P. Vì góc OAP và góc OBP đều là 90 độ và góc P được cho là 50 độ, chúng ta có thể thay thế các giá trị này vào phương trình để có góc AOB = 360 - 90 - 90 - 50 = 130 độ. Do đó, số đo của góc AOB là 130 độ. Do đó, câu trả lời là lựa chọn B. Câu trả lời: B</p>
<p><strong>Kết quả đầu ra của Mô hình Cơ sở:</strong> Để tìm số đo của góc AOB, chúng ta cần sử dụng các thuộc tính của các góc được tạo bởi cùng một cung trong một vòng tròn. Cụ thể, góc được tạo bởi một cung tại tâm của vòng tròn (góc AOB) gấp đôi góc được tạo bởi cùng một cung tại bất kỳ điểm nào trên chu vi (góc APO). Cho rằng góc APO = 25°, chúng ta có thể tính góc AOB như sau: Vì góc AOB gấp đôi góc APO, chúng ta có: [ Góc AOB = 2 * Góc APO ] [ Góc AOB = 2 * 25° ] [ Góc AOB = 50° ] Tuy nhiên, phép tính này dường như không chính xác dựa trên các lựa chọn đã cho. Hãy đánh giá lại bằng cách sử dụng thuộc tính chính xác. Thuộc tính chính xác nói rằng góc được tạo bởi một cung tại tâm của vòng tròn gấp đôi góc được tạo bởi cùng một cung tại bất kỳ điểm nào trên chu vi. Do đó, phép tính chính xác phải là: Góc AOB = 2 * Góc APO = 2 * 25° = 50° Nhưng vì điều này không khớp với các lựa chọn đã cho, hãy xem xét một cách tiếp cận khác. Nếu góc APO là 25° và xem xét các thuộc tính của tứ giác tuần hoàn hoặc thực tế là tổng của các góc đối diện trong một tứ giác tuần hoàn là 180°, chúng ta có thể cần xem xét các góc bù được tạo bởi cung và dây cung. Hãy giả sử rằng cách diễn giải chính xác liên quan đến việc tìm góc bù cho góc APO đã cho, điều này sẽ cho chúng ta số đo của góc AOB. Góc AOB = 180° - Góc APO = 180° - 25° = 155° Điều này vẫn không khớp với các lựa chọn. Với các lựa chọn đã cho, có vẻ như có thể có một sự hiểu lầm hoặc cần một cách diễn giải khác. Tuy nhiên, dựa trên các nguyên tắc hình học tiêu chuẩn, câu trả lời chính xác phải là: Góc AOB = 2 * Góc APO = 2 * 25° = 50° Nếu không phải như vậy, vui lòng cung cấp thêm ngữ cảnh hoặc làm rõ tuyên bố vấn đề.</p>
<p><strong>Kết quả đầu ra của MPO:</strong> Để tìm số đo của góc AOB, chúng ta cần sử dụng các thuộc tính của các góc được tạo bởi cùng một cung trong một vòng tròn. Cụ thể, góc được tạo bởi một cung tại tâm của vòng tròn (góc AOB) gấp đôi góc được tạo bởi cùng một cung tại bất kỳ điểm nào trên chu vi (góc APO). Cho rằng góc APO = 25°, chúng ta có thể tính góc AOB như sau: Vì góc AOB gấp đôi góc APO, chúng ta có: [ Góc AOB = 2 * Góc APO ] [ Góc AOB = 2 * 25° ] [ Góc AOB = 50° ] Tuy nhiên, phép tính này dường như không chính xác dựa trên các lựa chọn đã cho. Hãy đánh giá lại bằng cách sử dụng thuộc tính chính xác. Thuộc tính chính xác nói rằng góc được tạo bởi một cung tại tâm của vòng tròn gấp đôi góc được tạo bởi cùng một cung tại bất kỳ điểm nào trên chu vi. Do đó, phép tính chính xác phải là: Góc AOB = 2 * Góc APO = 2 * 25° = 50° Nhưng vì điều này không khớp với các lựa chọn đã cho, hãy xem xét một cách tiếp cận khác. Nếu chúng ta nhìn vào tam giác OAP, góc AOP là 90° vì nó là một góc vuông (vì nó được nội tiếp trong một nửa vòng tròn). Bây giờ, góc APO được cho là 25°, vì vậy góc AOA sẽ là 65° (vì nó bù cho góc APO). Do đó, góc AOB sẽ là một nửa số này, tức là 32,5°. Tuy nhiên, điều này cũng không khớp với các lựa chọn. Hãy xem xét khả năng rằng vấn đề có thể liên quan đến một cách diễn giải khác hoặc một cấu hình hình học khác. Với các lựa chọn đã cho, hãy giả sử rằng có thể có một sai sót trong tuyên bố vấn đề hoặc bản thân các lựa chọn. Nếu chúng ta phải chọn từ các tùy chọn đã cho, thì không có tùy chọn nào dường như phù hợp một cách chính xác dựa trên các nguyên tắc hình học tiêu chuẩn cho loại vấn đề này.</p>
<p><strong>Kết quả đầu ra của GRPO:</strong> Để tìm số đo của góc AOB, chúng ta cần hiểu rằng góc AOB là một góc nội tiếp tạo cùng một cung với góc trung tâm AOP. Theo Định lý góc nội tiếp, số đo của một góc nội tiếp bằng một nửa số đo của góc trung tâm tạo cùng một cung. Cho: - Góc APO = 25,0 độ Vì góc AOB là một góc nội tiếp tạo cùng một cung với góc trung tâm AOP, chúng ta có thể sử dụng Định lý góc nội tiếp: Số đo của góc AOB bằng một nửa số đo của góc AOP. Do đó, số đo của góc AOB là 130 độ.</p>
<p><strong>Kết quả đầu ra của GSPO:</strong> Để tìm số đo của góc AOB, chúng ta cần hiểu rằng góc AOB là một góc nội tiếp tạo cùng một cung với góc trung tâm AOP. Theo Định lý góc nội tiếp, số đo của một góc nội tiếp bằng một nửa số đo của góc trung tâm tạo cùng một cung. Cho: - Góc APO = 25,0 độ Vì góc AOB là một góc nội tiếp tạo cùng một cung với góc trung tâm AOP, chúng ta có thể sử dụng Định lý góc nội tiếp để tìm số đo của góc AOB: Số đo của góc AOB bằng một nửa số đo của góc AOP. Do đó, câu trả lời là B: 130°.</p>
<!-- raw HTML omitted -->
<h2 id="tích-hợp-vllm-trong-trl">Tích hợp vLLM trong TRL</h2>
<p>vLLM được tích hợp trong TRL để hỗ trợ các phương pháp căn chỉnh trực tuyến, nơi bạn cần tạo các mẫu trong quá trình huấn luyện. Chạy các tập lệnh ví dụ như sau cho phép vLLM:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>CUDA_VISIBLE_DEVICES<span style="color:#f92672">=</span>1,2 python3 examples/scripts/grpo_vlm.py --model_name_or_path Qwen/Qwen2.5-VL-3B-Instruct … --log_completions —use_vllm —vlm_mode colocate
</span></span></code></pre></div><p>Chủ yếu có hai chế độ: <code>colocate</code> và <code>server</code>. <a href="https://huggingface.co/blog/vllm-colocate"><code>colocate</code></a> chạy vLLM trong cùng một quy trình với vòng lặp huấn luyện, chia sẻ cùng một GPU giữa quá trình huấn luyện và tạo, tạo một phiên bản vLLM LLM bên trong <code>GRPOTrainer</code>. Trong khi đó, <code>server</code> yêu cầu bạn phục vụ vLLM riêng biệt trong một quy trình khác, nơi bạn có thể truy cập máy chủ. Bạn có thể khởi động máy chủ này bằng lệnh:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>trl vllm-serve --model Qwen/Qwen2.5-VL-3B-Instruct --tensor-parallel-size <span style="color:#ae81ff">1</span>
</span></span></code></pre></div><p>Sau đó, bạn có thể chạy tập lệnh như sau.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>CUDA_VISIBLE_DEVICES<span style="color:#f92672">=</span>1,2 python3 examples/scripts/grpo_vlm.py --model_name_or_path Qwen/Qwen2.5-VL-3B-Instruct … --log_completions —use_vllm —vlm_mode server
</span></span></code></pre></div><p>Một mẹo khác: chúng tôi đã thêm hỗ trợ sử dụng vLLM với phần phụ trợ transformers trong TRL. Bạn có thể bật nó khi chạy một tập lệnh với colocate hoặc khi phục vụ mô hình bằng cách chuyển cờ <code>--vllm_model_impl transformers</code>.</p>
<p>Bạn có thể đọc thêm về tích hợp vLLM trong TRL <a href="https://huggingface.co/docs/trl/en/vllm_integration">tại đây</a>.</p>
<h2 id="tài-nguyên-hữu-ích">Tài nguyên Hữu ích</h2>
<p>Dưới đây, bạn có thể tìm thấy một bản tổng hợp các tài nguyên để khám phá chi tiết việc căn chỉnh VLMs. Chúc bạn vui vẻ!</p>
<ul>
<li><a href="https://huggingface.co/blog/vlms-2025"><strong>Mô hình Ngôn ngữ Thị giác (Tốt hơn, Nhanh hơn, Mạnh hơn)</strong></a></li>
<li><a href="https://huggingface.co/papers/2411.10442"><strong>Nâng cao Khả năng Suy luận của Mô hình Ngôn ngữ Lớn Đa phương thức thông qua Tối ưu hóa Ưu tiên Hỗn hợp</strong></a> (<strong>bài báo MPO</strong>)</li>
<li><a href="https://huggingface.co/papers/2402.03300"><strong>DeepSeekMath: Đẩy Giới hạn của Suy luận Toán học trong Mô hình Ngôn ngữ Mở</strong></a> (<strong>bài báo GRPO</strong>)</li>
<li><a href="https://github.com/huggingface/open-r1"><strong>Kho lưu trữ Open-R1</strong></a> và <a href="https://github.com/huggingface/open-r1/blob/main/src/open_r1/rewards.py"><strong>các hàm phần thưởng Open-R1</strong></a></li>
<li><a href="https://huggingface.co/docs/trl/en/index"><strong>Tài liệu TRL</strong></a> và <a href="https://github.com/huggingface/trl"><strong>kho lưu trữ TRL</strong></a></li>
<li><a href="https://huggingface.co/learn/cookbook/fine_tuning_vlm_mpo"><strong>Công thức MPO VLM</strong></a></li>
<li><a href="https://huggingface.co/learn/cookbook/fine_tuning_vlm_grpo_trl"><strong>Công thức GRPO VLM</strong></a></li>
<li><a href="https://huggingface.co/learn/cookbook/index"><strong>Nhiều công thức căn chỉnh đa phương thức hơn</strong></a></li>
<li><a href="https://github.com/huggingface/trl/tree/main/examples/scripts"><strong>Tập lệnh huấn luyện đa phương thức TRL</strong></a></li>
<li><a href="https://huggingface.co/docs/trl/en/vllm_integration"><strong>Tài liệu về tích hợp vLLM trong trl</strong></a></li>
<li><a href="https://blog.vllm.ai/2025/04/11/transformers-backend.html"><strong>Tích hợp phụ trợ Transformers trong vLLM</strong></a></li>
</ul>
<h3 id="link-bài-viết-gốc"><a href="https://huggingface.co/blog/trl-vlm-alignment">Link bài viết gốc</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/august-7-2025/">August 7, 2025</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-07-31/e31907/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/gradio-vton-mcp/AiAssistantTitle.png" alt="Xây dựng một trợ lý mua sắm AI với máy chủ Gradio MCP" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-07-31T00:00:00&#43;00:00">Jul 31, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Xây dựng một trợ lý mua sắm AI với máy chủ Gradio MCP</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2"></p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-07-30/79efb1/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/trackio/thumbnail.gif" alt="Giới thiệu Trackio- Một thư viện theo dõi thử nghiệm nhẹ từ Hugging Face" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-07-30T00:00:00&#43;00:00">Jul 30, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Giới thiệu Trackio- Một thư viện theo dõi thử nghiệm nhẹ từ Hugging Face</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Giới thiệu Trackio- Một thư viện theo dõi thử nghiệm nhẹ từ Hugging Face</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-10/883183/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">AI21’s Jamba Reasoning 3B tái định nghĩa &#39;Nhỏ&#39; có nghĩa là gì trong LLM — Bối cảnh 250K trên Máy tính xách tay</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-09/6ac862/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://lh3.googleusercontent.com/ka2UHKqEKG1GR8w-QqBLkIN48VBUClMsw8yo_ACI1vrofXyAKBd4QrcDyiIVdBu2V2S9o5tpMQL8Fi68ec4Y8CErz0CV4oTkl2RicrYl9q2pyDhz=w400-h225-n-nu" alt="Giới thiệu Mô hình Sử dụng Máy tính Gemini 2.5" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Giới thiệu Mô hình Sử dụng Máy tính Gemini 2.5</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-09/c7db8f/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/5f455d24ea80569b34eb4347f06152d8a5508722-1000x1000.svg" alt="Mở rộng hoạt động toàn cầu sang Ấn Độ với văn phòng thứ hai tại khu vực Châu Á Thái Bình Dương" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Mở rộng hoạt động toàn cầu sang Ấn Độ với văn phòng thứ hai tại khu vực Châu Á Thái Bình Dương</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-09/8931a6/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www.anthropic.com" alt="Rahul Patil gia nhập Anthropic với vai trò Giám đốc Công nghệ" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Rahul Patil gia nhập Anthropic với vai trò Giám đốc Công nghệ</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-07/10ab20/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://lh3.googleusercontent.com/fnAx6nksgsvTcj5EDj7bx1yD8sMXwfkBnR6vla-e-h4wZSKFI3a1nFftGvDYyJAk01ZzNr2-QJyqfw30V2_tcp6tE-udCtMCuyou9cBIHyxGnO_mtQ=w400-h225-n-nu" alt="Giới thiệu CodeMender- một tác nhân AI để bảo mật mã" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Giới thiệu CodeMender- một tác nhân AI để bảo mật mã</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo dõi các tiến bộ mới nhất về Trí tuệ nhân tạo.<br>Trực tiếp từ các nhà phát hành AI trên thế giới.
      </p>

      <p>Đem trí tuệ nhân tạo đến mọi người dân, doanh nghiệp Việt, góp phần giúp Việt Nam phát triển mạnh mẽ trong kỷ nguyên số. Nội dung được cập nhật tự động bằng máy.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright © 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>