<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>N√¢ng cao m√¥ h√¨nh c·ªßa b·∫°n trong 5 ph√∫t v·ªõi Hugging Face Kernel Hub | AI Today - SkyAI</title>

<meta name="description" content="T√¨m hi·ªÉu c√°ch tƒÉng t·ªëc quy tr√¨nh l√†m vi·ªác c·ªßa b·∫°n b·∫±ng c√°ch s·ª≠ d·ª•ng m√¥i tr∆∞·ªùng m√£ h√≥a d·ª±a tr√™n ƒë√°m m√¢y, t√≠ch h·ª£p v√† c√≥ th·ªÉ nh√¢n r·ªông.">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['‚ùØ'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['‚ùØ'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">N√¢ng cao m√¥ h√¨nh c·ªßa b·∫°n trong 5 ph√∫t v·ªõi Hugging Face Kernel Hub</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">T√¨m hi·ªÉu c√°ch tƒÉng t·ªëc quy tr√¨nh l√†m vi·ªác c·ªßa b·∫°n b·∫±ng c√°ch s·ª≠ d·ª•ng m√¥i tr∆∞·ªùng m√£ h√≥a d·ª±a tr√™n ƒë√°m m√¢y, t√≠ch h·ª£p v√† c√≥ th·ªÉ nh√¢n r·ªông. </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['‚Ä¢'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-06-13T00:00:00&#43;00:00">June 13, 2025</time>
          </li>

          <li class="before:content-['‚Ä¢'] before:mr-2 before:opacity-50 my-2">
            17 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://huggingface.co/blog/assets/hello-hf-kernels/kernel-hub-five-mins-short-21.png" alt="N√¢ng cao m√¥ h√¨nh c·ªßa b·∫°n trong 5 ph√∫t v·ªõi Hugging Face Kernel Hub">
        <figcaption class="text-center italic text-xs">T√¨m hi·ªÉu c√°ch tƒÉng t·ªëc quy tr√¨nh l√†m vi·ªác c·ªßa b·∫°n b·∫±ng c√°ch s·ª≠ d·ª•ng m√¥i tr∆∞·ªùng m√£ h√≥a d·ª±a tr√™n ƒë√°m m√¢y, t√≠ch h·ª£p v√† c√≥ th·ªÉ nh√¢n r·ªông.</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="-tƒÉng-c∆∞·ªùng-m√¥-h√¨nh-c·ªßa-b·∫°n-trong-5-ph√∫t-v·ªõi-hugging-face-kernel-hub">üèéÔ∏è TƒÉng C∆∞·ªùng M√¥ H√¨nh C·ªßa B·∫°n Trong 5 Ph√∫t V·ªõi Hugging Face Kernel Hub</h1>
<p><strong>TƒÉng hi·ªáu su·∫•t m√¥ h√¨nh c·ªßa b·∫°n v·ªõi c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a tr∆∞·ªõc, d·ªÖ d√†ng t·∫£i t·ª´ Hub.</strong></p>
<p>H√¥m nay, ch√∫ng ta s·∫Ω kh√°m ph√° m·ªôt ph√°t tri·ªÉn th√∫ v·ªã t·ª´ Hugging Face: <strong>Kernel Hub</strong>! L√† nh·ªØng ng∆∞·ªùi th·ª±c h√†nh ML, ch√∫ng ta bi·∫øt r·∫±ng t·ªëi ƒëa h√≥a hi·ªáu su·∫•t th∆∞·ªùng li√™n quan ƒë·∫øn vi·ªác ƒëi s√¢u v√†o m√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a, c√°c kernel CUDA t√πy ch·ªânh ho·∫∑c c√°c h·ªá th·ªëng x√¢y d·ª±ng ph·ª©c t·∫°p. Kernel Hub ƒë∆°n gi·∫£n h√≥a qu√° tr√¨nh n√†y m·ªôt c√°ch ƒë√°ng k·ªÉ!</p>
<p>D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• ng·∫Øn g·ªçn v·ªÅ c√°ch s·ª≠ d·ª•ng m·ªôt kernel trong m√£ c·ªßa b·∫°n.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> kernels <span style="color:#f92672">import</span> get_kernel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># T·∫£i xu·ªëng c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a t·ª´ Hugging Face hub</span>
</span></span><span style="display:flex;"><span>activation <span style="color:#f92672">=</span> get_kernel(<span style="color:#e6db74">&#34;kernels-community/activation&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tensor ng·∫´u nhi√™n</span>
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn((<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>), dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float16, device<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cuda&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Ch·∫°y kernel</span>
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>empty_like(x)
</span></span><span style="display:flex;"><span>activation<span style="color:#f92672">.</span>gelu_fast(y, x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(y)
</span></span></code></pre></div><p>Trong c√°c ph·∫ßn ti·∫øp theo, ch√∫ng ta s·∫Ω ƒë·ªÅ c·∫≠p ƒë·∫øn c√°c ch·ªß ƒë·ªÅ sau:</p>
<ol>
<li><strong>Kernel Hub l√† g√¨?</strong> - Hi·ªÉu kh√°i ni·ªám c·ªët l√µi.</li>
<li><strong>C√°ch s·ª≠ d·ª•ng Kernel Hub</strong> - M·ªôt v√≠ d·ª• m√£ nhanh.</li>
<li><strong>Th√™m Kernel v√†o M√¥ H√¨nh ƒê∆°n Gi·∫£n</strong> - T√≠ch h·ª£p th·ª±c t·∫ø b·∫±ng RMSNorm.</li>
<li><strong>ƒê√°nh Gi√° T√°c ƒê·ªông Hi·ªáu Su·∫•t</strong> - ƒêi·ªÉm chu·∫©n s·ª± kh√°c bi·ªát c·ªßa RMSNorm.</li>
<li><strong>C√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng th·ª±c t·∫ø</strong> - C√°c v√≠ d·ª• v·ªÅ c√°ch th∆∞ vi·ªán kernel ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c d·ª± √°n kh√°c.</li>
</ol>
<p>Ch√∫ng ta s·∫Ω gi·ªõi thi·ªáu nh·ªØng kh√°i ni·ªám n√†y m·ªôt c√°ch nhanh ch√≥ng ‚Äì √Ω t∆∞·ªüng c·ªët l√µi c√≥ th·ªÉ ƒë∆∞·ª£c n·∫Øm b·∫Øt trong kho·∫£ng 5 ph√∫t (m·∫∑c d√π th·ª≠ nghi·ªám v√† ƒëo ƒëi·ªÉm chu·∫©n c√≥ th·ªÉ m·∫•t nhi·ªÅu th·ªùi gian h∆°n!).</p>
<h2 id="1-kernel-hub-l√†-g√¨">1. Kernel Hub L√† G√¨?</h2>
<p><!-- raw HTML omitted -->Kernel Hub<!-- raw HTML omitted --> (üëà H√£y xem!) cho ph√©p c√°c th∆∞ vi·ªán v√† ·ª©ng d·ª•ng Python <strong>t·∫£i c√°c kernel t√≠nh to√°n ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a tr·ª±c ti·∫øp t·ª´ Hugging Face Hub</strong>. H√£y nghƒ© v·ªÅ n√≥ nh∆∞ Model Hub, nh∆∞ng d√†nh cho c√°c ƒëo·∫°n m√£ (kernel) c·∫•p th·∫•p, hi·ªáu su·∫•t cao, gi√∫p tƒÉng t·ªëc c√°c ho·∫°t ƒë·ªông c·ª• th·ªÉ, th∆∞·ªùng tr√™n GPU.</p>
<p>C√°c v√≠ d·ª• bao g·ªìm c√°c c∆° ch·∫ø attention n√¢ng cao (nh∆∞ <!-- raw HTML omitted -->FlashAttention<!-- raw HTML omitted --> ƒë·ªÉ tƒÉng t·ªëc ƒë√°ng k·ªÉ v√† ti·∫øt ki·ªám b·ªô nh·ªõ). <!-- raw HTML omitted -->C√°c kernel l∆∞·ª£ng t·ª≠ h√≥a<!-- raw HTML omitted --> t√πy ch·ªânh (cho ph√©p t√≠nh to√°n hi·ªáu qu·∫£ v·ªõi c√°c ki·ªÉu d·ªØ li·ªáu c√≥ ƒë·ªô ch√≠nh x√°c th·∫•p h∆°n nh∆∞ INT8 ho·∫∑c INT4). C√°c kernel chuy√™n d·ª•ng c·∫ßn thi·∫øt cho c√°c ki·∫øn tr√∫c ph·ª©c t·∫°p nh∆∞ <!-- raw HTML omitted -->c√°c l·ªõp Mixture of Experts (MoE)<!-- raw HTML omitted -->, bao g·ªìm c√°c m·∫´u ƒë·ªãnh tuy·∫øn v√† t√≠nh to√°n ph·ª©c t·∫°p. C≈©ng nh∆∞ <!-- raw HTML omitted -->c√°c h√†m k√≠ch ho·∫°t<!-- raw HTML omitted --> v√† <!-- raw HTML omitted -->c√°c l·ªõp chu·∫©n h√≥a (nh∆∞ LayerNorm ho·∫∑c RMSNorm)<!-- raw HTML omitted -->.</p>
<p>Thay v√¨ t·ª± qu·∫£n l√Ω c√°c ph·ª• thu·ªôc ph·ª©c t·∫°p, v·∫≠t l·ªôn v·ªõi c√°c flag bi√™n d·ªãch ho·∫∑c x√¢y d·ª±ng c√°c th∆∞ vi·ªán nh∆∞ Triton ho·∫∑c CUTLASS t·ª´ ngu·ªìn, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng th∆∞ vi·ªán <code>kernels</code> ƒë·ªÉ t√¨m n·∫°p v√† ch·∫°y ngay l·∫≠p t·ª©c c√°c kernel ƒë∆∞·ª£c bi√™n d·ªãch v√† t·ªëi ∆∞u h√≥a tr∆∞·ªõc.</p>
<p>V√≠ d·ª•: ƒë·ªÉ b·∫≠t <strong>FlashAttention</strong>, b·∫°n ch·ªâ c·∫ßn m·ªôt d√≤ng‚Äîkh√¥ng c·∫ßn build, kh√¥ng c·∫ßn flag:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> kernels <span style="color:#f92672">import</span> get_kernel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>flash_attention <span style="color:#f92672">=</span> get_kernel(<span style="color:#e6db74">&#34;kernels-community/flash-attn&#34;</span>)
</span></span></code></pre></div><p><code>kernels</code> ph√°t hi·ªán ch√≠nh x√°c c√°c phi√™n b·∫£n Python, PyTorch v√† CUDA c·ªßa b·∫°n, sau ƒë√≥ t·∫£i xu·ªëng binary ƒë∆∞·ª£c bi√™n d·ªãch s·∫µn ph√π h·ª£p‚Äîth∆∞·ªùng trong v√†i gi√¢y (ho·∫∑c m·ªôt ho·∫∑c hai ph√∫t ƒë·ªëi v·ªõi k·∫øt n·ªëi ch·∫≠m).</p>
<p>Ng∆∞·ª£c l·∫°i, vi·ªác t·ª± bi√™n d·ªãch FlashAttention ƒë√≤i h·ªèi:</p>
<ul>
<li>Clone repository v√† c√†i ƒë·∫∑t m·ªçi ph·ª• thu·ªôc.</li>
<li>C·∫•u h√¨nh c√°c flag build v√† c√°c bi·∫øn m√¥i tr∆∞·ªùng.</li>
<li>D√†nh ra <strong>~96 GB RAM</strong> v√† nhi·ªÅu l√µi CPU.</li>
<li>Ch·ªù <strong>10 ph√∫t ƒë·∫øn v√†i gi·ªù</strong>, t√πy thu·ªôc v√†o ph·∫ßn c·ª©ng c·ªßa b·∫°n. (Xem <!-- raw HTML omitted -->h∆∞·ªõng d·∫´n c√†i ƒë·∫∑t<!-- raw HTML omitted --> c·ªßa ch√≠nh d·ª± √°n ƒë·ªÉ bi·∫øt chi ti·∫øt.)</li>
</ul>
<p>Kernel Hub x√≥a b·ªè t·∫•t c·∫£ nh·ªØng kh√≥ khƒÉn ƒë√≥: m·ªôt l·ªánh g·ªçi h√†m, tƒÉng t·ªëc t·ª©c th√¨.</p>
<h3 id="l·ª£i-√≠ch-c·ªßa-kernel-hub">L·ª£i √çch C·ªßa Kernel Hub:</h3>
<ul>
<li><strong>Truy C·∫≠p T·ª©c Th√¨ V√†o C√°c Kernel ƒê∆∞·ª£c T·ªëi ∆Øu H√≥a</strong>: T·∫£i v√† ch·∫°y c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho nhi·ªÅu lo·∫°i ph·∫ßn c·ª©ng, b·∫Øt ƒë·∫ßu v·ªõi GPU NVIDIA v√† AMD, m√† kh√¥ng g·∫∑p r·∫Øc r·ªëi v·ªÅ bi√™n d·ªãch c·ª•c b·ªô.</li>
<li><strong>Chia S·∫ª v√† T√°i S·ª≠ D·ª•ng</strong>: Kh√°m ph√°, chia s·∫ª v√† t√°i s·ª≠ d·ª•ng c√°c kernel tr√™n c√°c d·ª± √°n kh√°c nhau v√† c·ªông ƒë·ªìng.</li>
<li><strong>D·ªÖ D√†ng C·∫≠p Nh·∫≠t</strong>: Lu√¥n c·∫≠p nh·∫≠t nh·ªØng c·∫£i ti·∫øn kernel m·ªõi nh·∫•t b·∫±ng c√°ch ch·ªâ c·∫ßn k√©o phi√™n b·∫£n m·ªõi nh·∫•t t·ª´ Hub.</li>
<li><strong>TƒÉng T·ªëc Ph√°t Tri·ªÉn</strong>: T·∫≠p trung v√†o ki·∫øn tr√∫c v√† logic m√¥ h√¨nh c·ªßa b·∫°n, kh√¥ng ph·∫£i v√†o s·ª± ph·ª©c t·∫°p c·ªßa vi·ªác bi√™n d·ªãch v√† tri·ªÉn khai kernel.</li>
<li><strong>C·∫£i Thi·ªán Hi·ªáu Su·∫•t</strong>: T·∫≠n d·ª•ng c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a b·ªüi c√°c chuy√™n gia ƒë·ªÉ c√≥ kh·∫£ nƒÉng tƒÉng t·ªëc qu√° tr√¨nh hu·∫•n luy·ªán v√† suy lu·∫≠n.</li>
<li><strong>ƒê∆°n Gi·∫£n H√≥a Tri·ªÉn Khai</strong>: Gi·∫£m ƒë·ªô ph·ª©c t·∫°p c·ªßa m√¥i tr∆∞·ªùng tri·ªÉn khai c·ªßa b·∫°n b·∫±ng c√°ch t√¨m n·∫°p c√°c kernel theo y√™u c·∫ßu.</li>
<li><strong>Ph√°t Tri·ªÉn v√† Chia S·∫ª Kernel C·ªßa Ri√™ng B·∫°n</strong>: N·∫øu b·∫°n t·∫°o c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a, b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng chia s·∫ª ch√∫ng tr√™n Hub ƒë·ªÉ ng∆∞·ªùi kh√°c s·ª≠ d·ª•ng. ƒêi·ªÅu n√†y khuy·∫øn kh√≠ch s·ª± h·ª£p t√°c v√† chia s·∫ª ki·∫øn th·ª©c trong c·ªông ƒë·ªìng.</li>
</ul>
<blockquote>
<p>Nh∆∞ nhi·ªÅu nh√† ph√°t tri·ªÉn machine learning ƒë√£ bi·∫øt, vi·ªác qu·∫£n l√Ω c√°c ph·ª• thu·ªôc v√† x√¢y d·ª±ng m√£ c·∫•p th·∫•p t·ª´ ngu·ªìn c√≥ th·ªÉ l√† m·ªôt qu√° tr√¨nh t·ªën th·ªùi gian v√† d·ªÖ x·∫£y ra l·ªói. Kernel Hub nh·∫±m m·ª•c ƒë√≠ch ƒë∆°n gi·∫£n h√≥a ƒëi·ªÅu n√†y b·∫±ng c√°ch cung c·∫•p m·ªôt repository t·∫≠p trung c√°c kernel t√≠nh to√°n ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a c√≥ th·ªÉ d·ªÖ d√†ng t·∫£i v√† ch·∫°y.</p></blockquote>
<p>D√†nh nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh tuy·ªát v·ªùi v√† √≠t th·ªùi gian h∆°n ƒë·ªÉ chi·∫øn ƒë·∫•u v·ªõi c√°c h·ªá th·ªëng x√¢y d·ª±ng!</p>
<h2 id="2-c√°ch-s·ª≠-d·ª•ng-kernel-hub-v√≠-d·ª•-c∆°-b·∫£n">2. C√°ch S·ª≠ D·ª•ng Kernel Hub (V√≠ D·ª• C∆° B·∫£n)</h2>
<p>Vi·ªác s·ª≠ d·ª•ng Kernel Hub ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë∆°n gi·∫£n. Th∆∞ vi·ªán <code>kernels</code> cung c·∫•p giao di·ªán ch√≠nh. D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• nhanh t·∫£i m·ªôt kernel h√†m k√≠ch ho·∫°t GELU ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a. (Sau n√†y, ch√∫ng ta s·∫Ω th·∫•y m·ªôt v√≠ d·ª• kh√°c v·ªÅ c√°ch t√≠ch h·ª£p m·ªôt kernel trong m√¥ h√¨nh c·ªßa ch√∫ng ta).</p>
<p>T·ªáp: <!-- raw HTML omitted --><code>activation_validation_example.py</code><!-- raw HTML omitted --></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># /// script</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># dependencies = [</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;numpy&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;torch&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;kernels&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ]</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ///</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> kernels <span style="color:#f92672">import</span> get_kernel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>DEVICE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cuda&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># T·∫°o kh·∫£ nƒÉng t√°i t·∫°o</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>manual_seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># T·∫£i xu·ªëng c√°c kernel k√≠ch ho·∫°t ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a t·ª´ Hub</span>
</span></span><span style="display:flex;"><span>activation_kernels <span style="color:#f92672">=</span> get_kernel(<span style="color:#e6db74">&#34;kernels-community/activation&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># T·∫°o m·ªôt tensor ng·∫´u nhi√™n tr√™n GPU</span>
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>), dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float16, device<span style="color:#f92672">=</span>DEVICE)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Chu·∫©n b·ªã m·ªôt tensor ƒë·∫ßu ra</span>
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>empty_like(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Ch·∫°y kernel GELU nhanh</span>
</span></span><span style="display:flex;"><span>activation_kernels<span style="color:#f92672">.</span>gelu_fast(y, x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># L·∫•y ƒë·∫ßu ra d·ª± ki·∫øn b·∫±ng c√°ch s·ª≠ d·ª•ng GELU t√≠ch h·ª£p c·ªßa PyTorch</span>
</span></span><span style="display:flex;"><span>expected <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>gelu(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># So s√°nh ƒë·∫ßu ra kernel v·ªõi k·∫øt qu·∫£ c·ªßa PyTorch</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>testing<span style="color:#f92672">.</span>assert_close(y, expected, rtol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-2</span>, atol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;‚úÖ ƒê·∫ßu ra kernel kh·ªõp v·ªõi PyTorch GELU!&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># T√πy ch·ªçn: in c·∫£ hai tensor ƒë·ªÉ ki·ªÉm tra</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Tensor ƒë·∫ßu v√†o:&#34;</span>)
</span></span><span style="display:flex;"><span>print(x)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">ƒê·∫ßu ra kernel GELU nhanh:&#34;</span>)
</span></span><span style="display:flex;"><span>print(y)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">ƒê·∫ßu ra PyTorch GELU:&#34;</span>)
</span></span><span style="display:flex;"><span>print(expected)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Li·ªát k√™ c√°c h√†m kh·∫£ d·ª•ng trong m√¥-ƒëun kernel ƒë√£ t·∫£i</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">C√°c h√†m kh·∫£ d·ª•ng trong &#39;kernels-community/activation&#39;:&#34;</span>)
</span></span><span style="display:flex;"><span>print(dir(activation_kernels))
</span></span></code></pre></div><p><strong>(L∆∞u √Ω:</strong> N·∫øu b·∫°n ƒë√£ c√†i ƒë·∫∑t <!-- raw HTML omitted --><code>uv</code><!-- raw HTML omitted -->, b·∫°n c√≥ th·ªÉ l∆∞u script n√†y d∆∞·ªõi d·∫°ng <code>script.py</code> v√† ch·∫°y <code>uv run script.py</code> ƒë·ªÉ t·ª± ƒë·ªông x·ª≠ l√Ω c√°c ph·ª• thu·ªôc.)</p>
<h3 id="ƒëi·ªÅu-g√¨-ƒëang-x·∫£y-ra-·ªü-ƒë√¢y">ƒêi·ªÅu G√¨ ƒêang X·∫£y Ra ·ªû ƒê√¢y?</h3>
<ol>
<li><strong>Import <code>get_kernel</code></strong>: H√†m n√†y l√† ƒëi·ªÉm v√†o Kernel Hub th√¥ng qua th∆∞ vi·ªán <code>kernels</code>.</li>
<li><strong><code>get_kernel(&quot;kernels-community/activation&quot;)</code></strong>: D√≤ng n√†y t√¨m repository kernel <code>activation</code> trong organization <code>kernels-community</code>. N√≥ t·∫£i xu·ªëng, l∆∞u v√†o b·ªô nh·ªõ cache v√† t·∫£i binary kernel ƒë∆∞·ª£c bi√™n d·ªãch s·∫µn th√≠ch h·ª£p.</li>
<li><strong>Chu·∫©n B·ªã Tensors</strong>: Ch√∫ng ta t·∫°o c√°c tensor ƒë·∫ßu v√†o (<code>x</code>) v√† ƒë·∫ßu ra (<code>y</code>) tr√™n GPU.</li>
<li><strong><code>activation_kernels.gelu_fast(y, x)</code></strong>: Ch√∫ng ta g·ªçi h√†m ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a c·ª• th·ªÉ (<code>gelu_fast</code>) ƒë∆∞·ª£c cung c·∫•p b·ªüi m√¥-ƒëun kernel ƒë√£ t·∫£i.</li>
<li><strong>X√°c Minh</strong>: Ch√∫ng ta ki·ªÉm tra ƒë·∫ßu ra.</li>
</ol>
<p>V√≠ d·ª• ƒë∆°n gi·∫£n n√†y cho th·∫•y b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng t√¨m n·∫°p v√† th·ª±c thi m√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cao nh∆∞ th·∫ø n√†o. B√¢y gi·ªù h√£y xem x√©t m·ªôt t√≠ch h·ª£p th·ª±c t·∫ø h∆°n b·∫±ng c√°ch s·ª≠ d·ª•ng RMS Normalization.</p>
<h2 id="3-th√™m-kernel-v√†o-m√¥-h√¨nh-ƒë∆°n-gi·∫£n">3. Th√™m Kernel V√†o M√¥ H√¨nh ƒê∆°n Gi·∫£n</h2>
<p>H√£y t√≠ch h·ª£p m·ªôt kernel <strong>RMS Normalization</strong> ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a v√†o m·ªôt m√¥ h√¨nh c∆° b·∫£n. Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng implementation <code>LlamaRMSNorm</code> ƒë∆∞·ª£c cung c·∫•p trong repository <code>kernels-community/triton-layer-norm</code> (l∆∞u √Ω: repo n√†y ch·ª©a c√°c kernel chu·∫©n h√≥a kh√°c nhau) v√† so s√°nh n√≥ v·ªõi implementation RMSNorm PyTorch c∆° b·∫£n.</p>
<p>ƒê·∫ßu ti√™n, x√°c ƒë·ªãnh m·ªôt m√¥-ƒëun RMSNorm ƒë∆°n gi·∫£n trong PyTorch v√† m·ªôt m√¥ h√¨nh c∆° s·ªü s·ª≠ d·ª•ng n√≥:</p>
<p>T·ªáp: <!-- raw HTML omitted --><code>rmsnorm_baseline.py</code><!-- raw HTML omitted --></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># /// script</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># dependencies = [</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;numpy&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;torch&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;kernels&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ]</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ///</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>DEVICE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cuda&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>DTYPE <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>float16  <span style="color:#75715e"># S·ª≠ d·ª•ng float16 ƒë·ªÉ c√≥ ti·ªÅm nƒÉng hi·ªáu su·∫•t kernel t·ªët h∆°n</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Implementation PyTorch ƒë∆°n gi·∫£n c·ªßa RMSNorm ƒë·ªÉ so s√°nh c∆° b·∫£n</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">RMSNorm</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, hidden_size, variance_epsilon<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-5</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(torch<span style="color:#f92672">.</span>ones(hidden_size))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>eps <span style="color:#f92672">=</span> variance_epsilon
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>hidden_size <span style="color:#f92672">=</span> hidden_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Gi·∫£ s·ª≠ x l√† (batch_size, ..., hidden_size)</span>
</span></span><span style="display:flex;"><span>        input_dtype <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>dtype
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># T√≠nh ph∆∞∆°ng sai trong float32 ƒë·ªÉ ·ªïn ƒë·ªãnh</span>
</span></span><span style="display:flex;"><span>        variance <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>float32)<span style="color:#f92672">.</span>pow(<span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>mean(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x <span style="color:#f92672">*</span> torch<span style="color:#f92672">.</span>rsqrt(variance <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>eps)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># √Åp d·ª•ng tr·ªçng s·ªë v√† chuy·ªÉn ƒë·ªïi tr·ªü l·∫°i dtype ban ƒë·∫ßu</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> (self<span style="color:#f92672">.</span>weight <span style="color:#f92672">*</span> x)<span style="color:#f92672">.</span>to(input_dtype)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">BaselineModel</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, input_size, hidden_size, output_size, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-5</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(input_size, hidden_size)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>norm <span style="color:#f92672">=</span> RMSNorm(hidden_size, variance_epsilon<span style="color:#f92672">=</span>eps)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>activation <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>GELU()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(hidden_size, output_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c tr·ªçng s·ªë c·ªßa c√°c l·ªõp tuy·∫øn t√≠nh l√† 1 ƒë·ªÉ ki·ªÉm tra</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear1<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear1<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear2<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear2<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>norm<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>linear1(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>norm(x)  <span style="color:#75715e"># √Åp d·ª•ng RMSNorm</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>activation(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>linear2(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># V√≠ d·ª• s·ª≠ d·ª•ng</span>
</span></span><span style="display:flex;"><span>input_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>
</span></span><span style="display:flex;"><span>hidden_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>
</span></span><span style="display:flex;"><span>output_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>eps_val <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-5</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>baseline_model <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    BaselineModel(input_size, hidden_size, output_size, eps<span style="color:#f92672">=</span>eps_val)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DEVICE)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DTYPE)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">32</span>, input_size, device<span style="color:#f92672">=</span>DEVICE, dtype<span style="color:#f92672">=</span>DTYPE)  <span style="color:#75715e"># Batch g·ªìm 32</span>
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> baseline_model(dummy_input)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;H√¨nh d·∫°ng ƒë·∫ßu ra c·ªßa m√¥ h√¨nh Baseline RMSNorm:&#34;</span>, output<span style="color:#f92672">.</span>shape)
</span></span></code></pre></div><p>B√¢y gi·ªù, h√£y t·∫°o m·ªôt phi√™n b·∫£n b·∫±ng c√°ch s·ª≠ d·ª•ng kernel <code>LlamaRMSNorm</code> ƒë∆∞·ª£c t·∫£i qua <code>kernels</code>.</p>
<p>T·ªáp: <!-- raw HTML omitted --><code>rmsnorm_kernel.py</code><!-- raw HTML omitted --></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># /// script</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># dependencies = [</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;numpy&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;torch&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;kernels&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ]</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ///</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> kernels <span style="color:#f92672">import</span> get_kernel, use_kernel_forward_from_hub
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># t√°i s·ª≠ d·ª•ng m√¥ h√¨nh t·ª´ ƒëo·∫°n m√£ tr∆∞·ªõc ho·∫∑c sao ch√©p l·ªõp</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ƒë·ªãnh nghƒ©a ·ªü ƒë√¢y ƒë·ªÉ ch·∫°y script n√†y m·ªôt c√°ch ƒë·ªôc l·∫≠p</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> rmsnorm_baseline <span style="color:#f92672">import</span> BaselineModel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>DEVICE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cuda&#34;</span>
</span></span><span style="display:flex;"><span>DTYPE <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>float16  <span style="color:#75715e"># S·ª≠ d·ª•ng float16 ƒë·ªÉ c√≥ ti·ªÅm nƒÉng hi·ªáu su·∫•t kernel t·ªët h∆°n</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>layer_norm_kernel_module <span style="color:#f92672">=</span> get_kernel(<span style="color:#e6db74">&#34;kernels-community/triton-layer-norm&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ƒê∆°n gi·∫£n ch·ªâ c·∫ßn th√™m decorator v√†o l·ªõp LlamaRMSNorm ƒë·ªÉ t·ª± ƒë·ªông thay th·∫ø h√†m forward</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># v·ªõi phi√™n b·∫£n kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># L∆∞u √Ω: l∆∞u √Ω t·∫•t c·∫£ c√°c kernel ƒë·ªÅu ƒë∆∞·ª£c ship v·ªõi c√°c l·ªõp ƒë√£ ƒë∆∞·ª£c √°nh x·∫° v√† s·∫Ω y√™u c·∫ßu g·ªçi h√†m tr·ª±c ti·∫øp</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tuy nhi√™n, trong tr∆∞·ªùng h·ª£p n√†y, l·ªõp LlamaRMSNorm ƒë√£ ƒë∆∞·ª£c √°nh x·∫° t·ªõi h√†m kernel. N·∫øu kh√¥ng, ch√∫ng ta c·∫ßn</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># g·ªçi h√†m tr·ª±c ti·∫øp nh∆∞ sau:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ```python</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># layer_norm_kernel_module.rms_norm_fn(</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     hidden_states,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     self.weight,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     bias=None,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     residual=None,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     eps=self.variance_epsilon,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     dropout_p=0.0,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     prenorm=False,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     residual_in_fp32=False,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># )</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ```</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@use_kernel_forward_from_hub</span>(<span style="color:#e6db74">&#34;LlamaRMSNorm&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">OriginalRMSNorm</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, hidden_size, variance_epsilon<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-5</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>weight <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Parameter(torch<span style="color:#f92672">.</span>ones(hidden_size))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>eps <span style="color:#f92672">=</span> variance_epsilon
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>hidden_size <span style="color:#f92672">=</span> hidden_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Gi·∫£ s·ª≠ x l√† (batch_size, ..., hidden_size)</span>
</span></span><span style="display:flex;"><span>        input_dtype <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>dtype
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># T√≠nh ph∆∞∆°ng sai trong float32 ƒë·ªÉ ·ªïn ƒë·ªãnh</span>
</span></span><span style="display:flex;"><span>        variance <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>float32)<span style="color:#f92672">.</span>pow(<span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>mean(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x <span style="color:#f92672">*</span> torch<span style="color:#f92672">.</span>rsqrt(variance <span style="color:#f92672">+</span> self<span style="color:#f92672">.</span>eps)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># √Åp d·ª•ng tr·ªçng s·ªë v√† chuy·ªÉn ƒë·ªïi tr·ªü l·∫°i dtype ban ƒë·∫ßu</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> (self<span style="color:#f92672">.</span>weight <span style="color:#f92672">*</span> x)<span style="color:#f92672">.</span>to(input_dtype)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">KernelModel</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(
</span></span><span style="display:flex;"><span>        self,
</span></span><span style="display:flex;"><span>        input_size,
</span></span><span style="display:flex;"><span>        hidden_size,
</span></span><span style="display:flex;"><span>        output_size,
</span></span><span style="display:flex;"><span>        device<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;cuda&#34;</span>,
</span></span><span style="display:flex;"><span>        dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float16,
</span></span><span style="display:flex;"><span>        eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-5</span>,
</span></span><span style="display:flex;"><span>    ):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(input_size, hidden_size)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># OriginalRMSNorm s·∫Ω ƒë∆∞·ª£c thay th·∫ø b·∫±ng l·ªõp kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># khi m√¥ h√¨nh ƒë∆∞·ª£c t·∫£i</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>norm <span style="color:#f92672">=</span> OriginalRMSNorm(hidden_size, variance_epsilon<span style="color:#f92672">=</span>eps)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>activation <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>GELU()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>linear2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(hidden_size, output_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c tr·ªçng s·ªë c·ªßa c√°c l·ªõp tuy·∫øn t√≠nh l√† 1 ƒë·ªÉ ki·ªÉm tra</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear1<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear1<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear2<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>linear2<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>norm<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>linear1(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>norm(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>activation(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>linear2(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># V√≠ d·ª• s·ª≠ d·ª•ng</span>
</span></span><span style="display:flex;"><span>input_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>
</span></span><span style="display:flex;"><span>hidden_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>
</span></span><span style="display:flex;"><span>output_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>eps_val <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-5</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kernel_model <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    KernelModel(
</span></span><span style="display:flex;"><span>        input_size, hidden_size, output_size, device<span style="color:#f92672">=</span>DEVICE, dtype<span style="color:#f92672">=</span>DTYPE, eps<span style="color:#f92672">=</span>eps_val
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DEVICE)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DTYPE)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>baseline_model <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    BaselineModel(input_size, hidden_size, output_size, eps<span style="color:#f92672">=</span>eps_val)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DEVICE)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DTYPE)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dummy_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">32</span>, input_size, device<span style="color:#f92672">=</span>DEVICE, dtype<span style="color:#f92672">=</span>DTYPE)  <span style="color:#75715e"># Batch g·ªìm 32</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> baseline_model(dummy_input)
</span></span><span style="display:flex;"><span>output_kernel <span style="color:#f92672">=</span> kernel_model(dummy_input)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;H√¨nh d·∫°ng ƒë·∫ßu ra c·ªßa m√¥ h√¨nh Kernel RMSNorm:&#34;</span>, output_kernel<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># X√°c minh c√°c ƒë·∫ßu ra g·∫ßn nhau (c√°c implementations RMSNorm ph·∫£i g·∫ßn nhau v·ªÅ m·∫∑t s·ªë)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>testing<span style="color:#f92672">.</span>assert_close(output, output_kernel, rtol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-2</span>, atol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-2</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">C√°c ƒë·∫ßu ra c·ªßa m√¥ h√¨nh Baseline v√† Kernel RMSNorm kh·ªõp nhau!&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">except</span> <span style="color:#a6e22e">AssertionError</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">C√°c ƒë·∫ßu ra c·ªßa m√¥ h√¨nh Baseline v√† Kernel RMSNorm h∆°i kh√°c nhau:&#34;</span>)
</span></span><span style="display:flex;"><span>    print(e)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">except</span> <span style="color:#a6e22e">NameError</span>:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">B·ªè qua so s√°nh ƒë·∫ßu ra v√¨ ƒë·∫ßu ra c·ªßa m√¥ h√¨nh kernel kh√¥ng ƒë∆∞·ª£c t·∫°o.&#34;</span>)
</span></span></code></pre></div><p><strong>L∆∞u √ù Quan Tr·ªçng V·ªÅ <code>KernelModel</code>:</strong></p>
<ul>
<li><strong>K·∫ø th·ª´a Kernel:</strong> L·ªõp <code>KernelRMSNorm</code> k·∫ø th·ª´a t·ª´ <code>layer_norm_kernel_module.layers.LlamaRMSNorm</code>, l√† implementation RMSNorm trong kernel. ƒêi·ªÅu n√†y cho ph√©p ch√∫ng ta s·ª≠ d·ª•ng tr·ª±c ti·∫øp kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a.</li>
<li><strong>Truy C·∫≠p H√†m:</strong> C√°ch ch√≠nh x√°c ƒë·ªÉ truy c·∫≠p h√†m RMSNorm (<code>layer_norm_kernel_module.layers.LlamaRMSNorm.forward</code>, <code>layer_norm_kernel_module.rms_norm_forward</code> ho·∫∑c m·ªôt c√°i g√¨ ƒë√≥ kh√°c) <strong>ho√†n to√†n ph·ª• thu·ªôc v√†o c√°ch ng∆∞·ªùi t·∫°o kernel c·∫•u tr√∫c repository tr√™n Hub.</strong> B·∫°n c√≥ th·ªÉ c·∫ßn ki·ªÉm tra ƒë·ªëi t∆∞·ª£ng <code>layer_norm_kernel_module</code> ƒë√£ t·∫£i (v√≠ d·ª•: s·ª≠ d·ª•ng <code>dir()</code>) ho·∫∑c ki·ªÉm tra t√†i li·ªáu c·ªßa kernel tr√™n Hub ƒë·ªÉ t√¨m h√†m/ph∆∞∆°ng th·ª©c ch√≠nh x√°c v√† signature c·ªßa n√≥. T√¥i ƒë√£ s·ª≠ d·ª•ng <code>rms_norm_forward</code> l√†m tr√¨nh gi·ªØ ch·ªó h·ª£p l√Ω v√† th√™m x·ª≠ l√Ω l·ªói.</li>
<li><strong>Tham S·ªë:</strong> B√¢y gi·ªù ch√∫ng ta ch·ªâ x√°c ƒë·ªãnh <code>rms_norm_weight</code> (kh√¥ng c√≥ bias), nh·∫•t qu√°n v·ªõi RMSNorm.</li>
</ul>
<h2 id="4-ƒë√°nh-gi√°-t√°c-ƒë·ªông-hi·ªáu-su·∫•t">4. ƒê√°nh Gi√° T√°c ƒê·ªông Hi·ªáu Su·∫•t</h2>
<p>Kernel RMSNorm Triton ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a nhanh h∆°n bao nhi√™u so v·ªõi phi√™n b·∫£n PyTorch ti√™u chu·∫©n? H√£y benchmark l∆∞·ª£t forward ƒë·ªÉ t√¨m hi·ªÉu.</p>
<p>T·ªáp: <!-- raw HTML omitted --><code>rmsnorm_benchmark.py</code><!-- raw HTML omitted --></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># /// script</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># dependencies = [</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;numpy&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;torch&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  &#34;kernels&#34;,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ]</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ///</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># t√°i s·ª≠ d·ª•ng c√°c m√¥ h√¨nh t·ª´ c√°c ƒëo·∫°n m√£ tr∆∞·ªõc ho·∫∑c sao ch√©p l·ªõp</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># c√°c ƒë·ªãnh nghƒ©a ·ªü ƒë√¢y ƒë·ªÉ ch·∫°y script n√†y m·ªôt c√°ch ƒë·ªôc l·∫≠p</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> rmsnorm_baseline <span style="color:#f92672">import</span> BaselineModel
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> rmsnorm_kernel <span style="color:#f92672">import</span> KernelModel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>DEVICE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cuda&#34;</span>
</span></span><span style="display:flex;"><span>DTYPE <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>float16  <span style="color:#75715e"># S·ª≠ d·ª•ng float16 ƒë·ªÉ c√≥ ti·ªÅm nƒÉng hi·ªáu su·∫•t kernel t·ªët h∆°n</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># S·ª≠ d·ª•ng torch.cuda.Event ƒë·ªÉ c√≥ th·ªùi gian GPU ch√≠nh x√°c (ƒë·∫£m b·∫£o h√†m ƒë∆∞·ª£c x√°c ƒë·ªãnh)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">benchmark_model</span>(model, input_tensor, num_runs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, warmup_runs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>eval()  <span style="color:#75715e"># ƒê·∫∑t m√¥ h√¨nh ·ªü ch·∫ø ƒë·ªô ƒë√°nh gi√°</span>
</span></span><span style="display:flex;"><span>    dtype <span style="color:#f92672">=</span> input_tensor<span style="color:#f92672">.</span>dtype
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>to(input_tensor<span style="color:#f92672">.</span>device)<span style="color:#f92672">.</span>to(dtype)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># C√°c l·∫ßn ch·∫°y kh·ªüi ƒë·ªông</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(warmup_runs):
</span></span><span style="display:flex;"><span>        _ <span style="color:#f92672">=</span> model(input_tensor)
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>synchronize()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># C√°c l·∫ßn ch·∫°y ƒë∆∞·ª£c t√≠nh th·ªùi gian</span>
</span></span><span style="display:flex;"><span>    start_event <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>Event(enable_timing<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    end_event <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>Event(enable_timing<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    start_event<span style="color:#f92672">.</span>record()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_runs):
</span></span><span style="display:flex;"><span>        _ <span style="color:#f92672">=</span> model(input_tensor)
</span></span><span style="display:flex;"><span>    end_event<span style="color:#f92672">.</span>record()
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>synchronize()
</span></span><span style="display:flex;"><span>    elapsed_time_ms <span style="color:#f92672">=</span> start_event<span style="color:#f92672">.</span>elapsed_time(end_event)
</span></span><span style="display:flex;"><span>    avg_time_ms <span style="color:#f92672">=</span> elapsed_time_ms <span style="color:#f92672">/</span> num_runs
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> avg_time_ms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>input_size_bench <span style="color:#f92672">=</span> <span style="color:#ae81ff">4096</span>
</span></span><span style="display:flex;"><span>hidden_size_bench <span style="color:#f92672">=</span> <span style="color:#ae81ff">4096</span>  <span style="color:#75715e"># Hi·ªáu su·∫•t RMSNorm nh·∫°y c·∫£m v·ªõi chi·ªÅu n√†y</span>
</span></span><span style="display:flex;"><span>output_size_bench <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>eps_val_bench <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-5</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># T·∫°o c√°c m√¥ h√¨nh l·ªõn h∆°n v√† ƒë·∫ßu v√†o ƒë·ªÉ benchmark</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ƒê·∫£m b·∫£o c·∫£ hai m√¥ h√¨nh ƒë·ªÅu ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi ho√†n to√†n sang DEVICE v√† DTYPE m·ª•c ti√™u</span>
</span></span><span style="display:flex;"><span>baseline_model_bench <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    BaselineModel(
</span></span><span style="display:flex;"><span>        input_size_bench, hidden_size_bench, output_size_bench, eps<span style="color:#f92672">=</span>eps_val_bench
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DEVICE)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DTYPE)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>kernel_model_bench <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    KernelModel(
</span></span><span style="display:flex;"><span>        input_size_bench,
</span></span><span style="display:flex;"><span>        hidden_size_bench,
</span></span><span style="display:flex;"><span>        output_size_bench,
</span></span><span style="display:flex;"><span>        device<span style="color:#f92672">=</span>DEVICE,
</span></span><span style="display:flex;"><span>        dtype<span style="color:#f92672">=</span>DTYPE,
</span></span><span style="display:flex;"><span>        eps<span style="color:#f92672">=</span>eps_val_bench,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DEVICE)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span>to(DTYPE)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># g·ªçi c·∫£ hai v·ªõi k√≠ch th∆∞·ªõc batch l·ªõn h∆°n ƒë·ªÉ kh·ªüi ƒë·ªông GPU</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># v√† ƒë·∫£m b·∫£o c√°c m√¥ h√¨nh ƒë∆∞·ª£c t·∫£i</span>
</span></span><span style="display:flex;"><span>warmup_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">4096</span>, input_size_bench, device<span style="color:#f92672">=</span>DEVICE, dtype<span style="color:#f92672">=</span>DTYPE)
</span></span><span style="display:flex;"><span>_ <span style="color:#f92672">=</span> kernel_model_bench(warmup_input)
</span></span><span style="display:flex;"><span>_ <span style="color:#f92672">=</span> baseline_model_bench(warmup_input)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_sizes <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">256</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">512</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">1024</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">2048</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">4096</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">8192</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">16384</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">32768</span>,
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Batch Size&#39;</span><span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;12</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> | </span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Baseline Time (ms)&#39;</span><span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;18</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> | </span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Kernel Time (ms)&#39;</span><span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;18</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> | </span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;Speedup&#39;</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;-&#34;</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">74</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> batch_size <span style="color:#f92672">in</span> batch_sizes:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># G·ªçi cuda synchronize ƒë·ªÉ ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c ho·∫°t ƒë·ªông GPU tr∆∞·ªõc ƒë√≥ ƒë√£ ho√†n th√†nh</span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>synchronize()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># T·∫°o tensor ƒë·∫ßu v√†o ng·∫´u nhi√™n</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ƒê·∫£m b·∫£o tensor ƒë·∫ßu v√†o n·∫±m tr√™n thi·∫øt b·ªã v√† dtype ch√≠nh x√°c</span>
</span></span><span style="display:flex;"><span>    bench_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(batch_size, input_size_bench, device<span style="color:#f92672">=</span>DEVICE, dtype<span style="color:#f92672">=</span>DTYPE)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Ch·∫°y benchmark ch·ªâ khi kernel ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng</span>
</span></span><span style="display:flex;"><span>    baseline_time <span style="color:#f92672">=</span> benchmark_model(baseline_model_bench, bench_input)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    kernel_time <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>  <span style="color:#75715e"># Gi√° tr·ªã sentinel</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    kernel_time <span style="color:#f92672">=</span> benchmark_model(kernel_model_bench, bench_input)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    baseline_time <span style="color:#f92672">=</span> round(baseline_time, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>    kernel_time <span style="color:#f92672">=</span> round(kernel_time, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>    speedup <span style="color:#f92672">=</span> round(baseline_time <span style="color:#f92672">/</span> kernel_time, <span style="color:#ae81ff">2</span>) <span style="color:#66d9ef">if</span> kernel_time <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;N/A&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> kernel_time <span style="color:#f92672">&lt;</span> baseline_time:
</span></span><span style="display:flex;"><span>        speedup <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>speedup<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">x&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> kernel_time <span style="color:#f92672">==</span> baseline_time:
</span></span><span style="display:flex;"><span>        speedup <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;1.00x (gi·ªëng h·ªát nhau)&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        speedup <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>kernel_time <span style="color:#f92672">/</span> baseline_time<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">x ch·∫≠m h∆°n&#34;</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>batch_size<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;12</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> | </span><span style="color:#e6db74">{</span>baseline_time<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;18</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> | </span><span style="color:#e6db74">{</span>kernel_time<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;18</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> | </span><span style="color:#e6db74">{</span>speedup<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p><strong>K·∫øt Qu·∫£ D·ª± Ki·∫øn:</strong>
C≈©ng nh∆∞ LayerNorm, m·ªôt implementation RMSNorm ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh t·ªët b·∫±ng c√°ch s·ª≠ d·ª•ng Triton c√≥ th·ªÉ mang l·∫°i t·ªëc ƒë·ªô ƒë√°ng k·ªÉ so v·ªõi phi√™n b·∫£n m·∫∑c ƒë·ªãnh c·ªßa PyTorch‚Äîƒë·∫∑c bi·ªát ƒë·ªëi v·ªõi kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác b·ªã gi·ªõi h·∫°n b·ªô nh·ªõ tr√™n ph·∫ßn c·ª©ng t∆∞∆°ng th√≠ch (v√≠ d·ª•: GPU NVIDIA Ampere ho·∫∑c Hopper) v√† v·ªõi c√°c ki·ªÉu d·ªØ li·ªáu c√≥ ƒë·ªô ch√≠nh x√°c th·∫•p nh∆∞ <code>float16</code> ho·∫∑c <code>bfloat16</code>.</p>
<p><strong>H√£y Nh·ªõ R·∫±ng:</strong></p>
<ul>
<li>K·∫øt qu·∫£ c√≥ th·ªÉ kh√°c nhau t√πy thu·ªôc v√†o GPU, k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o v√† ki·ªÉu d·ªØ li·ªáu c·ªßa b·∫°n.</li>
<li>ƒêi·ªÉm chu·∫©n vi m√¥ c√≥ th·ªÉ xuy√™n t·∫°c hi·ªáu su·∫•t trong th·∫ø gi·ªõi th·ª±c.</li>
<li>Hi·ªáu su·∫•t ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng c·ªßa implementation kernel.</li>
<li>C√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a c√≥ th·ªÉ kh√¥ng mang l·∫°i l·ª£i √≠ch cho c√°c k√≠ch th∆∞·ªõc batch nh·ªè do chi ph√≠ chung.</li>
</ul>
<p>K·∫øt qu·∫£ th·ª±c t·∫ø s·∫Ω ph·ª• thu·ªôc v√†o ph·∫ßn c·ª©ng c·ªßa b·∫°n v√† implementation kernel c·ª• th·ªÉ. D∆∞·ªõi ƒë√¢y l√† m·ªôt v√≠ d·ª• v·ªÅ nh·ªØng g√¨ b·∫°n c√≥ th·ªÉ th·∫•y (tr√™n GPU L4):</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Batch Size</th>
          <th style="text-align: left">Baseline Time (ms)</th>
          <th style="text-align: left">Kernel Time (ms)</th>
          <th style="text-align: left">Speedup</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">256</td>
          <td style="text-align: left">0.2122</td>
          <td style="text-align: left">0.2911</td>
          <td style="text-align: left">0.72x</td>
      </tr>
      <tr>
          <td style="text-align: left">512</td>
          <td style="text-align: left">0.4748</td>
          <td style="text-align: left">0.3312</td>
          <td style="text-align: left">1.43x</td>
      </tr>
      <tr>
          <td style="text-align: left">1024</td>
          <td style="text-align: left">0.8946</td>
          <td style="text-align: left">0.6864</td>
          <td style="text-align: left">1.30x</td>
      </tr>
      <tr>
          <td style="text-align: left">2048</td>
          <td style="text-align: left">2.0289</td>
          <td style="text-align: left">1.3889</td>
          <td style="text-align: left">1.46x</td>
      </tr>
      <tr>
          <td style="text-align: left">4096</td>
          <td style="text-align: left">4.4318</td>
          <td style="text-align: left">2.2467</td>
          <td style="text-align: left">1.97x</td>
      </tr>
      <tr>
          <td style="text-align: left">8192</td>
          <td style="text-align: left">9.2438</td>
          <td style="text-align: left">4.8497</td>
          <td style="text-align: left">1.91x</td>
      </tr>
      <tr>
          <td style="text-align: left">16384</td>
          <td style="text-align: left">18.6992</td>
          <td style="text-align: left">9.8805</td>
          <td style="text-align: left">1.89x</td>
      </tr>
      <tr>
          <td style="text-align: left">32768</td>
          <td style="text-align: left">37.079</td>
          <td style="text-align: left">19.9461</td>
          <td style="text-align: left">1.86x</td>
      </tr>
      <tr>
          <td style="text-align: left">65536</td>
          <td style="text-align: left">73.588</td>
          <td style="text-align: left">39.593</td>
          <td style="text-align: left">1.86x</td>
      </tr>
  </tbody>
</table>
<h2 id="5-c√°c-tr∆∞·ªùng-h·ª£p-s·ª≠-d·ª•ng-th·ª±c-t·∫ø">5. C√°c Tr∆∞·ªùng H·ª£p S·ª≠ D·ª•ng Th·ª±c T·∫ø</h2>
<p>Th∆∞ vi·ªán <code>kernels</code> v·∫´n ƒëang ph√°t tri·ªÉn nh∆∞ng ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu d·ª± √°n c√¥ng vi·ªác th·ª±c t·∫ø kh√°c nhau, bao g·ªìm:</p>
<ul>
<li><!-- raw HTML omitted -->Text Generation Inference<!-- raw HTML omitted -->: D·ª± √°n TGI s·ª≠ d·ª•ng th∆∞ vi·ªán <code>kernels</code> ƒë·ªÉ t·∫£i c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho c√°c t√°c v·ª• t·∫°o vƒÉn b·∫£n, c·∫£i thi·ªán hi·ªáu su·∫•t v√† hi·ªáu qu·∫£.</li>
<li><!-- raw HTML omitted -->Transformers<!-- raw HTML omitted -->: Th∆∞ vi·ªán Transformers ƒë√£ t√≠ch h·ª£p th∆∞ vi·ªán <code>kernels</code> ƒë·ªÉ s·ª≠ d·ª•ng drop in c√°c l·ªõp ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a m√† kh√¥ng y√™u c·∫ßu b·∫•t k·ª≥ thay ƒë·ªïi n√†o ƒë·ªëi v·ªõi m√£ m√¥ h√¨nh. ƒêi·ªÅu n√†y cho ph√©p ng∆∞·ªùi d√πng d·ªÖ d√†ng chuy·ªÉn ƒë·ªïi gi·ªØa c√°c implementation ti√™u chu·∫©n v√† ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a.</li>
</ul>
<h2 id="b·∫Øt-ƒë·∫ßu-v√†-c√°c-b∆∞·ªõc-ti·∫øp-theo">B·∫Øt ƒê·∫ßu v√† C√°c B∆∞·ªõc Ti·∫øp Theo!</h2>
<p>B·∫°n ƒë√£ th·∫•y vi·ªác t√¨m n·∫°p v√† s·ª≠ d·ª•ng c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a d·ªÖ d√†ng nh∆∞ th·∫ø n√†o v·ªõi Hugging Face Kernel Hub. B·∫°n ƒë√£ s·∫µn s√†ng t·ª± m√¨nh th·ª≠ ch∆∞a?</p>
<ol>
<li><strong>C√†i ƒë·∫∑t th∆∞ vi·ªán:</strong></li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install kernels torch numpy
</span></span></code></pre></div><p>ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t phi√™n b·∫£n PyTorch v√† tr√¨nh ƒëi·ªÅu khi·ªÉn gpu t∆∞∆°ng th√≠ch.</p>
<ol start="2">
<li>
<p><strong>Duy·ªát Hub:</strong> Kh√°m ph√° c√°c kernel kh·∫£ d·ª•ng tr√™n Hugging Face Hub d∆∞·ªõi <!-- raw HTML omitted -->tag <code>kernels</code><!-- raw HTML omitted --> ho·∫∑c trong c√°c organization nh∆∞ <!-- raw HTML omitted --><code>kernels-community</code><!-- raw HTML omitted -->. T√¨m ki·∫øm c√°c kernel c√≥ li√™n quan ƒë·∫øn c√°c ho·∫°t ƒë·ªông c·ªßa b·∫°n (k√≠ch ho·∫°t, attention, chu·∫©n h√≥a nh∆∞ LayerNorm/RMSNorm, v.v.).</p>
</li>
<li>
<p><strong>Th·ª≠ Nghi·ªám:</strong> Th·ª≠ thay th·∫ø c√°c th√†nh ph·∫ßn trong m√¥ h√¨nh c·ªßa ri√™ng b·∫°n. S·ª≠ d·ª•ng <code>get_kernel(&quot;user-or-org/kernel-name&quot;)</code>. <strong>ƒêi·ªÅu quan tr·ªçng l√†, h√£y ki·ªÉm tra ƒë·ªëi t∆∞·ª£ng kernel ƒë√£ t·∫£i</strong> (v√≠ d·ª•: <code>print(dir(loaded_kernel))</code> ) ho·∫∑c ki·ªÉm tra t√†i li·ªáu repository Hub c·ªßa n√≥ ƒë·ªÉ hi·ªÉu c√°ch g·ªçi ch√≠nh x√°c c√°c h√†m/ph∆∞∆°ng th·ª©c c·ªßa n√≥ v√† nh·ªØng tham s·ªë (tr·ªçng s·ªë, bias, ƒë·∫ßu v√†o, epsilon) m√† n√≥ mong ƒë·ª£i.</p>
</li>
<li>
<p><strong>ƒêo ƒêi·ªÉm Chu·∫©n:</strong> ƒêo l∆∞·ªùng t√°c ƒë·ªông hi·ªáu su·∫•t tr√™n ph·∫ßn c·ª©ng v√† kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác c·ª• th·ªÉ c·ªßa b·∫°n. ƒê·ª´ng qu√™n ki·ªÉm tra t√≠nh ch√≠nh x√°c v·ªÅ m·∫∑t s·ªë h·ªçc (<code>torch.testing.assert_close</code>).</p>
</li>
<li>
<p><strong>(N√¢ng cao) ƒê√≥ng G√≥p:</strong> N·∫øu b·∫°n ph√°t tri·ªÉn c√°c kernel ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a, h√£y c√¢n nh·∫Øc chia s·∫ª ch√∫ng tr√™n Hub!</p>
</li>
</ol>
<h2 id="k·∫øt-lu·∫≠n">K·∫øt Lu·∫≠n</h2>
<p>Hugging Face Kernel Hub cung c·∫•p m·ªôt c√°ch m·∫°nh m·∫Ω nh∆∞ng ƒë∆°n gi·∫£n ƒë·ªÉ truy c·∫≠p v√† t·∫≠n d·ª•ng c√°c kernel t√≠nh to√°n ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a. B·∫±ng c√°ch thay th·∫ø c√°c th√†nh ph·∫ßn PyTorch ti√™u chu·∫©n b·∫±ng c√°c phi√™n b·∫£n ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho c√°c ho·∫°t ƒë·ªông nh∆∞ RMS Normalization, b·∫°n c√≥ th·ªÉ m·ªü kh√≥a nh·ªØng c·∫£i thi·ªán hi·ªáu su·∫•t ƒë√°ng k·ªÉ m√† kh√¥ng g·∫∑p nh·ªØng ph·ª©c t·∫°p truy·ªÅn th·ªëng c·ªßa c√°c b·∫£n build t√πy ch·ªânh. H√£y nh·ªõ ki·ªÉm tra c√°c th√¥ng s·ªë k·ªπ thu·∫≠t c·ªßa t·ª´ng kernel tr√™n Hub ƒë·ªÉ s·ª≠ d·ª•ng ch√≠nh x√°c. H√£y th·ª≠ v√† xem n√≥ c√≥ th·ªÉ tƒÉng t·ªëc quy tr√¨nh l√†m vi·ªác c·ªßa b·∫°n nh∆∞ th·∫ø n√†o!</p>
<h3 id="link-b√†i-vi·∫øt-g·ªëc"><a href="https://huggingface.co/blog/hello-hf-kernels">Link b√†i vi·∫øt g·ªëc</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/june-12-2025/">June 12, 2025</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-06-12/680408/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/inference-providers/welcome-featherless.jpg" alt="Featherless AI tr√™n Hugging Face Inference Providers üî•" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-06-12T00:00:00&#43;00:00">Jun 12, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Featherless AI tr√™n Hugging Face Inference Providers üî•</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Featherless AI hi·ªán ƒë√£ c√≥ tr√™n Hugging Face Inference Providers!</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-06-13/ace681/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/nvidia-training-cluster/nvidia-training-cluster-thumbnail-compressed.png" alt="Gi·ªõi thi·ªáu c·ª•m ƒë√†o t·∫°o d∆∞·ªõi d·∫°ng d·ªãch v·ª• - m·ªôt s·ª± h·ª£p t√°c m·ªõi v·ªõi NVIDIA" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-06-13T00:00:00&#43;00:00">Jun 13, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Gi·ªõi thi·ªáu c·ª•m ƒë√†o t·∫°o d∆∞·ªõi d·∫°ng d·ªãch v·ª• - m·ªôt s·ª± h·ª£p t√°c m·ªõi v·ªõi NVIDIA</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">C·ª•m ƒë√†o t·∫°o gi√∫p b·∫°n d·ªÖ d√†ng h∆°n bao gi·ªù h·∫øt ƒë·ªÉ b·∫Øt ƒë·∫ßu ƒë√†o t·∫°o m√¥ h√¨nh AI.</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-23/657a6b/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/smol2operator/thumbnail.png" alt="Smol2Operator- ƒê·∫°i l√Ω GUI h·∫≠u hu·∫•n luy·ªán ƒë·ªÉ s·ª≠ d·ª•ng m√°y t√≠nh" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Smol2Operator- ƒê·∫°i l√Ω GUI h·∫≠u hu·∫•n luy·ªán ƒë·ªÉ s·ª≠ d·ª•ng m√°y t√≠nh</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-22/58648e/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://lh3.googleusercontent.com/KrVRFeSqPbxpjcC81NjJbRZig1fB45GEdP0ePsC745QFbZoWMp7X0kPDUFM2sIcILhupUje-eemShX4zSTMutwwCyozz6xc0g1yhGep4TwHzUanW=w400-h225-n-nu" alt="C·ªßng c·ªë Khung Khung An To√†n Ti·ªÅn Tuy·∫øn c·ªßa ch√∫ng t√¥i" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">C·ªßng c·ªë Khung Khung An To√†n Ti·ªÅn Tuy·∫øn c·ªßa ch√∫ng t√¥i</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-22/de97b7/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_mare_gaia2.png" alt="Gaia2 v√† ARE- Trao quy·ªÅn cho c·ªông ƒë·ªìng nghi√™n c·ª©u c√°c t√°c nh√¢n" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Gaia2 v√† ARE- Trao quy·ªÅn cho c·ªông ƒë·ªìng nghi√™n c·ª©u c√°c t√°c nh√¢n</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-09/19e89e/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6e00dbffcddc82df5e471c43453abfc74ca94e8d-1000x1000.svg" alt="Anthropic ƒëang ·ªßng h·ªô d·ª± lu·∫≠t SB 53" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Anthropic ƒëang ·ªßng h·ªô d·ª± lu·∫≠t SB 53</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-02/d324c9/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/zerogpu-aoti/thumbnail.png" alt="T·ªëi ∆∞u h√≥a kh√¥ng gian ZeroGPU c·ªßa b·∫°n v·ªõi vi·ªác bi√™n d·ªãch tr∆∞·ªõc th·ªùi h·∫°n PyTorch" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">T·ªëi ∆∞u h√≥a kh√¥ng gian ZeroGPU c·ªßa b·∫°n v·ªõi vi·ªác bi√™n d·ªãch tr∆∞·ªõc th·ªùi h·∫°n PyTorch</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo d√µi c√°c ti·∫øn b·ªô m·ªõi nh·∫•t v·ªÅ Tr√≠ tu·ªá nh√¢n t·∫°o.<br>Tr·ª±c ti·∫øp t·ª´ c√°c nh√† ph√°t h√†nh AI tr√™n th·∫ø gi·ªõi.
      </p>

      <p>ƒêem tr√≠ tu·ªá nh√¢n t·∫°o ƒë·∫øn m·ªçi ng∆∞·ªùi d√¢n, doanh nghi·ªáp Vi·ªát, g√≥p ph·∫ßn gi√∫p Vi·ªát Nam ph√°t tri·ªÉn m·∫°nh m·∫Ω trong k·ª∑ nguy√™n s·ªë. N·ªôi dung ƒë∆∞·ª£c c·∫≠p nh·∫≠t t·ª± ƒë·ªông b·∫±ng m√°y.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright ¬© 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>