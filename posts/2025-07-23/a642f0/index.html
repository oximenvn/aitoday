<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Suy luận LoRA nhanh cho Flux với Diffusers và PEFT | AI Today - SkyAI</title>

<meta name="description" content="Suy luận LoRA nhanh cho Flux với Diffusers và PEFT">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">Suy luận LoRA nhanh cho Flux với Diffusers và PEFT</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">Suy luận LoRA nhanh cho Flux với Diffusers và PEFT </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-07-23T00:00:00&#43;00:00">July 23, 2025</time>
          </li>

          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2">
            12 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://huggingface.co/blog/assets/lora-fast/thumbnail.png" alt="Suy luận LoRA nhanh cho Flux với Diffusers và PEFT">
        <figcaption class="text-center italic text-xs">Suy luận LoRA nhanh cho Flux với Diffusers và PEFT</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="suy-luận-lora-nhanh-cho-flux-với-diffusers-và-peft">Suy luận LoRA nhanh cho Flux với Diffusers và PEFT</h1>
<p>LoRA adapter cung cấp một mức độ tùy biến tuyệt vời cho các mô hình thuộc mọi hình dạng và kích thước. Khi nói đến tạo ảnh, chúng có thể trao quyền cho các mô hình với <a href="https://huggingface.co/spaces/multimodalart/flux-lora-the-explorer">các kiểu khác nhau, các nhân vật khác nhau và nhiều hơn nữa</a>. Đôi khi, chúng cũng có thể được tận dụng <a href="https://huggingface.co/ByteDance/Hyper-SD/">để giảm độ trễ suy luận</a>. Do đó, tầm quan trọng của chúng là tối quan trọng, đặc biệt khi nói đến tùy chỉnh và tinh chỉnh các mô hình.</p>
<p>Trong bài đăng này, chúng tôi sử dụng <a href="https://huggingface.co/black-forest-labs/FLUX.1-dev">mô hình Flux.1-Dev</a> để tạo văn bản thành hình ảnh vì sự phổ biến và chấp nhận rộng rãi của nó, đồng thời làm thế nào để tối ưu hóa tốc độ suy luận của nó khi sử dụng LoRA (~2.3x). Nó có hơn 30 nghìn bộ điều hợp được đào tạo với nó (<a href="https://huggingface.co/models?other=base_model:adapter:black-forest-labs/FLUX.1-dev">như đã báo cáo</a> trên nền tảng Hugging Face Hub). Do đó, tầm quan trọng của nó đối với cộng đồng là rất lớn.</p>
<p>Lưu ý rằng mặc dù chúng tôi chứng minh khả năng tăng tốc với Flux, nhưng chúng tôi tin rằng công thức của chúng tôi đủ chung để có thể áp dụng cho các mô hình khác.</p>
<p>Nếu bạn nóng lòng muốn bắt đầu với mã, vui lòng xem <a href="https://github.com/huggingface/lora-fast">kho mã đi kèm</a>.</p>
<h3 id="mục-lục">Mục lục</h3>
<ul>
<li><a href="#hurdles-in-optimizing-lora-inference">Những trở ngại trong việc tối ưu hóa suy luận LoRA</a></li>
<li><a href="#optimization-recipe">Công thức tối ưu hóa</a></li>
<li><a href="#optimized-lora-inference-on-a-consumer-gpu">Suy luận LoRA được tối ưu hóa trên GPU tiêu dùng</a></li>
<li><a href="#conclusion">Kết luận</a></li>
</ul>
<h1 id="những-trở-ngại-trong-việc-tối-ưu-hóa-suy-luận-lora">Những trở ngại trong việc tối ưu hóa suy luận LoRA</h1>
<p>Khi phục vụ LoRA, việc hoán đổi nóng (hoán đổi và hoán đổi các LoRA khác nhau) chúng là điều phổ biến. LoRA thay đổi kiến trúc mô hình cơ sở. Ngoài ra, LoRA có thể khác nhau - mỗi LoRA có thể có các thứ hạng khác nhau và các lớp khác nhau mà chúng nhắm mục tiêu để điều chỉnh. Để tính đến các thuộc tính động này của LoRA, chúng ta phải thực hiện các bước cần thiết để đảm bảo các tối ưu hóa mà chúng ta áp dụng là mạnh mẽ.</p>
<p>Ví dụ: chúng ta có thể áp dụng <code>torch.compile</code> trên một mô hình được tải với một LoRA cụ thể để có được khả năng tăng tốc trên độ trễ suy luận. Tuy nhiên, ngay khi chúng ta hoán đổi LoRA với một LoRA khác (có khả năng có cấu hình khác), chúng ta sẽ gặp phải các sự cố biên dịch lại, gây ra tình trạng chậm lại trong quá trình suy luận.</p>
<p>Người ta cũng có thể hợp nhất các tham số LoRA vào các tham số mô hình cơ sở, chạy biên dịch và bỏ hợp nhất các tham số LoRA khi tải các tham số mới. Tuy nhiên, cách tiếp cận này sẽ lại gặp phải vấn đề biên dịch lại bất cứ khi nào quá trình suy luận được chạy, do các thay đổi tiềm ẩn ở cấp độ kiến trúc.</p>
<p>Công thức tối ưu hóa của chúng tôi có tính đến các tình huống nói trên để thực tế nhất có thể. Dưới đây là các thành phần chính trong công thức tối ưu hóa của chúng tôi:</p>
<ul>
<li>Flash Attention 3 (FA3)</li>
<li><code>torch.compile</code></li>
<li>Lượng tử hóa FP8 từ TorchAO</li>
<li>Sẵn sàng hoán đổi nóng</li>
</ul>
<p>Lưu ý rằng trong số những điều đã nói ở trên, lượng tử hóa FP8 bị mất mát nhưng thường cung cấp sự đánh đổi về tốc độ-bộ nhớ đáng gờm nhất. Mặc dù chúng tôi đã thử nghiệm công thức chủ yếu bằng GPU NVIDIA, nhưng nó cũng sẽ hoạt động trên GPU AMD.</p>
<h1 id="công-thức-tối-ưu-hóa">Công thức tối ưu hóa</h1>
<p>Trong các bài đăng trên blog trước đây của chúng tôi (<a href="https://pytorch.org/blog/presenting-flux-fast-making-flux-go-brrr-on-h100s/">bài đăng 1</a> và <a href="https://pytorch.org/blog/torch-compile-and-diffusers-a-hands-on-guide-to-peak-performance/">bài đăng 2</a>), chúng tôi đã thảo luận về lợi ích của việc sử dụng ba thành phần đầu tiên trong công thức tối ưu hóa của chúng tôi. Áp dụng chúng từng cái một chỉ là một vài dòng mã:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> diffusers <span style="color:#f92672">import</span> DiffusionPipeline, TorchAoConfig
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> diffusers.quantizers <span style="color:#f92672">import</span> PipelineQuantizationConfig
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> utils.fa3_processor <span style="color:#f92672">import</span> FlashFluxAttnProcessor3_0
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># lượng tử hóa bộ biến đổi Flux với FP8</span>
</span></span><span style="display:flex;"><span>pipe <span style="color:#f92672">=</span> DiffusionPipeline<span style="color:#f92672">.</span>from_pretrained(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;black-forest-labs/FLUX.1-dev&#34;</span>, 
</span></span><span style="display:flex;"><span>    torch_dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>bfloat16, 
</span></span><span style="display:flex;"><span>    quantization_config<span style="color:#f92672">=</span>PipelineQuantizationConfig(
</span></span><span style="display:flex;"><span>        quant_mapping<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;transformer&#34;</span>: TorchAoConfig(<span style="color:#e6db74">&#34;float8dq_e4m3_row&#34;</span>)}
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#34;cuda&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sử dụng Flash-attention 3</span>
</span></span><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>set_attn_processor(FlashFluxAttnProcessor3_0())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sử dụng torch.compile()</span>
</span></span><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>compile(fullgraph<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;max-autotune&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># thực hiện suy luận</span>
</span></span><span style="display:flex;"><span>pipe_kwargs <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;prompt&#34;</span>: <span style="color:#e6db74">&#34;Một con mèo đang cầm một tấm biển có dòng chữ xin chào thế giới&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;height&#34;</span>: <span style="color:#ae81ff">1024</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;width&#34;</span>: <span style="color:#ae81ff">1024</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;guidance_scale&#34;</span>: <span style="color:#ae81ff">3.5</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;num_inference_steps&#34;</span>: <span style="color:#ae81ff">28</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;max_sequence_length&#34;</span>: <span style="color:#ae81ff">512</span>,
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># lần đầu tiên sẽ chậm hơn, các lần chạy tiếp theo sẽ nhanh hơn</span>
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> pipe(<span style="color:#f92672">**</span>pipe_kwargs)<span style="color:#f92672">.</span>images[<span style="color:#ae81ff">0</span>]
</span></span></code></pre></div><p><em>Bộ xử lý FA3 đến từ <a href="https://github.com/huggingface/lora-fast/blob/main/utils/fa3_processor.py">đây</a>.</em></p>
<p>Các vấn đề bắt đầu nổi lên khi chúng ta cố gắng hoán đổi và hoán đổi LoRA vào một bộ biến đổi khuếch tán đã được biên dịch (<code>pipe.transformer</code>) mà không kích hoạt quá trình biên dịch lại.</p>
<p>Thông thường, việc tải và dỡ LoRA sẽ yêu cầu biên dịch lại, điều này làm mất đi bất kỳ lợi thế tốc độ nào đạt được từ quá trình biên dịch. May mắn thay, có một cách để tránh sự cần thiết phải biên dịch lại. Bằng cách chuyển <code>hotswap=True</code>, diffusers sẽ giữ nguyên kiến trúc mô hình và chỉ trao đổi trọng số của chính bộ điều hợp LoRA, điều này không cần thiết phải biên dịch lại.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>enable_lora_hotswap(target_rank<span style="color:#f92672">=</span>max_rank)
</span></span><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>load_lora_weights(<span style="color:#f92672">&amp;</span>lt;tên<span style="color:#f92672">-</span>bộ<span style="color:#f92672">-</span>điều<span style="color:#f92672">-</span>hợp<span style="color:#f92672">-</span>lora1<span style="color:#f92672">&amp;</span>gt;)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># biên dịch *sau khi* tải LoRA đầu tiên</span>
</span></span><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>compile(mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;max-autotune&#34;</span>, fullgraph<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> pipe(<span style="color:#f92672">**</span>pipe_kwargs)<span style="color:#f92672">.</span>images[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span><span style="color:#75715e"># kể từ thời điểm này, hãy tải các LoRA mới bằng `hotswap=True`</span>
</span></span><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>load_lora_weights(<span style="color:#f92672">&amp;</span>lt;tên<span style="color:#f92672">-</span>bộ<span style="color:#f92672">-</span>điều<span style="color:#f92672">-</span>hợp<span style="color:#f92672">-</span>lora2<span style="color:#f92672">&amp;</span>gt;, hotswap<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> pipe(<span style="color:#f92672">**</span>pipe_kwargs)<span style="color:#f92672">.</span>images[<span style="color:#ae81ff">0</span>]
</span></span></code></pre></div><p><em>(Để nhắc nhở, lần gọi đầu tiên đến <code>pipe</code> sẽ chậm vì <code>torch.compile</code> là trình biên dịch just-in-time. Tuy nhiên, các lệnh gọi tiếp theo sẽ nhanh hơn đáng kể.)</em></p>
<p>Điều này thường cho phép hoán đổi LoRA mà không cần biên dịch lại, nhưng có những hạn chế:</p>
<ul>
<li>Chúng ta cần cung cấp thứ hạng tối đa trong số tất cả các bộ điều hợp LoRA trước. Do đó, nếu chúng ta có một bộ điều hợp có thứ hạng 16 và một bộ điều hợp khác có 32, chúng ta cần chuyển <code>max_rank=32</code>.</li>
<li>Các bộ điều hợp LoRA được hoán đổi nóng chỉ có thể nhắm mục tiêu đến cùng một lớp hoặc một tập hợp con các lớp mà LoRA đầu tiên nhắm mục tiêu.</li>
<li>Việc nhắm mục tiêu bộ mã hóa văn bản chưa được hỗ trợ.</li>
</ul>
<p>Để biết thêm thông tin về hoán đổi nóng trong Diffusers và các hạn chế của nó, hãy truy cập <a href="https://huggingface.co/docs/diffusers/main/en/tutorials/using_peft_for_inference#hotswapping">phần hoán đổi nóng của tài liệu</a>.</p>
<p>Lợi ích của quy trình làm việc này trở nên rõ ràng khi chúng ta xem xét độ trễ suy luận mà không sử dụng quá trình biên dịch với hoán đổi nóng.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Tùy chọn</th>
          <th style="text-align: left">Thời gian (s) ⬇️</th>
          <th style="text-align: left">Tăng tốc (so với đường cơ sở) ⬆️</th>
          <th style="text-align: left">Ghi chú</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">đường cơ sở</td>
          <td style="text-align: left">7.8910</td>
          <td style="text-align: left">–</td>
          <td style="text-align: left">Đường cơ sở</td>
      </tr>
      <tr>
          <td style="text-align: left">được tối ưu hóa</td>
          <td style="text-align: left">3.5464</td>
          <td style="text-align: left">2.23×</td>
          <td style="text-align: left">Hoán đổi nóng + biên dịch mà không gặp trục trặc khi biên dịch lại (FP8 bật theo mặc định)</td>
      </tr>
      <tr>
          <td style="text-align: left">không_fp8</td>
          <td style="text-align: left">4.3520</td>
          <td style="text-align: left">1.81×</td>
          <td style="text-align: left">Giống như được tối ưu hóa, nhưng tắt lượng tử hóa FP8</td>
      </tr>
      <tr>
          <td style="text-align: left">không_fa3</td>
          <td style="text-align: left">4.3020</td>
          <td style="text-align: left">1.84×</td>
          <td style="text-align: left">Tắt FA3 (flash‑attention v3)</td>
      </tr>
      <tr>
          <td style="text-align: left">đường cơ sở + biên dịch</td>
          <td style="text-align: left">5.0920</td>
          <td style="text-align: left">1.55×</td>
          <td style="text-align: left">Bật biên dịch, nhưng bị gián đoạn bởi các quầy hàng biên dịch lại không liên tục</td>
      </tr>
      <tr>
          <td style="text-align: left">không_fa3_fp8</td>
          <td style="text-align: left">5.0850</td>
          <td style="text-align: left">1.55×</td>
          <td style="text-align: left">Tắt FA3 và FP8</td>
      </tr>
      <tr>
          <td style="text-align: left">không_biên_dịch_fp8</td>
          <td style="text-align: left">7.5190</td>
          <td style="text-align: left">1.05×</td>
          <td style="text-align: left">Tắt lượng tử hóa FP8 và biên dịch</td>
      </tr>
      <tr>
          <td style="text-align: left">không_biên_dịch</td>
          <td style="text-align: left">10.4340</td>
          <td style="text-align: left">0.76×</td>
          <td style="text-align: left">Tắt biên dịch: cài đặt chậm nhất</td>
      </tr>
  </tbody>
</table>
<p><strong>Những điểm chính</strong>:</p>
<ul>
<li>Tùy chọn &ldquo;thông thường + biên dịch&rdquo; cung cấp khả năng tăng tốc kha khá so với tùy chọn thông thường, nhưng nó gây ra các sự cố biên dịch lại, làm tăng thời gian thực hiện tổng thể. Trong các điểm chuẩn của chúng tôi, chúng tôi không trình bày thời gian biên dịch.</li>
<li>Khi các vấn đề biên dịch lại được loại bỏ thông qua hoán đổi nóng (còn được gọi là tùy chọn &ldquo;được tối ưu hóa&rdquo;), chúng ta đạt được khả năng tăng tốc cao nhất.</li>
<li>Trong tùy chọn &ldquo;được tối ưu hóa&rdquo;, lượng tử hóa FP8 được bật, điều này có thể dẫn đến mất chất lượng. Ngay cả khi không sử dụng FP8, chúng ta vẫn nhận được một lượng tăng tốc kha khá (tùy chọn &ldquo;không_fp8&rdquo;).</li>
<li>Với mục đích trình diễn, chúng tôi sử dụng một nhóm gồm hai LoRA để hoán đổi nóng với quá trình biên dịch. Để có mã đầy đủ, vui lòng tham khảo <a href="https://github.com/huggingface.com/lora-fast">kho mã</a> đi kèm.</li>
</ul>
<p>Công thức tối ưu hóa mà chúng tôi đã thảo luận cho đến nay giả định quyền truy cập vào một GPU mạnh mẽ như H100. Tuy nhiên, chúng ta có thể làm gì khi chúng ta bị giới hạn trong việc sử dụng GPU tiêu dùng như RTX 4090? Hãy cùng tìm hiểu.</p>
<h1 id="suy-luận-lora-được-tối-ưu-hóa-trên-gpu-tiêu-dùng">Suy luận LoRA được tối ưu hóa trên GPU tiêu dùng</h1>
<p>Flux.1-Dev (không có bất kỳ LoRA nào), sử dụng kiểu dữ liệu Bfloat16, cần ~33GB bộ nhớ để chạy. Tùy thuộc vào kích thước của mô-đun LoRA và không sử dụng bất kỳ tối ưu hóa nào, mức sử dụng bộ nhớ này có thể tăng hơn nữa. Nhiều GPU tiêu dùng như RTX 4090 chỉ có 24GB. Trong phần còn lại của phần này, chúng ta sẽ coi một máy RTX 4090 là bệ thử nghiệm của chúng ta.</p>
<p>Đầu tiên, để cho phép thực thi Flux.1-Dev từ đầu đến cuối, chúng ta có thể áp dụng CPU offloading, trong đó các thành phần không cần thiết để thực thi tính toán hiện tại được chuyển sang CPU để giải phóng thêm bộ nhớ tăng tốc. Làm như vậy cho phép chúng ta chạy toàn bộ quy trình trong ~22GB trong <strong>35.403 giây</strong> trên RTX 4090. Bật quá trình biên dịch có thể giảm độ trễ xuống còn <strong>31.205 giây</strong> (tăng tốc 1.12x). Về mã, nó chỉ là một vài dòng:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>pipe <span style="color:#f92672">=</span> DiffusionPipeline<span style="color:#f92672">.</span>from_pretrained(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;black-forest-labs/FLUX.1-dev&#34;</span>, torch_dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>bfloat16,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>enable_model_cpu_offload()
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Thay vì biên dịch đầy đủ, chúng ta áp dụng biên dịch khu vực</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ở đây để tận dụng `fullgraph=True` và cũng để giảm</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># thời gian biên dịch. Bạn có thể tìm thêm chi tiết ở đây:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://hf.co/docs/diffusers/main/en/optimization/fp16#regional-compilation</span>
</span></span><span style="display:flex;"><span>pipe<span style="color:#f92672">.</span>transformer<span style="color:#f92672">.</span>compile_repeated_blocks(fullgraph<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image <span style="color:#f92672">=</span> pipe(<span style="color:#f92672">**</span>pipe_kwargs)<span style="color:#f92672">.</span>images[<span style="color:#ae81ff">0</span>]
</span></span></code></pre></div><p>Lưu ý rằng chúng ta không áp dụng lượng tử hóa FP8 ở đây vì nó không được hỗ trợ với CPU offloading và biên dịch (hỗ trợ <a href="https://github.com/pytorch/pytorch/issues/141548">chuỗi vấn đề</a>). Do đó, chỉ cần áp dụng lượng tử hóa FP8 cho Flux Transformer là không đủ để giảm thiểu vấn đề cạn kiệt bộ nhớ. Trong trường hợp này, chúng ta đã quyết định xóa nó.</p>
<p>Do đó, để tận dụng sơ đồ lượng tử hóa FP8, chúng ta cần tìm cách thực hiện nó mà không cần CPU offloading. Đối với Flux.1-Dev, nếu chúng ta áp dụng thêm lượng tử hóa cho bộ mã hóa văn bản T5, chúng ta sẽ có thể tải và chạy toàn bộ quy trình trong 24GB. Dưới đây là so sánh kết quả có và không có bộ mã hóa văn bản T5 được lượng tử hóa (lượng tử hóa NF4 từ <a href="https://huggingface.co/docs/diffusers/main/en/quantization/bitsandbytes"><code>bitsandbytes</code></a>).</p>
<!-- raw HTML omitted -->
<p>Như chúng ta có thể nhận thấy trong hình trên, việc lượng tử hóa bộ mã hóa văn bản T5 không gây ra quá nhiều mất mát về chất lượng. Kết hợp bộ mã hóa văn bản T5 đã lượng tử hóa và Flux Transformer đã lượng tử hóa FP8 với <code>torch.compile</code> mang lại cho chúng ta kết quả khá hợp lý - <strong>9.668 giây</strong> từ 32.27 giây (tăng tốc ~3.3x lớn) mà không làm giảm chất lượng đáng kể.</p>
<!-- raw HTML omitted -->
<p>Có thể tạo hình ảnh với 24 GB VRAM ngay cả khi không lượng tử hóa bộ mã hóa văn bản T5, nhưng điều đó sẽ làm cho quy trình tạo của chúng ta trở nên phức tạp hơn một chút.</p>
<p>Chúng ta hiện có một cách để chạy toàn bộ quy trình Flux.1-Dev với lượng tử hóa FP8 trên RTX 4090. Chúng ta có thể áp dụng công thức tối ưu hóa đã thiết lập trước đó để tối ưu hóa suy luận LoRA trên cùng một phần cứng. Vì FA3 không được hỗ trợ trên RTX 4090, nên chúng ta sẽ tuân theo công thức tối ưu hóa sau với lượng tử hóa T5 mới được thêm vào:</p>
<ul>
<li>Lượng tử hóa FP8</li>
<li><code>torch.compile</code></li>
<li>Sẵn sàng hoán đổi nóng</li>
<li>Lượng tử hóa T5 (với NF4)</li>
</ul>
<p>Trong bảng dưới đây, chúng ta hiển thị các số độ trễ suy luận với các kết hợp khác nhau của các thành phần trên được áp dụng.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Tùy chọn</th>
          <th style="text-align: left">Cờ args chính</th>
          <th style="text-align: left">Thời gian (s) ⬇️</th>
          <th style="text-align: left">Tăng tốc (so với đường cơ sở) ⬆️</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">đường cơ sở</td>
          <td style="text-align: left"><code>disable_fp8=False disable_compile=True</code>  <code>quantize_t5=True offload=False</code></td>
          <td style="text-align: left">23.6060</td>
          <td style="text-align: left">–</td>
      </tr>
      <tr>
          <td style="text-align: left">được tối ưu hóa</td>
          <td style="text-align: left"><code>disable_fp8=False disable_compile=False</code>  <code>quantize_t5=True offload=False</code></td>
          <td style="text-align: left">11.5715</td>
          <td style="text-align: left">2.04×</td>
      </tr>
  </tbody>
</table>
<p><strong>Ghi chú nhanh</strong>:</p>
<ul>
<li>Quá trình biên dịch cung cấp khả năng tăng tốc 2x lớn so với đường cơ sở.</li>
<li>Các tùy chọn khác mang lại lỗi OOM ngay cả khi đã bật offloading.</li>
</ul>
<h1 id="kết-luận">Kết luận</h1>
<p>Bài đăng này đã phác thảo một công thức tối ưu hóa để suy luận LoRA nhanh với Flux, chứng minh khả năng tăng tốc đáng kể. Cách tiếp cận của chúng tôi kết hợp Flash Attention 3, <code>torch.compile</code> và lượng tử hóa FP8 đồng thời đảm bảo khả năng hoán đổi nóng mà không gặp sự cố khi biên dịch lại. Trên các GPU cao cấp như H100, thiết lập được tối ưu hóa này cung cấp khả năng tăng tốc 2.23x so với đường cơ sở.</p>
<p>Đối với GPU tiêu dùng, cụ thể là RTX 4090, chúng tôi đã giải quyết các giới hạn về bộ nhớ bằng cách giới thiệu lượng tử hóa bộ mã hóa văn bản T5 (NF4) và tận dụng quá trình biên dịch khu vực. Công thức toàn diện này đạt được khả năng tăng tốc đáng kể 2.04x, làm cho suy luận LoRA trên Flux khả thi và hiệu quả ngay cả với VRAM hạn chế. Thông tin chi tiết chính là bằng cách quản lý cẩn thận quá trình biên dịch và lượng tử hóa, lợi ích của LoRA có thể được nhận ra đầy đủ trên các cấu hình phần cứng khác nhau.</p>
<p>Hy vọng rằng các công thức từ bài đăng này sẽ truyền cảm hứng cho bạn để tối ưu hóa
các trường hợp sử dụng dựa trên LoRA của bạn, hưởng lợi từ suy luận nhanh chóng.</p>
<h2 id="tài-nguyên">Tài nguyên</h2>
<p>Dưới đây là danh sách các tài nguyên quan trọng mà chúng tôi đã trích dẫn trong suốt bài đăng này:</p>
<ul>
<li><a href="https://pytorch.org/blog/presenting-flux-fast-making-flux-go-brrr-on-h100s/">Giới thiệu Flux Fast: Làm cho Flux hoạt động trên H100</a></li>
<li><a href="https://pytorch.org/blog/torch-compile-and-diffusers-a-hands-on-guide-to-peak-performance/">torch.compile và Diffusers: Hướng dẫn thực hành để đạt hiệu suất cao nhất</a></li>
<li><a href="https://huggingface.co/docs/diffusers/main/en/tutorials/using_peft_for_inference">Hướng dẫn LoRA trong Diffusers</a></li>
</ul>
<h3 id="link-bài-viết-gốc"><a href="https://huggingface.co/blog/lora-fast">Link bài viết gốc</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/july-23-2025/">July 23, 2025</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-07-20/5ee102/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/virtual-cell-challenge/thumbnail.png" alt="Thử thách ô ảo Arc- Sơ cấp" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-07-20T00:00:00&#43;00:00">Jul 20, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Thử thách ô ảo Arc- Sơ cấp</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Bài viết này cung cấp một cái nhìn tổng quan về Thử thách Ô ảo Arc, một cuộc thi nhằm mục đích phát triển các tác nhân AI có thể điều khiển một ô ảo để đạt được mục tiêu phức tạp.</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-07-19/39aba8/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/consilium-multi-llm/thumbnail.png" alt="Consilium- Khi Nhiều LLM Cộng Tác" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-07-19T00:00:00&#43;00:00">Jul 19, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Consilium- Khi Nhiều LLM Cộng Tác</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Bài viết này thảo luận về Consilium, một phương pháp tiếp cận trong đó nhiều LLM hợp tác để cải thiện hiệu suất.</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-08-12/33b3cb/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/openai/openai-hf-thumbnail.png" alt="Chào mừng GPT OSS, dòng mô hình mã nguồn mở mới từ OpenAI!" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Chào mừng GPT OSS, dòng mô hình mã nguồn mở mới từ OpenAI!</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-08-12/a072d3/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6e00dbffcddc82df5e471c43453abfc74ca94e8d-1000x1000.svg" alt="Cung cấp khả năng truy cập Claude mở rộng trên cả ba nhánh của chính phủ Hoa Kỳ" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Cung cấp khả năng truy cập Claude mở rộng trên cả ba nhánh của chính phủ Hoa Kỳ</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-08-12/efd4ea/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://venturebeat.com/wp-content/uploads/2025/08/nuneybits_Vector_art_of_human_and_AI_sharing_keyboard_9a3adda9-66ab-4482-8716-8d7eda0c5b72.webp?w=700&amp;h=350&amp;crop=1" alt="Nghiên cứu cảnh báo về các rủi ro bảo mật khi &#39;tác nhân hệ điều hành&#39; giành quyền kiểm soát máy tính và điện thoại" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Nghiên cứu cảnh báo về các rủi ro bảo mật khi &#39;tác nhân hệ điều hành&#39; giành quyền kiểm soát máy tính và điện thoại</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-08-12/afa7dd/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://venturebeat.com/wp-content/uploads/2025/08/crimedy7_illustration_of_a_trading_floor_but_the_traders_are__371ae64a-395f-485f-bcfd-19fb4cceec66_1.png?w=700&amp;h=350&amp;crop=1" alt="TD Securities khai thác Layer 6 và OpenAI để cung cấp thông tin chi tiết về vốn chủ sở hữu theo thời gian thực cho các nhóm bán hàng và giao dịch" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">TD Securities khai thác Layer 6 và OpenAI để cung cấp thông tin chi tiết về vốn chủ sở hữu theo thời gian thực cho các nhóm bán hàng và giao dịch</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-08-11/44de11/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Anthropic bổ nhiệm Hidetoshi Tojo làm Giám đốc Nhật Bản và công bố kế hoạch tuyển dụng</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo dõi các tiến bộ mới nhất về Trí tuệ nhân tạo.<br>Trực tiếp từ các nhà phát hành AI trên thế giới.
      </p>

      <p>Đem trí tuệ nhân tạo đến mọi người dân, doanh nghiệp Việt, góp phần giúp Việt Nam phát triển mạnh mẽ trong kỷ nguyên số. Nội dung được cập nhật tự động bằng máy.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright © 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>