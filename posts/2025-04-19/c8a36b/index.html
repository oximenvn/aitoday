<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Cải tiến hệ thống AI thông qua tiến bộ trong nhận thức, định vị và suy luận | AI Today - SkyAI</title>

<meta name="description" content="Meta FAIR phát hành một số hiện vật nghiên cứu mới giúp nâng cao hiểu biết của chúng ta về nhận thức và hỗ trợ mục tiêu đạt được trí tuệ máy móc tiên tiến (AMI).">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">Cải tiến hệ thống AI thông qua tiến bộ trong nhận thức, định vị và suy luận</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">Meta FAIR phát hành một số hiện vật nghiên cứu mới giúp nâng cao hiểu biết của chúng ta về nhận thức và hỗ trợ mục tiêu đạt được trí tuệ máy móc tiên tiến (AMI). </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-04-19T00:00:00&#43;00:00">April 19, 2025</time>
          </li>

          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2">
            13 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://scontent.fhan15-2.fna.fbcdn.net/v/t39.2365-6/492216842_576463918172339_3408275426150658552_n.png?_nc_cat=107&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=_mkRDzBZ93cQ7kNvwFB3ECK&amp;_nc_oc=AdmW_dBLMWf4lNNbwDrQDlc39xLK-KZDzpEgwqlJPV9qeccSsBM-8-YRcxCaoY_9T1k2xufc7GkFzi8UxGwUqwol&amp;_nc_zt=14&amp;_nc_ht=scontent.fhan15-2.fna&amp;_nc_gid=bxKVrJZc-I1NQYfARbWnzQ&amp;oh=00_AfHitfPRtZX-kZOAi2C5F39EnnrWDNtXV8CCo4JYQUi91Q&amp;oe=681DD416" alt="Cải tiến hệ thống AI thông qua tiến bộ trong nhận thức, định vị và suy luận">
        <figcaption class="text-center italic text-xs">Meta FAIR phát hành một số hiện vật nghiên cứu mới giúp nâng cao hiểu biết của chúng ta về nhận thức và hỗ trợ mục tiêu đạt được trí tuệ máy móc tiên tiến (AMI).</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h2 id="nâng-cao-hệ-thống-ai-thông-qua-những-tiến-bộ-trong-nhận-thức-định-vị-và-lý-luận">Nâng cao hệ thống AI thông qua những tiến bộ trong nhận thức, định vị và lý luận</h2>
<p>Meta FAIR đang phát hành một số sản phẩm nghiên cứu mới nhằm nâng cao sự hiểu biết của chúng ta về nhận thức và hỗ trợ mục tiêu đạt được trí tuệ máy móc tiên tiến (AMI).</p>
<p><strong>Những điểm chính:</strong></p>
<ul>
<li>Meta FAIR đang phát hành một số sản phẩm nghiên cứu mới nhằm nâng cao sự hiểu biết của chúng ta về nhận thức và hỗ trợ mục tiêu đạt được trí tuệ máy móc tiên tiến (AMI).</li>
<li>Công việc mà chúng tôi chia sẻ bao gồm Meta Perception Encoder, nhằm xây dựng các hệ thống thị giác máy tính tiên tiến hơn có thể hỗ trợ mọi người trong các công việc hàng ngày, chẳng hạn như nhận dạng hình ảnh và phát hiện đối tượng. Chúng tôi cũng chia sẻ những tiến bộ trong việc hiểu cảnh 3D và định vị các đối tượng từ các truy vấn bằng ngôn ngữ tự nhiên — tất cả đều là những phát triển quan trọng trên con đường đạt được các hệ thống AI tinh vi hơn.</li>
<li>Chúng tôi cũng giới thiệu Collaborative Reasoner, một khuôn khổ để đánh giá và cải thiện các kỹ năng lý luận hợp tác của các mô hình ngôn ngữ lớn, đây là một bước quan trọng hướng tới việc xây dựng các tác nhân xã hội hợp tác.</li>
<li>Bằng cách cung cấp rộng rãi nghiên cứu của mình, chúng tôi mong muốn cung cấp khả năng truy cập dễ dàng cho cộng đồng nghiên cứu và giúp thúc đẩy một hệ sinh thái mở cho AI, đẩy nhanh tiến độ và khám phá.</li>
</ul>
<p>Khi chúng tôi làm việc để đạt được mục tiêu về trí tuệ máy móc tiên tiến (AMI), điều quan trọng là phải có các mô hình, điểm chuẩn và tập dữ liệu tập trung vào nhận thức. Chúng ta cần những cỗ máy có khả năng thu thập, xử lý và giải thích thông tin cảm giác về thế giới xung quanh và có thể sử dụng thông tin này để đưa ra quyết định với trí thông minh và tốc độ giống như con người. Hôm nay, chúng tôi rất vui mừng được công khai phát hành năm công trình mới từ nhóm Meta Fundamental AI Research (FAIR), đưa chúng ta đến gần hơn với mục tiêu đó.</p>
<h2 id="meta-perception-encoder-thiết-lập-các-tiêu-chuẩn-mới-cho-mô-hình-hóa-tầm-nhìn-phù-hợp-với-ngôn-ngữ">Meta Perception Encoder: Thiết lập các tiêu chuẩn mới cho mô hình hóa tầm nhìn phù hợp với ngôn ngữ</h2>
<p>Chúng tôi rất vui mừng được giới thiệu Perception Encoder, một bộ mã hóa tầm nhìn quy mô lớn, vượt trội trong một số nhiệm vụ tầm nhìn cho hình ảnh và video. Bộ mã hóa tầm nhìn đóng vai trò là &ldquo;đôi mắt&rdquo; cho phép các hệ thống AI diễn giải thông tin trực quan và hiểu rõ hơn về thế giới. Khi các hệ thống AI trở nên tiên tiến hơn, việc xây dựng một bộ mã hóa tầm nhìn đáp ứng mọi kỳ vọng về trí thông minh tiên tiến thậm chí còn trở nên khó khăn hơn. Để đạt được điều này, bộ mã hóa tầm nhìn phải kết nối tầm nhìn và ngôn ngữ, hoạt động tốt trên hình ảnh và video, đồng thời mạnh mẽ trước các điều kiện đầy thách thức và có khả năng gây hại khác nhau. Bộ mã hóa tầm nhìn cũng phải có khả năng nhận ra một loạt các khái niệm đồng thời đủ nhạy bén để phân biệt các khác biệt nhỏ, chẳng hạn như các loài động vật khác nhau.</p>
<p>Perception Encoder thể hiện hiệu suất vượt trội về phân loại và truy xuất không cần ảnh và video, vượt qua tất cả các mô hình độc quyền và mã nguồn mở hiện có cho các tác vụ như vậy. Nó cũng hoạt động đặc biệt tốt trên các tác vụ &ldquo;khó&rdquo;, chẳng hạn như nhận ra một con cá đuối gai độc nằm dưới đáy biển, xác định một con chim sẻ nhỏ bé ở hậu cảnh của một hình ảnh hoặc bắt một con chuột lang đang chạy trốn trên một chiếc máy ảnh quan sát động vật hoang dã vào ban đêm.</p>
<p>Những khả năng nhận thức mạnh mẽ này chuyển sang các nhiệm vụ ngôn ngữ hạ nguồn. Sau khi điều chỉnh theo một mô hình ngôn ngữ lớn, Perception Encoder vượt qua tất cả các bộ mã hóa tầm nhìn khác để trả lời câu hỏi bằng hình ảnh và video, chú thích, hiểu tài liệu và nền tảng. Perception Encoder cũng cho phép cải thiện đáng kể các tác vụ vốn khó khăn đối với các mô hình ngôn ngữ, chẳng hạn như cho biết liệu một đối tượng có ở phía sau đối tượng khác hay không hoặc liệu máy ảnh có đang di chuyển theo chiều kim đồng hồ xung quanh một đối tượng hay không.</p>
<p>Khi Perception Encoder bắt đầu được tích hợp vào các ứng dụng mới, chúng tôi rất vui mừng được thấy những khả năng tầm nhìn tiên tiến của nó sẽ cho phép các hệ thống AI có khả năng hơn nữa như thế nào.</p>
<ul>
<li><a href="https://huggingface.co/collections/facebook/perception-encoder-67f977c9a65ca5895a7f6ba1">Tải xuống mô hình</a></li>
<li><a href="https://github.com/facebookresearch/perception_models">Tải xuống mã</a></li>
<li><a href="https://ai.meta.com/datasets/pe-video/">Tải xuống tập dữ liệu</a></li>
<li><a href="https://ai.meta.com/research/publications/perception-encoder-the-best-visual-embeddings-are-not-at-the-output-of-the-network/">Đọc bài báo</a></li>
</ul>
<h2 id="meta-perception-language-model-nâng-cao-sự-hiểu-biết-của-chúng-ta-về-các-nhiệm-vụ-nhận-thức-trực-quan">Meta Perception Language Model: Nâng cao sự hiểu biết của chúng ta về các nhiệm vụ nhận thức trực quan</h2>
<p>Tiếp tục công việc của chúng tôi về nhận thức, chúng tôi đang phát hành Perception Language Model (PLM), một mô hình ngôn ngữ thị giác mở và có thể tái tạo để giải quyết các nhiệm vụ nhận dạng hình ảnh đầy thách thức.</p>
<p>Chúng tôi đã đào tạo PLM bằng cách sử dụng dữ liệu tổng hợp được tạo ở quy mô lớn và các tập dữ liệu hiểu ngôn ngữ thị giác mở, mà không cần bất kỳ sự chắt lọc nào từ các mô hình bên ngoài. Sau đó, chúng tôi xác định các khoảng trống chính trong dữ liệu hiện có để hiểu video và thu thập 2,5 triệu mẫu chú thích không gian thời gian và QA video có nhãn thủ công mới để lấp đầy những khoảng trống này, tạo thành tập dữ liệu lớn nhất thuộc loại này cho đến nay.</p>
<p>PLM được đào tạo trên tập dữ liệu khổng lồ này, sử dụng kết hợp dữ liệu tổng hợp và được gắn nhãn thủ công để tạo ra một mô hình mạnh mẽ, chính xác và hoàn toàn có thể tái tạo. PLM cung cấp các biến thể với 1, 3 và 8 tỷ tham số, khiến nó rất phù hợp cho nghiên cứu học thuật hoàn toàn minh bạch.</p>
<p>Chúng tôi cũng đang chia sẻ một điểm chuẩn mới, PLM-VideoBench, tập trung vào các tác vụ mà các điểm chuẩn hiện có bỏ lỡ: hiểu hoạt động chi tiết và lý luận có nền tảng về mặt không gian thời gian. Chúng tôi hy vọng rằng tập dữ liệu nguồn mở và quy mô lớn, điểm chuẩn đầy thách thức và các mô hình mạnh mẽ của chúng tôi sẽ cùng nhau cho phép cộng đồng nguồn mở xây dựng các hệ thống thị giác máy tính có khả năng hơn.</p>
<ul>
<li><a href="https://huggingface.co/collections/facebook/perception-lm-67f9783f171948c383ee7498">Tải xuống mô hình</a></li>
<li><a href="https://github.com/facebookresearch/perception_models">Tải xuống mã</a></li>
<li><a href="https://ai.meta.com/datasets/plm-data/">Tải xuống tập dữ liệu</a></li>
<li><a href="https://ai.meta.com/research/publications/perceptionlm-open-access-data-and-models-for-detailed-visual-understanding/">Đọc bài báo</a></li>
</ul>
<h2 id="meta-locate-3d-một-biên-giới-mới-trong-bản-địa-hóa-đối-tượng-từ-vựng-mở">Meta Locate 3D: Một biên giới mới trong bản địa hóa đối tượng từ vựng mở</h2>
<p>Hãy tưởng tượng bạn nói, &ldquo;Này robot, mang cho tôi cái cốc màu đỏ trên bàn,&rdquo; và có một con robot hoàn thành nhiệm vụ. Để các hệ thống AI hỗ trợ chúng ta một cách hiệu quả trong thế giới vật chất, điều cần thiết là chúng phải có sự hiểu biết về thế giới 3D dựa trên ngôn ngữ tự nhiên. Để thực hiện các nhiệm vụ như vậy, robot cần trước tiên xác định vị trí đối tượng trong môi trường 3D, điều hướng đến đó và nhặt nó lên.</p>
<p>Để giải quyết vấn đề này, chúng tôi đã xây dựng Meta Locate 3D, một mô hình đầu cuối có thể định vị chính xác các đối tượng từ các truy vấn từ vựng mở. Meta Locate 3D hoạt động trực tiếp trên các đám mây điểm 3D từ các cảm biến RGB-D nhận được từ robot. Khi được cung cấp một lời nhắc bằng văn bản, chẳng hạn như &ldquo;bình hoa gần bảng điều khiển TV&rdquo;, Meta Locate 3D sẽ tính đến các mối quan hệ không gian và ngữ cảnh để xác định thể hiện đối tượng cụ thể, chẳng hạn như &ldquo;bình hoa gần TV&rdquo;, không phải &ldquo;bình hoa trên bàn&rdquo; và có thể xác định chính xác vị trí của vật phẩm.</p>
<p>Meta Locate 3D bao gồm ba thành phần chính:</p>
<ul>
<li>Một bước tiền xử lý, bước đầu tiên nâng các tính năng nền tảng 2D lên các đám mây điểm có tính năng 3D.</li>
<li>Bộ mã hóa 3D-JEPA, một bộ mã hóa được đào tạo trước lấy các đám mây điểm có tính năng làm đầu vào và dự đoán một biểu diễn theo ngữ cảnh, được làm mịn của thế giới 3D.</li>
<li>Bộ giải mã Locate 3D, bộ này lấy biểu diễn 3D-JEPA và một truy vấn ngôn ngữ và tạo ra cả hộp giới hạn và mặt nạ cho các đối tượng được chỉ định.</li>
</ul>
<p>Chúng tôi cũng đang phát hành một tập dữ liệu mới để bản địa hóa các đối tượng dựa trên các biểu thức tham chiếu. Tập dữ liệu này bao gồm 130.000 chú thích ngôn ngữ trên ba tập dữ liệu được sử dụng rộng rãi — ARKitScenes, ScanNet và ScanNet++ — và bao gồm 1.346 cảnh, tăng gấp đôi hiệu quả số lượng chú thích dữ liệu hiện có.</p>
<p>Bằng cách cho phép robot hiểu chính xác môi trường xung quanh và đặt nền tảng cho sự hiểu biết của chúng bằng ngôn ngữ tự nhiên, Meta Locate 3D hỗ trợ sự phát triển của các hệ thống robot tinh vi và có khả năng hơn, bao gồm cả <a href="https://ai.meta.com/research/publications/partnr-a-benchmark-for-planning-and-reasoning-in-embodied-multi-agent-tasks/">Meta PARTNR</a>. Với Meta Locate 3D, con người có thể tương tác tự nhiên với robot để yêu cầu hoặc cộng tác trong các nhiệm vụ, điều này đánh dấu một bước tiến thú vị trong việc theo đuổi các cỗ máy thông minh và tự chủ hơn.</p>
<ul>
<li><a href="https://github.com/facebookresearch/locate-3d">Tải xuống mô hình</a></li>
<li><a href="https://locate3d.atmeta.com/">Dùng thử bản demo</a></li>
<li><a href="https://github.com/facebookresearch/locate-3d/tree/main/locate3d_data">Tải xuống tập dữ liệu</a></li>
<li><a href="https://ai.meta.com/research/publications/locate-3d-real-world-object-localization-via-self-supervised-learning-in-3d/">Đọc bài báo</a></li>
</ul>
<h2 id="dynamic-byte-latent-transformer-xác-định-lại-các-tiêu-chuẩn-về-hiệu-quả-và-độ-tin-cậy">Dynamic Byte Latent Transformer: Xác định lại các tiêu chuẩn về hiệu quả và độ tin cậy</h2>
<p>Sau khi xuất bản <a href="https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/">bài báo</a> nghiên cứu của chúng tôi vào cuối năm 2024, theo yêu cầu phổ biến, chúng tôi đang phát hành trọng số mô hình cho Dynamic Byte Latent Transformer tham số 8B của chúng tôi. Nghiên cứu này đánh dấu một tiến bộ đáng kể trong kiến trúc mô hình ngôn ngữ ở cấp độ byte, đạt được hiệu suất ở quy mô phù hợp với các mô hình ngôn ngữ dựa trên mã thông báo truyền thống lần đầu tiên. Công nghệ này giúp tăng cường hiệu quả suy luận và cải thiện đáng kể độ tin cậy.</p>
<p>Kiến trúc Dynamic Byte Latent Transformer vượt trội hơn các mô hình dựa trên tokenizer trong nhiều tác vụ khác nhau, với lợi thế độ tin cậy trung bình là +7 điểm (trên HellaSwag bị nhiễu) và đạt mức cao nhất là +55 điểm trên các tác vụ từ điểm chuẩn hiểu mã thông báo CUTE. Điều này làm nổi bật tiềm năng của Dynamic Byte Latent Transformer để xác định lại các tiêu chuẩn về hiệu quả và độ tin cậy của mô hình ngôn ngữ, cung cấp một giải pháp thay thế hấp dẫn cho các phương pháp mã thông báo truyền thống.</p>
<p>Với mô hình mới này và <a href="https://github.com/facebookresearch/blt">cơ sở mã</a> đã phát hành trước đó của chúng tôi, chúng tôi khuyến khích cộng đồng khám phá những ý tưởng mới, hy vọng mở đường cho những phát triển đột phá hơn nữa trong lĩnh vực mô hình hóa ngôn ngữ.</p>
<ul>
<li><a href="https://huggingface.co/facebook/blt">Tải xuống mô hình</a></li>
<li><a href="https://github.com/facebookresearch/blt">Tải xuống mã</a></li>
<li><a href="https://arxiv.org/abs/2412.09871">Đọc bài báo</a></li>
</ul>
<h2 id="collaborative-reasoner-các-tác-nhân-xã-hội-tự-cải-thiện-bằng-các-cuộc-trò-chuyện-tổng-hợp">Collaborative Reasoner: Các tác nhân xã hội tự cải thiện bằng các cuộc trò chuyện tổng hợp</h2>
<p>Khi con người cộng tác, chúng ta thường đạt được kết quả tốt hơn cùng nhau. Tương tự như sự hợp tác của con người, mục tiêu của chúng tôi là phát triển các tác nhân AI xã hội có thể cộng tác với con người hoặc các tác nhân AI khác để hoàn thành nhiệm vụ tốt hơn một tác nhân hoặc con người duy nhất. Hãy tưởng tượng một tác nhân giúp bạn hiểu một bài tập về nhà khó hoặc giúp bạn chuẩn bị cho một cuộc phỏng vấn xin việc. Những sự hợp tác này đầy thách thức vì ngoài việc giải quyết vấn đề, chúng còn đòi hỏi các kỹ năng xã hội như giao tiếp hiệu quả, cung cấp phản hồi, có sự đồng cảm và lý thuyết về tâm trí. Hơn nữa, loại hợp tác này thường biểu hiện qua nhiều lượt trò chuyện tự nhiên qua lại. Các điểm chuẩn đánh giá và đường ống đào tạo LLM hiện tại không xem xét các loại kỹ năng hợp tác và xã hội này. Dữ liệu trò chuyện qua lại hợp tác rất tốn kém để thu thập, dành riêng cho từng lĩnh vực và ít có khả năng kiểm soát hơn, gây khó khăn cho cả đánh giá và đào tạo.</p>
<p>Để giải quyết những thách thức này, chúng tôi đã xây dựng Collaborative Reasoner, một khuôn khổ để đánh giá và cải thiện các kỹ năng lý luận hợp tác của các mô hình ngôn ngữ. Collaborative Reasoner bao gồm một bộ các nhiệm vụ hướng đến mục tiêu, đòi hỏi lý luận nhiều bước cần được hai tác nhân hoàn thành một cách hợp tác thông qua một cuộc trò chuyện nhiều lượt. Các nhiệm vụ và số liệu trong Collaborative Reasoner yêu cầu các tác nhân không đồng ý về các giải pháp, thuyết phục đối tác của họ về một giải pháp chính xác và cuối cùng đồng ý về giải pháp tốt nhất với tư cách là một nhóm.</p>
<p>Đánh giá của chúng tôi cho thấy các mô hình hiện tại không thể sử dụng nhất quán sự cộng tác để đạt được hiệu suất nhiệm vụ tốt hơn. Để cải thiện khả năng lý luận hợp tác của LLM, chúng tôi đề xuất một phương pháp tự cải thiện bằng cách sử dụng dữ liệu tương tác tổng hợp được lấy mẫu với sự tự cộng tác — nói cách khác, một tác nhân LLM cộng tác với chính nó. Để cho phép tạo dữ liệu như vậy ở quy mô lớn, chúng tôi cũng phát triển một công cụ phục vụ mô hình hiệu suất cao, linh hoạt để suy luận quy mô lớn, được gọi là Matrix: Cơ sở hạ tầng và thử nghiệm tạo dữ liệu đa tác nhân. Trong các nhiệm vụ toán học (MATH), khoa học (MMLU-Pro, GPQA) và lý luận xã hội (ExploreToM, HiToM), phương pháp của chúng tôi mang lại những cải tiến lên đến 29,4% so với hiệu suất chuỗi tư duy của một LLM tác nhân đơn tương đương.</p>
<p>Collaborative Reasoner mở đường cho việc phát triển các tác nhân xã hội có thể hợp tác với con người và các tác nhân khác. Chúng tôi đang mở nguồn dữ liệu và đường ống mô hình hóa của mình để hỗ trợ nghiên cứu sâu hơn trong lĩnh vực này.</p>
<ul>
<li><a href="https://github.com/facebookresearch/collaborative-reasoner">Tải xuống mã Collaborative Reasoner</a></li>
<li><a href="https://github.com/facebookresearch/matrix">Tải xuống mã MATRIX</a></li>
<li><a href="https://ai.meta.com/research/publications/collaborative-reasoner-self-improving-social-agents-with-synthetic-conversations/">Đọc bài báo</a></li>
</ul>
<h2 id="các-bản-cập-nhật-mới-nhất-của-chúng-tôi-được-gửi-đến-hộp-thư-đến-của-bạn">Các bản cập nhật mới nhất của chúng tôi được gửi đến hộp thư đến của bạn</h2>
<p><a href="https://ai.facebook.com/subscribe/">Đăng ký</a> vào bản tin của chúng tôi để cập nhật tin tức, sự kiện, đột phá nghiên cứu và hơn thế nữa về Meta AI.</p>
<h2 id="tham-gia-cùng-chúng-tôi-trong-việc-theo-đuổi-những-gì-có-thể-với-ai">Tham gia cùng chúng tôi trong việc theo đuổi những gì có thể với AI.</h2>
<p><a href="https://www.metacareers.com/jobs/?is_leadership=0&amp;sub_teams%5B0%5D=Artificial+Intelligence&amp;is_in_page=0&amp;fbclid=IwAR0O8BF7opOj5gASJmwYVGalPPXTLu-6xrl9w00eC7Rarp2HQ9uEH8tERFw">Xem tất cả các vị trí đang mở</a></p>
<h3 id="link-bài-báo-gốc"><a href="https://ai.meta.com/blog/meta-fair-updates-perception-localization-reasoning/">Link bài báo gốc</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/april-17-2025/">April 17, 2025</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-04-19/ac4fc5/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png" alt="17 lý do tại sao Gradio không chỉ là một thư viện UI khác" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-04-19T00:00:00&#43;00:00">Apr 19, 2025</time>

		<h3 class="my-4 text-2xl font-bold">17 lý do tại sao Gradio không chỉ là một thư viện UI khác</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Gradio không chỉ là một thư viện UI.</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-04-19/53b449/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://venturebeat.com/wp-content/uploads/2025/04/google-5x-data-1280-720.png?w=350&amp;h=175&amp;crop=1" alt="BigQuery lớn hơn 5 lần so với Snowflake và Databricks Google đang làm gì để làm cho nó tốt hơn nữa" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-04-19T00:00:00&#43;00:00">Apr 19, 2025</time>

		<h3 class="my-4 text-2xl font-bold">BigQuery lớn hơn 5 lần so với Snowflake và Databricks Google đang làm gì để làm cho nó tốt hơn nữa</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">BigQuery lớn hơn 5 lần so với Snowflake và Databricks Đây là những gì Google đang làm để làm cho nó tốt hơn nữa.</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-10/883183/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">AI21’s Jamba Reasoning 3B tái định nghĩa &#39;Nhỏ&#39; có nghĩa là gì trong LLM — Bối cảnh 250K trên Máy tính xách tay</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-09/6ac862/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://lh3.googleusercontent.com/ka2UHKqEKG1GR8w-QqBLkIN48VBUClMsw8yo_ACI1vrofXyAKBd4QrcDyiIVdBu2V2S9o5tpMQL8Fi68ec4Y8CErz0CV4oTkl2RicrYl9q2pyDhz=w400-h225-n-nu" alt="Giới thiệu Mô hình Sử dụng Máy tính Gemini 2.5" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Giới thiệu Mô hình Sử dụng Máy tính Gemini 2.5</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-09/c7db8f/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/5f455d24ea80569b34eb4347f06152d8a5508722-1000x1000.svg" alt="Mở rộng hoạt động toàn cầu sang Ấn Độ với văn phòng thứ hai tại khu vực Châu Á Thái Bình Dương" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Mở rộng hoạt động toàn cầu sang Ấn Độ với văn phòng thứ hai tại khu vực Châu Á Thái Bình Dương</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-09/8931a6/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www.anthropic.com" alt="Rahul Patil gia nhập Anthropic với vai trò Giám đốc Công nghệ" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Rahul Patil gia nhập Anthropic với vai trò Giám đốc Công nghệ</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-07/10ab20/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://lh3.googleusercontent.com/fnAx6nksgsvTcj5EDj7bx1yD8sMXwfkBnR6vla-e-h4wZSKFI3a1nFftGvDYyJAk01ZzNr2-QJyqfw30V2_tcp6tE-udCtMCuyou9cBIHyxGnO_mtQ=w400-h225-n-nu" alt="Giới thiệu CodeMender- một tác nhân AI để bảo mật mã" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Giới thiệu CodeMender- một tác nhân AI để bảo mật mã</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo dõi các tiến bộ mới nhất về Trí tuệ nhân tạo.<br>Trực tiếp từ các nhà phát hành AI trên thế giới.
      </p>

      <p>Đem trí tuệ nhân tạo đến mọi người dân, doanh nghiệp Việt, góp phần giúp Việt Nam phát triển mạnh mẽ trong kỷ nguyên số. Nội dung được cập nhật tự động bằng máy.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright © 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>