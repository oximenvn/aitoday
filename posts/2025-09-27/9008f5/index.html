<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>ChÃ o má»«ng EmbeddingGemma, mÃ´ hÃ¬nh nhÃºng hiá»‡u quáº£ má»›i cá»§a Google | AI Today - SkyAI</title>

<meta name="description" content="">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['â¯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['â¯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">ChÃ o má»«ng EmbeddingGemma, mÃ´ hÃ¬nh nhÃºng hiá»‡u quáº£ má»›i cá»§a Google</h1>

      <div id="lead" class="my-6">

        <p class="font-bold"> </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['â€¢'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-09-27T00:00:00&#43;00:00">September 27, 2025</time>
          </li>

          <li class="before:content-['â€¢'] before:mr-2 before:opacity-50 my-2">
            19 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://huggingface.co/blog/assets/embeddinggemma/thumbnail.png" alt="ChÃ o má»«ng EmbeddingGemma, mÃ´ hÃ¬nh nhÃºng hiá»‡u quáº£ má»›i cá»§a Google">
        <figcaption class="text-center italic text-xs"></figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="chÃ o-má»«ng-embeddinggemma-mÃ´-hÃ¬nh-embedding-hiá»‡u-quáº£-má»›i-cá»§a-google">ChÃ o má»«ng EmbeddingGemma, mÃ´ hÃ¬nh embedding hiá»‡u quáº£ má»›i cá»§a Google</h1>
<p><strong>TL;DR</strong></p>
<p>HÃ´m nay, Google phÃ¡t hÃ nh <a href="https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4">EmbeddingGemma</a>, má»™t mÃ´ hÃ¬nh embedding Ä‘a ngÃ´n ngá»¯ hiá»‡n Ä‘áº¡i, hoÃ n háº£o cho cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng trÃªn thiáº¿t bá»‹. ÄÆ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘áº¡t tá»‘c Ä‘á»™ vÃ  hiá»‡u quáº£, mÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c nhá» gá»n <strong>308 triá»‡u tham sá»‘</strong> vÃ  <strong>cá»­a sá»• ngá»¯ cáº£nh 2K</strong>, má»Ÿ ra nhá»¯ng kháº£ nÄƒng má»›i cho cÃ¡c quy trÃ¬nh RAG trÃªn thiáº¿t bá»‹ di Ä‘á»™ng, cÃ¡c tÃ¡c nhÃ¢n vÃ  hÆ¡n tháº¿ ná»¯a. EmbeddingGemma Ä‘Æ°á»£c Ä‘Ã o táº¡o Ä‘á»ƒ há»— trá»£ hÆ¡n <strong>100 ngÃ´n ngá»¯</strong> vÃ  lÃ  mÃ´ hÃ¬nh embedding chá»‰ vÄƒn báº£n Ä‘a ngÃ´n ngá»¯ xáº¿p háº¡ng cao nháº¥t dÆ°á»›i 500M trÃªn Äiá»ƒm chuáº©n Embedding VÄƒn báº£n Lá»›n (MTEB) táº¡i thá»i Ä‘iá»ƒm viáº¿t bÃ i.</p>
<h2 id="má»¥c-lá»¥c">Má»¥c lá»¥c</h2>
<ul>
<li><a href="#introduction">Giá»›i thiá»‡u</a></li>
<li><a href="#evaluation">ÄÃ¡nh giÃ¡</a></li>
<li><a href="#demo">Demo</a></li>
<li><a href="#usage">CÃ¡ch sá»­ dá»¥ng</a>
<ul>
<li><a href="#sentence-transformers">Sentence Transformers</a>
<ul>
<li><a href="#retrieval">Truy xuáº¥t</a></li>
</ul>
</li>
<li><a href="#langchain">LangChain</a></li>
<li><a href="#llamaindex">LlamaIndex</a></li>
<li><a href="#haystack">Haystack</a></li>
<li><a href="#txtai">txtai</a></li>
<li><a href="#transformersjs">Transformers.js</a></li>
<li><a href="#text-embeddings-inference">Suy luáº­n Embedding VÄƒn báº£n</a></li>
<li><a href="#onnx-runtime">ONNX Runtime</a></li>
</ul>
</li>
<li><a href="#finetuning">Tinh chá»‰nh</a>
<ul>
<li><a href="#full-finetuning-script">Táº­p lá»‡nh tinh chá»‰nh hoÃ n chá»‰nh</a></li>
<li><a href="#training">ÄÃ o táº¡o</a></li>
<li><a href="#finetuned-evaluation">ÄÃ¡nh giÃ¡ tinh chá»‰nh</a></li>
</ul>
</li>
<li><a href="#further-reading">Äá»c thÃªm</a></li>
</ul>
<h2 id="giá»›i-thiá»‡u">Giá»›i thiá»‡u</h2>
<p><a href="https://sbert.net/">VÄƒn báº£n nhÃºng</a> Ä‘Ã£ trá»Ÿ thÃ nh xÆ°Æ¡ng sá»‘ng cá»§a cÃ¡c á»©ng dá»¥ng ngÃ´n ngá»¯ tá»± nhiÃªn hiá»‡n Ä‘áº¡i, biáº¿n cÃ¡c tá»«, cÃ¢u vÃ  tÃ i liá»‡u thÃ nh cÃ¡c vectÆ¡ dÃ y Ä‘áº·c náº¯m báº¯t Ã½ nghÄ©a, tÃ¬nh cáº£m vÃ  Ã½ Ä‘á»‹nh. CÃ¡c vectÆ¡ nÃ y cho phÃ©p tÃ¬m kiáº¿m tÆ°Æ¡ng tá»± nhanh chÃ³ng, phÃ¢n cá»¥m, phÃ¢n loáº¡i vÃ  truy xuáº¥t trÃªn cÃ¡c vÄƒn báº£n lá»›n, há»— trá»£ má»i thá»© tá»« cÃ¡c cÃ´ng cá»¥ Ä‘á» xuáº¥t vÃ  tÃ¬m kiáº¿m ngá»¯ nghÄ©a Ä‘áº¿n táº¡o vÄƒn báº£n tÄƒng cÆ°á»ng kháº£ nÄƒng truy xuáº¥t vÃ  cÃ¡c cÃ´ng cá»¥ tÃ¬m kiáº¿m mÃ£. MÃ´ hÃ¬nh Embedding Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c embedding nÃ y, vá»›i hÆ¡n <a href="https://huggingface.co/models?library=sentence-transformers&amp;sort=downloads">200 triá»‡u lÆ°á»£t táº£i xuá»‘ng hÃ ng thÃ¡ng trÃªn Hugging Face</a>.</p>
<p>Dá»±a trÃªn ná»n táº£ng nÃ y, <strong>EmbeddingGemma</strong> cá»§a Google DeepMind xuáº¥t hiá»‡n nhÆ° lÃ  mÃ´ hÃ¬nh embedding Ä‘a ngÃ´n ngá»¯ nhá», cÃ³ kháº£ nÄƒng nháº¥t tá»« trÆ°á»›c Ä‘áº¿n nay. Vá»›i chá»‰ 308M tham sá»‘, cá»­a sá»• ngá»¯ cáº£nh 2k vÃ  há»— trá»£ hÆ¡n 100 ngÃ´n ngá»¯, EmbeddingGemma mang láº¡i hiá»‡u suáº¥t hiá»‡n Ä‘áº¡i trÃªn Äiá»ƒm chuáº©n Embedding VÄƒn báº£n Äa ngÃ´n ngá»¯ Lá»›n (MMTEB) trong khi váº«n dÆ°á»›i 200 MB RAM khi Ä‘Æ°á»£c lÆ°á»£ng tá»­ hÃ³a.</p>
<p>CÃ¡c lá»±a chá»n thiáº¿t káº¿ khÃ¡c nhau dáº«n Ä‘áº¿n má»™t cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ ráº¥t thiáº¿t thá»±c Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c embedding Ä‘a ngÃ´n ngá»¯ cháº¥t lÆ°á»£ng cao trÃªn cÃ¡c thiáº¿t bá»‹ hÃ ng ngÃ y.</p>
<p>Trong bÃ i Ä‘Äƒng trÃªn blog nÃ y, chÃºng tÃ´i mÃ´ táº£ kiáº¿n trÃºc vÃ  Ä‘Ã o táº¡o EmbeddingGemma, Ä‘á»“ng thá»i chá»‰ cho báº¡n cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh vá»›i nhiá»u framework khÃ¡c nhau nhÆ° Sentence Transformers, LangChain, LlamaIndex, Haystack, txtai, Transformers.js, Text Embedding Inference vÃ  ONNX.</p>
<p>Sau Ä‘Ã³, chÃºng tÃ´i sáº½ trÃ¬nh bÃ y cÃ¡ch tinh chá»‰nh EmbeddingGemma trÃªn miá»n cá»§a báº¡n Ä‘á»ƒ cÃ³ hiá»‡u suáº¥t tháº­m chÃ­ cÃ²n máº¡nh máº½ hÆ¡n. Trong vÃ­ dá»¥ cá»§a chÃºng tÃ´i, chÃºng tÃ´i tinh chá»‰nh EmbeddingGemma trÃªn Táº­p dá»¯ liá»‡u Truy xuáº¥t vÃ  HÆ°á»›ng dáº«n Y táº¿ (MIRIAD). MÃ´ hÃ¬nh káº¿t quáº£, <a href="https://huggingface.co/sentence-transformers/embeddinggemma-300m-medical">sentence-transformers/embeddinggemma-300m-medical</a>, Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t hiá»‡n Ä‘áº¡i trÃªn nhiá»‡m vá»¥ cá»§a chÃºng tÃ´i: truy xuáº¥t cÃ¡c Ä‘oáº¡n vÄƒn báº£n cá»§a cÃ¡c bÃ i bÃ¡o y há»c khoa há»c Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i y táº¿ chi tiáº¿t. NÃ³ tháº­m chÃ­ cÃ²n <a href="#finetuned-evaluation">vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh lá»›n gáº¥p Ä‘Ã´i</a> trong nhiá»‡m vá»¥ nÃ y.</p>
<h2 id="kiáº¿n-trÃºc">Kiáº¿n trÃºc</h2>
<p>EmbeddingGemma Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn ná»n táº£ng bá»™ chuyá»ƒn Ä‘á»•i <a href="https://huggingface.co/blog/gemma3">Gemma3</a>, nhÆ°ng Ä‘Æ°á»£c sá»­a Ä‘á»•i Ä‘á»ƒ sá»­ dá»¥ng attention hai chiá»u thay vÃ¬ attention nhÃ¢n quáº£ (má»™t chiá»u). Äiá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ¡c token trÆ°á»›c Ä‘Ã³ trong chuá»—i cÃ³ thá»ƒ tham gia vÃ o cÃ¡c token sau, biáº¿n kiáº¿n trÃºc tá»« má»™t bá»™ giáº£i mÃ£ thÃ nh má»™t bá»™ mÃ£ hÃ³a. CÃ¡c mÃ´ hÃ¬nh mÃ£ hÃ³a cÃ³ thá»ƒ vÆ°á»£t trá»™i hÆ¡n LLM, lÃ  bá»™ giáº£i mÃ£, trong cÃ¡c nhiá»‡m vá»¥ embedding nhÆ° truy xuáº¥t (<a href="https://arxiv.org/abs/2507.11412">Weller et al., 2025</a>). Vá»›i ná»n táº£ng nÃ y, mÃ´ hÃ¬nh cÃ³ thá»ƒ xá»­ lÃ½ Ä‘á»“ng thá»i 2048 token Ä‘Ã¡ng ká»ƒ, Ä‘á»§ cho cÃ¡c Ä‘áº§u vÃ o truy xuáº¥t Ä‘iá»ƒn hÃ¬nh, Ä‘áº·c biá»‡t lÃ  khi Ä‘áº§u vÃ o lá»›n hÆ¡n thÆ°á»ng dáº«n Ä‘áº¿n máº¥t thÃ´ng tin trong cÃ¡c embedding vÄƒn báº£n.</p>
<p>NgoÃ i ná»n táº£ng bá»™ mÃ£ hÃ³a dá»±a trÃªn Gemma3 má»›i, táº¡o ra cÃ¡c embedding token, má»™t lá»›p gá»™p trung bÃ¬nh sáº½ chuyá»ƒn Ä‘á»•i cÃ¡c embedding token nÃ y thÃ nh embedding vÄƒn báº£n. Cuá»‘i cÃ¹ng, hai lá»›p dÃ y Ä‘áº·c chuyá»ƒn Ä‘á»•i cÃ¡c embedding vÄƒn báº£n thÃ nh dáº¡ng cuá»‘i cÃ¹ng cá»§a chÃºng, má»™t vectÆ¡ 768 chiá»u.</p>
<p>MÃ´ hÃ¬nh EmbeddingGemma Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng <a href="https://huggingface.co/blog/matryoshka">Há»c biá»ƒu diá»…n Matryoshka (MRL)</a>, cho phÃ©p báº¡n cáº¯t ngáº¯n Ä‘áº§u ra 768 chiá»u thÃ nh 512, 256 hoáº·c 128 chiá»u theo yÃªu cáº§u. Äiá»u nÃ y dáº«n Ä‘áº¿n xá»­ lÃ½ háº¡ nguá»“n nhanh hÆ¡n vÃ  sá»­ dá»¥ng Ã­t bá»™ nhá»› vÃ  dung lÆ°á»£ng Ä‘Ä©a hÆ¡n. Xem <a href="#sentence-transformers">CÃ¡ch sá»­ dá»¥ng Sentence Transformers</a> Ä‘á»ƒ biáº¿t Ä‘oáº¡n mÃ£ hiá»ƒn thá»‹ cÃ¡ch thá»±c hiá»‡n viá»‡c cáº¯t ngáº¯n nÃ y.</p>
<p>MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng cÃ¡ch sá»­ dá»¥ng má»™t kho vÄƒn báº£n Ä‘a ngÃ´n ngá»¯ Ä‘Æ°á»£c tuyá»ƒn chá»n cáº©n tháº­n vá»›i tá»•ng sá»‘ khoáº£ng 320 tá»· token. Táº­p dá»¯ liá»‡u Ä‘á»™c quyá»n lÃ  sá»± káº¿t há»£p cá»§a vÄƒn báº£n web cÃ³ sáºµn cÃ´ng khai, mÃ£ vÃ  tÃ i liá»‡u ká»¹ thuáº­t, vÃ  cÃ¡c vÃ­ dá»¥ tá»•ng há»£p dÃ nh riÃªng cho nhiá»‡m vá»¥. NÃ³ Ä‘Ã£ Ä‘Æ°á»£c lá»c Ä‘á»ƒ trÃ¡nh TÃ i liá»‡u Láº¡m dá»¥ng TÃ¬nh dá»¥c Tráº» em (CSAM), dá»¯ liá»‡u nháº¡y cáº£m vÃ  ná»™i dung cháº¥t lÆ°á»£ng tháº¥p hoáº·c khÃ´ng an toÃ n.</p>
<h2 id="Ä‘Ã¡nh-giÃ¡">ÄÃ¡nh giÃ¡</h2>
<p>EmbeddingGemma Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn bá»™ MMTEB (Äa ngÃ´n ngá»¯, v2) vÃ  MTEB (Tiáº¿ng Anh, v2), bao gá»“m má»™t loáº¡t cÃ¡c nhiá»‡m vá»¥, miá»n vÃ  ngÃ´n ngá»¯. Máº·c dÃ¹ cÃ³ kÃ­ch thÆ°á»›c tham sá»‘ 308M khiÃªm tá»‘n, mÃ´ hÃ¬nh nÃ y liÃªn tá»¥c Ä‘Ã¡nh báº¡i cÃ¡c Ä‘Æ°á»ng cÆ¡ sá»Ÿ so sÃ¡nh Ä‘Æ°á»£c trong khi váº«n giá»¯ má»™t dáº¥u chÃ¢n bá»™ nhá»› ráº¥t nhá».</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Hiá»‡u suáº¥t MTEB (Äa ngÃ´n ngá»¯, v2)</th>
          <th style="text-align: left">Hiá»‡u suáº¥t MTEB (Tiáº¿ng Anh, v2)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/embeddinggemma/embeddinggemma-300m-mteb-multilingual.png" alt=""></td>
          <td style="text-align: left"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/embeddinggemma/embeddinggemma-300m-mteb-eng.png" alt=""></td>
      </tr>
  </tbody>
</table>
<p>Káº¿t quáº£ sáº½ Ä‘Æ°á»£c liá»‡t kÃª trÃªn <a href="https://huggingface.co/spaces/mteb/leaderboard">Báº£ng xáº¿p háº¡ng MTEB</a> chÃ­nh thá»©c. ChÃºng tÃ´i loáº¡i trá»« báº¥t ká»³ mÃ´ hÃ¬nh nÃ o Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn hÆ¡n 20% dá»¯ liá»‡u MTEB, Ä‘á»ƒ giáº£m thiá»ƒu kháº£ nÄƒng trang bá»‹ quÃ¡ má»©c.</p>
<h2 id="báº£n-trÃ¬nh-diá»…n">Báº£n trÃ¬nh diá»…n</h2>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h2 id="cÃ¡ch-sá»­-dá»¥ng">CÃ¡ch sá»­ dá»¥ng</h2>
<p>EmbeddingGemma Ä‘Æ°á»£c tÃ­ch há»£p vá»›i nhiá»u cÃ´ng cá»¥ phá»• biáº¿n, giÃºp báº¡n dá»… dÃ ng káº¿t há»£p vÃ o cÃ¡c quy trÃ¬nh lÃ m viá»‡c vÃ  á»©ng dá»¥ng hiá»‡n cÃ³ cá»§a mÃ¬nh. MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p trong Sentence Transformers, vÃ  do Ä‘Ã³ cÅ©ng trong cÃ¡c dá»± Ã¡n sá»­ dá»¥ng Sentence Transformers á»Ÿ cháº¿ Ä‘á»™ ná»n, cháº³ng háº¡n nhÆ° LangChain, LlamaIndex, Haystack vÃ  txtai. Xem cÃ¡c vÃ­ dá»¥ bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u vá»›i framework Æ°a thÃ­ch cá»§a báº¡n.</p>
<p>Äá»‘i vá»›i viá»‡c triá»ƒn khai sáº£n xuáº¥t, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng <a href="https://huggingface.co/docs/text-embeddings-inference/en/index">Suy luáº­n Embedding VÄƒn báº£n</a> (TEI) Ä‘á»ƒ phá»¥c vá»¥ mÃ´ hÃ¬nh má»™t cÃ¡ch hiá»‡u quáº£ trÃªn cÃ¡c cáº¥u hÃ¬nh pháº§n cá»©ng khÃ¡c nhau vÃ  báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng <a href="https://huggingface.co/docs/transformers.js/index">Transformers.js</a> Ä‘á»ƒ sá»­ dá»¥ng trong cÃ¡c á»©ng dá»¥ng web.</p>
<p>Báº¥t ká»ƒ báº¡n chá»n framework nÃ o, báº¡n nÃªn lÆ°u Ã½ Ä‘áº¿n <strong>cÃ¡c lá»i nháº¯c</strong>. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh embedding, cÃ¡c lá»i nháº¯c Ä‘Æ°á»£c thÃªm vÃ o vÄƒn báº£n Ä‘áº§u vÃ o Ä‘á»ƒ cho phÃ©p mÃ´ hÃ¬nh phÃ¢n biá»‡t giá»¯a cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhau. EmbeddingGemma Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã o táº¡o vá»›i cÃ¡c tÃªn vÃ  lá»i nháº¯c nÃ y, vÃ¬ váº­y chÃºng cÅ©ng nÃªn Ä‘Æ°á»£c bao gá»“m khi sá»­ dá»¥ng mÃ´ hÃ¬nh:</p>
<ul>
<li><code>query</code>: <code>&quot;task: search result | query: &quot;</code></li>
<li><code>document</code>: <code>&quot;title: none | text: &quot;</code></li>
<li><code>BitextMining</code>: <code>&quot;task: search result | query: &quot;</code></li>
<li><code>Clustering</code>: <code>&quot;task: clustering | query: &quot;</code></li>
<li><code>Classification</code>: <code>&quot;task: classification | query: &quot;</code></li>
<li><code>InstructionRetrieval</code>: <code>&quot;task: code retrieval | query: &quot;</code></li>
<li><code>MultilabelClassification</code>: <code>&quot;task: classification | query: &quot;</code></li>
<li><code>PairClassification</code>: <code>&quot;task: sentence similarity | query: &quot;</code></li>
<li><code>Reranking</code>: <code>&quot;task: search result | query: &quot;</code></li>
<li><code>Retrieval-query</code>: <code>&quot;task: search result | query: &quot;</code></li>
<li><code>Retrieval-document</code>: <code>&quot;title: none | text: &quot;</code></li>
<li><code>STS</code>: <code>&quot;task: sentence similarity | query: &quot;</code></li>
<li><code>Summarization</code>: <code>&quot;task: summarization | query: &quot;</code></li>
</ul>
<p>Trong Sentence Transformers, cÃ¡c lá»i nháº¯c <code>query</code> vÃ  <code>document</code> Ä‘Æ°á»£c sá»­ dá»¥ng tá»± Ä‘á»™ng khi gá»i <code>model.encode_query</code> vÃ  <code>model.encode_document</code>, nhÆ°ng Ä‘á»‘i vá»›i cÃ¡c framework khÃ¡c, báº¡n cÃ³ thá»ƒ pháº£i: $</p>
<ol>
<li>chá»‰ Ä‘á»‹nh tÃªn lá»i nháº¯c (vÃ­ dá»¥: &ldquo;Reranking&rdquo;),</li>
<li>chá»‰ Ä‘á»‹nh chuá»—i lá»i nháº¯c (vÃ­ dá»¥: &ldquo;task: search result | query: &ldquo;), hoáº·c</li>
<li>thÃªm thá»§ cÃ´ng cÃ¡c lá»i nháº¯c vÃ o vÄƒn báº£n Ä‘áº§u vÃ o cá»§a báº¡n.</li>
</ol>
<p>CÃ¡c táº­p lá»‡nh vÃ­ dá»¥ sau sáº½ trÃ¬nh bÃ y Ä‘iá»u nÃ y vá»›i nhiá»u framework khÃ¡c nhau.</p>
<h3 id="sentence-transformers">Sentence Transformers</h3>
<p>Báº¡n sáº½ cáº§n cÃ i Ä‘áº·t cÃ¡c gÃ³i sau:</p>
<p>shell
pip install git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview
pip install sentence-transformers&gt;=5.0.0</p>
<h4 id="truy-xuáº¥t">Truy xuáº¥t</h4>
<p>Suy luáº­n báº±ng Sentence Transformers khÃ¡ Ä‘Æ¡n giáº£n, hÃ£y xem vÃ­ dá»¥ nÃ y Ä‘á»ƒ tÃ¬m kiáº¿m ngá»¯ nghÄ©a:</p>
<p>py
from sentence_transformers import SentenceTransformer</p>
<h1 id="táº£i-xuá»‘ng-tá»«--hub">Táº£i xuá»‘ng tá»« ğŸ¤— Hub</h1>
<p>model = SentenceTransformer(&ldquo;google/embeddinggemma-300m&rdquo;)</p>
<h1 id="cháº¡y-suy-luáº­n-vá»›i-cÃ¡c-truy-váº¥n-vÃ -tÃ i-liá»‡u">Cháº¡y suy luáº­n vá»›i cÃ¡c truy váº¥n vÃ  tÃ i liá»‡u</h1>
<p>query = &ldquo;HÃ nh tinh nÃ o Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá»?&rdquo;
documents = [
&ldquo;Sao Kim thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  song sinh cá»§a TrÃ¡i Äáº¥t vÃ¬ kÃ­ch thÆ°á»›c vÃ  khoáº£ng cÃ¡ch tÆ°Æ¡ng tá»±.&rdquo;,
&ldquo;Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá».&rdquo;,
&ldquo;Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t.&rdquo;,
&ldquo;Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá».&rdquo;
]
query_embeddings = model.encode_query(query)
document_embeddings = model.encode_document(documents)
print(query_embeddings.shape, document_embeddings.shape)</p>
<h1 id="768-4-768">(768,) (4, 768)</h1>
<h1 id="tÃ­nh-toÃ¡n-sá»±-tÆ°Æ¡ng-Ä‘á»“ng-Ä‘á»ƒ-xÃ¡c-Ä‘á»‹nh-thá»©-háº¡ng">TÃ­nh toÃ¡n sá»± tÆ°Æ¡ng Ä‘á»“ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh thá»© háº¡ng</h1>
<p>similarities = model.similarity(query_embeddings, document_embeddings)
print(similarities)</p>
<h1 id="tensor03011-06359-04930-04889">tensor([[0.3011, 0.6359, 0.4930, 0.4889]])</h1>
<h1 id="chuyá»ƒn-Ä‘á»•i-sá»±-tÆ°Æ¡ng-Ä‘á»“ng-thÃ nh-thá»©-háº¡ng">Chuyá»ƒn Ä‘á»•i sá»± tÆ°Æ¡ng Ä‘á»“ng thÃ nh thá»© háº¡ng</h1>
<p>ranking = similarities.argsort(descending=True)[0]
print(ranking)</p>
<h1 id="tensor1-2-3-0">tensor([1, 2, 3, 0])</h1>
<ul>
<li><a href="https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.encode_query">TÃ i liá»‡u vá» phÆ°Æ¡ng thá»©c <code>encode_query</code> cá»§a Sentence Transformers</a></li>
<li><a href="https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.encode_document">TÃ i liá»‡u vá» phÆ°Æ¡ng thá»©c <code>encode_document</code> cá»§a Sentence Transformers</a></li>
<li><a href="https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.similarity">TÃ i liá»‡u vá» phÆ°Æ¡ng thá»©c <code>similarity</code> cá»§a Sentence Transformers</a></li>
</ul>
<!-- raw HTML omitted -->
<p>Náº¿u báº¡n khÃ´ng tÃ¬m cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ y Ä‘á»ƒ Truy xuáº¥t ThÃ´ng tin, thÃ¬ cÃ³ láº½ báº¡n nÃªn sá»­ dá»¥ng phÆ°Æ¡ng thá»©c <code>encode</code> chung nháº¥t cÃ¹ng vá»›i lá»i nháº¯c mÃ´ hÃ¬nh mÃ´ táº£ tá»‘t nháº¥t nhiá»‡m vá»¥ háº¡ nguá»“n cá»§a báº¡n trong sá»‘ cÃ¡c tÃ¹y chá»n sau:</p>
<ul>
<li><code>BitextMining</code>: TÃ¬m cÃ¡c cáº·p cÃ¢u Ä‘Ã£ dá»‹ch báº±ng hai ngÃ´n ngá»¯.</li>
<li><code>Clustering</code>: TÃ¬m cÃ¡c vÄƒn báº£n tÆ°Æ¡ng tá»± Ä‘á»ƒ nhÃ³m chÃºng láº¡i vá»›i nhau.</li>
<li><code>Classification</code>: GÃ¡n nhÃ£n Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c cho vÄƒn báº£n.</li>
<li><code>InstructionRetrieval</code>: Truy xuáº¥t cÃ¡c Ä‘oáº¡n mÃ£ liÃªn quan dá»±a trÃªn hÆ°á»›ng dáº«n báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn.</li>
<li><code>MultilabelClassification</code>: GÃ¡n nhiá»u nhÃ£n cho vÄƒn báº£n.</li>
<li><code>PairClassification</code>: GÃ¡n nhÃ£n Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c cho vÄƒn báº£n.</li>
<li><code>Reranking</code>: Sáº¯p xáº¿p láº¡i káº¿t quáº£ tÃ¬m kiáº¿m dá»±a trÃªn má»©c Ä‘á»™ liÃªn quan.</li>
<li><code>Retrieval-query</code>: Truy xuáº¥t tÃ i liá»‡u dá»±a trÃªn truy váº¥n.</li>
<li><code>Retrieval-document</code>: Truy xuáº¥t tÃ i liá»‡u dá»±a trÃªn ná»™i dung cá»§a chÃºng.</li>
<li><code>STS</code>: TÃ­nh toÃ¡n sá»± tÆ°Æ¡ng Ä‘á»“ng vÄƒn báº£n ngá»¯ nghÄ©a giá»¯a cÃ¡c vÄƒn báº£n.</li>
<li><code>Summarization</code>: Táº¡o tÃ³m táº¯t ngáº¯n gá»n vá» vÄƒn báº£n.</li>
</ul>
<p>python
from sentence_transformers import SentenceTransformer</p>
<h1 id="táº£i-xuá»‘ng-tá»«--hub-1">Táº£i xuá»‘ng tá»« ğŸ¤— Hub</h1>
<p>model = SentenceTransformer(&ldquo;google/embeddinggemma-300m&rdquo;)</p>
<h1 id="hÃ£y-kiá»ƒm-tra-cÃ¡c-lá»i-nháº¯c-Ä‘Ã£-Ä‘Æ°á»£c-cáº¥u-hÃ¬nh">HÃ£y kiá»ƒm tra cÃ¡c lá»i nháº¯c Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh</h1>
<p>print(model.prompts)</p>
<h1 id="heading">{</h1>
<h1 id="query-task-search-result--query-">&ldquo;query&rdquo;: &ldquo;task: search result | query: &ldquo;,</h1>
<h1 id="document-title-none--text-">&ldquo;document&rdquo;: &ldquo;title: none | text: &ldquo;,</h1>
<h1 id="bitextmining-task-search-result--query-">&ldquo;BitextMining&rdquo;: &ldquo;task: search result | query: &ldquo;,</h1>
<h1 id="clustering-task-clustering--query-">&ldquo;Clustering&rdquo;: &ldquo;task: clustering | query: &ldquo;,</h1>
<h1 id="classification-task-classification--query-">&ldquo;Classification&rdquo;: &ldquo;task: classification | query: &ldquo;,</h1>
<h1 id="instructionretrieval-task-code-retrieval--query-">&ldquo;InstructionRetrieval&rdquo;: &ldquo;task: code retrieval | query: &ldquo;,</h1>
<h1 id="multilabelclassification-task-classification--query-">&ldquo;MultilabelClassification&rdquo;: &ldquo;task: classification | query: &ldquo;,</h1>
<h1 id="pairclassification-task-sentence-similarity--query-">&ldquo;PairClassification&rdquo;: &ldquo;task: sentence similarity | query: &ldquo;,</h1>
<h1 id="reranking-task-search-result--query-">&ldquo;Reranking&rdquo;: &ldquo;task: search result | query: &ldquo;,</h1>
<h1 id="retrieval-query-task-search-result--query-">&ldquo;Retrieval-query&rdquo;: &ldquo;task: search result | query: &ldquo;,</h1>
<h1 id="retrieval-document-title-none--text-">&ldquo;Retrieval-document&rdquo;: &ldquo;title: none | text: &ldquo;,</h1>
<h1 id="sts-task-sentence-similarity--query-">&ldquo;STS&rdquo;: &ldquo;task: sentence similarity | query: &ldquo;,</h1>
<h1 id="summarization-task-summarization--query-">&ldquo;Summarization&rdquo;: &ldquo;task: summarization | query: &ldquo;,</h1>
<h1 id="heading-1">}</h1>
<h1 id="tÃ­nh-toÃ¡n-sá»±-tÆ°Æ¡ng-Ä‘á»“ng-vÄƒn-báº£n-ngá»¯-nghÄ©a-báº±ng-cÃ¡ch-sá»­-dá»¥ng-vÄƒn-báº£n-vÃ¬-váº­y-hÃ£y-sá»­-dá»¥ng-lá»i-nháº¯c-sts">TÃ­nh toÃ¡n sá»± tÆ°Æ¡ng Ä‘á»“ng vÄƒn báº£n ngá»¯ nghÄ©a báº±ng cÃ¡ch sá»­ dá»¥ng vÄƒn báº£n, vÃ¬ váº­y hÃ£y sá»­ dá»¥ng lá»i nháº¯c STS</h1>
<p>texts = [
&ldquo;Thá»i tiáº¿t hÃ´m nay ráº¥t Ä‘áº¹p.&rdquo;,
&ldquo;NgoÃ i trá»i lÃ  má»™t ngÃ y tuyá»‡t vá»i.&rdquo;,
&ldquo;Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Ä‘Ã£ sá»¥p Ä‘á»• ngÃ y hÃ´m qua.&rdquo;,
&ldquo;TÃ´i thÃ­ch láº­p trÃ¬nh vá»›i Python.&rdquo;
]
embeddings = model.encode(texts, prompt_name=&ldquo;STS&rdquo;)
print(embeddings.shape)</p>
<h1 id="4-768">(4, 768)</h1>
<h1 id="tÃ­nh-toÃ¡n-sá»±-tÆ°Æ¡ng-Ä‘á»“ng">TÃ­nh toÃ¡n sá»± tÆ°Æ¡ng Ä‘á»“ng</h1>
<p>similarities = model.similarity(embeddings, embeddings)
print(similarities)
&quot;&rdquo;&rdquo;
tensor([[1.0000, 0.9305, 0.4660, 0.4326],
[0.9305, 1.0000, 0.4227, 0.4434],
[0.4660, 0.4227, 1.0000, 0.2638],
[0.4326, 0.4434, 0.2638, 1.0000]])
&quot;&rdquo;&rdquo;</p>
<ul>
<li><a href="https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.encode">TÃ i liá»‡u vá» phÆ°Æ¡ng thá»©c <code>encode</code> cá»§a Sentence Transformers</a></li>
<li><a href="https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.similarity">TÃ i liá»‡u vá» phÆ°Æ¡ng thá»©c <code>similarity</code> cá»§a Sentence Transformers</a></li>
</ul>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>VÃ¬ <code>google/embeddinggemma-300m</code> Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng MRL, nÃªn cÃ¡c embedding Ä‘Æ°á»£c táº¡o bá»Ÿi mÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ bá»‹ cáº¯t ngáº¯n thÃ nh cÃ¡c chiá»u tháº¥p hÆ¡n mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n hiá»‡u suáº¥t Ä‘Ã¡nh giÃ¡. CÃ¡c embedding cÃ³ chiá»u tháº¥p hÆ¡n vá»«a ráº» hÆ¡n Ä‘á»ƒ lÆ°u trá»¯ trÃªn Ä‘Ä©a vÃ  trong bá»™ nhá»›, vá»«a nhanh hÆ¡n cho cÃ¡c nhiá»‡m vá»¥ háº¡ nguá»“n nhÆ° truy xuáº¥t, phÃ¢n cá»¥m hoáº·c phÃ¢n loáº¡i.</p>
<p>Trong Sentence Transformers, báº¡n cÃ³ thá»ƒ Ä‘áº·t chiá»u tháº¥p hÆ¡n báº±ng cÃ¡ch sá»­ dá»¥ng tham sá»‘ <code>truncate_dim</code> khi khá»Ÿi táº¡o <code>SentenceTransformer</code> hoáº·c khi gá»i <code>model.encode</code>/<code>model.encode_query</code>/<code>model.encode_document</code>:</p>
<p>python
from sentence_transformers import SentenceTransformer</p>
<h1 id="táº£i-xuá»‘ng-tá»«--hub-2">Táº£i xuá»‘ng tá»« ğŸ¤— Hub</h1>
<p>model = SentenceTransformer(&ldquo;google/embeddinggemma-300m&rdquo;, truncate_dim=256)</p>
<h1 id="cháº¡y-suy-luáº­n-vá»›i-cÃ¡c-truy-váº¥n-vÃ -tÃ i-liá»‡u-1">Cháº¡y suy luáº­n vá»›i cÃ¡c truy váº¥n vÃ  tÃ i liá»‡u</h1>
<p>query = &ldquo;HÃ nh tinh nÃ o Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá»?&rdquo;
documents = [
&ldquo;Sao Kim thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  song sinh cá»§a TrÃ¡i Äáº¥t vÃ¬ kÃ­ch thÆ°á»›c vÃ  khoáº£ng cÃ¡ch tÆ°Æ¡ng tá»±.&rdquo;,
&ldquo;Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá».&rdquo;,
&ldquo;Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t.&rdquo;,
&ldquo;Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá».&rdquo;
]
query_embeddings = model.encode_query(query)
document_embeddings = model.encode_document(documents)
print(query_embeddings.shape, document_embeddings.shape)</p>
<h1 id="256-4-256">(256,) (4, 256)</h1>
<h1 id="tÃ­nh-toÃ¡n-sá»±-tÆ°Æ¡ng-Ä‘á»“ng-Ä‘á»ƒ-xÃ¡c-Ä‘á»‹nh-thá»©-háº¡ng-1">TÃ­nh toÃ¡n sá»± tÆ°Æ¡ng Ä‘á»“ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh thá»© háº¡ng</h1>
<p>similarities = model.similarity(query_embeddings, document_embeddings)
print(similarities)</p>
<h1 id="tensor04016-06715-05283-05261">tensor([[0.4016, 0.6715, 0.5283, 0.5261]])</h1>
<h1 id="chuyá»ƒn-Ä‘á»•i-sá»±-tÆ°Æ¡ng-Ä‘á»“ng-thÃ nh-thá»©-háº¡ng-1">Chuyá»ƒn Ä‘á»•i sá»± tÆ°Æ¡ng Ä‘á»“ng thÃ nh thá»© háº¡ng</h1>
<p>ranking = similarities.argsort(descending=True)[0]
print(ranking)</p>
<h1 id="tensor1-2-3-0-1">tensor([1, 2, 3, 0])</h1>
<p>LÆ°u Ã½ ráº±ng thá»© háº¡ng Ä‘Æ°á»£c giá»¯ nguyÃªn máº·c dÃ¹ sá»­ dá»¥ng embedding nhá» hÆ¡n 3 láº§n so vá»›i embedding cÃ³ kÃ­ch thÆ°á»›c Ä‘áº§y Ä‘á»§.</p>
<ul>
<li><a href="https://sbert.net/examples/sentence_transformer/training/matryoshka/README.html">TÃ i liá»‡u vá» Embedding Matryoshka cá»§a Sentence Transformers</a></li>
</ul>
<!-- raw HTML omitted -->
<h3 id="langchain">LangChain</h3>
<p>Náº¿u báº¡n thÃ­ch, báº¡n cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng <code>HuggingFaceEmbeddings</code> cá»§a LangChain, sá»­ dá»¥ng Sentence Transformers á»Ÿ cháº¿ Ä‘á»™ ná»n. LÆ°u Ã½ ráº±ng báº¡n sáº½ pháº£i yÃªu cáº§u LangChain sá»­ dá»¥ng cÃ¡c lá»i nháº¯c cÃ³ tÃªn &ldquo;query&rdquo; vÃ  &ldquo;document&rdquo; cho cÃ¡c truy váº¥n vÃ  tÃ i liá»‡u, tÆ°Æ¡ng á»©ng. VÃ­ dá»¥ nÃ y liÃªn quan Ä‘áº¿n má»™t thiáº¿t láº­p truy xuáº¥t thÃ´ng tin Ä‘Æ¡n giáº£n, nhÆ°ng mÃ´ hÃ¬nh embedding tÆ°Æ¡ng tá»± cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c ká»‹ch báº£n phá»©c táº¡p hÆ¡n.</p>
<p>Báº¡n sáº½ cáº§n cÃ i Ä‘áº·t cÃ¡c gÃ³i sau:</p>
<p>pip install git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview
pip install sentence-transformers
pip install langchain
pip install langchain-community
pip install langchain-huggingface
pip install faiss-cpu</p>
<p>python
from langchain.docstore.document import Document
from langchain_community.vectorstores import FAISS
from langchain_huggingface.embeddings import HuggingFaceEmbeddings</p>
<h1 id="táº£i-xuá»‘ng-mÃ´-hÃ¬nh-tá»«--hub-ngoÃ i-ra-hÃ£y-chá»‰-Ä‘á»‹nh-sá»­-dá»¥ng-cÃ¡c-lá»i-nháº¯c-query-vÃ -document">Táº£i xuá»‘ng mÃ´ hÃ¬nh tá»« ğŸ¤— Hub. NgoÃ i ra, hÃ£y chá»‰ Ä‘á»‹nh sá»­ dá»¥ng cÃ¡c lá»i nháº¯c &ldquo;query&rdquo; vÃ  &ldquo;document&rdquo;</h1>
<h1 id="nhÆ°-Ä‘Æ°á»£c-xÃ¡c-Ä‘á»‹nh-trong-cáº¥u-hÃ¬nh-mÃ´-hÃ¬nh-vÃ¬-langchain-khÃ´ng-tá»±-Ä‘á»™ng-sá»­-dá»¥ng-chÃºng">nhÆ° Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong cáº¥u hÃ¬nh mÃ´ hÃ¬nh, vÃ¬ LangChain khÃ´ng tá»± Ä‘á»™ng sá»­ dá»¥ng chÃºng.</h1>
<h1 id="xem">Xem <a href="https://huggingface.co/google/embeddinggemma-300m/blob/main/config_sentence_transformers.json">https://huggingface.co/google/embeddinggemma-300m/blob/main/config_sentence_transformers.json</a></h1>
<p>embedder = HuggingFaceEmbeddings(
model_name=&ldquo;google/embeddinggemma-300m&rdquo;,
query_encode_kwargs={&ldquo;prompt_name&rdquo;: &ldquo;query&rdquo;},
encode_kwargs={&ldquo;prompt_name&rdquo;: &ldquo;document&rdquo;}
)</p>
<p>data = [
&ldquo;Sao Kim thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  song sinh cá»§a TrÃ¡i Äáº¥t vÃ¬ kÃ­ch thÆ°á»›c vÃ  khoáº£ng cÃ¡ch tÆ°Æ¡ng tá»±.&rdquo;,
&ldquo;Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá».&rdquo;,
&ldquo;Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t.&rdquo;,
&ldquo;Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá».&rdquo;
]</p>
<h1 id="táº¡o-tÃ i-liá»‡u-cho-kho-vectÆ¡">Táº¡o tÃ i liá»‡u cho kho vectÆ¡</h1>
<p>documents = [Document(page_content=text, metadata={&ldquo;id&rdquo;: i}) for i, text in enumerate(data)]</p>
<h1 id="táº¡o-kho-vectÆ¡-báº±ng-faiss-Ä‘áº·t-distance_strategy-thÃ nh-max_inner_product-sá»­-dá»¥ng">Táº¡o kho vectÆ¡ báº±ng FAISS. Äáº·t distance_strategy thÃ nh &ldquo;MAX_INNER_PRODUCT&rdquo; sá»­ dá»¥ng</h1>
<h1 id="flatindexip-cá»§a-faiss-á»Ÿ-cháº¿-Ä‘á»™-ná»n-Ä‘Æ°á»£c-tá»‘i-Æ°u-hÃ³a-cho-tÃ¬m-kiáº¿m-tÃ­ch-bÃªn-trong-Ä‘iá»u-nÃ y">FlatIndexIP cá»§a FAISS á»Ÿ cháº¿ Ä‘á»™ ná»n, Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho tÃ¬m kiáº¿m tÃ­ch bÃªn trong. Äiá»u nÃ y</h1>
<h1 id="lÃ -nhá»¯ng-gÃ¬-mÃ´-hÃ¬nh-Ä‘Æ°á»£c-Ä‘Ã o-táº¡o-cho">lÃ  nhá»¯ng gÃ¬ mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã o táº¡o cho</h1>
<p>vector_store = FAISS.from_documents(documents, embedder, distance_strategy=&ldquo;MAX_INNER_PRODUCT&rdquo;)</p>
<h1 id="tÃ¬m-kiáº¿m-3-tÃ i-liá»‡u-tÆ°Æ¡ng-tá»±-hÃ ng-Ä‘áº§u">TÃ¬m kiáº¿m 3 tÃ i liá»‡u tÆ°Æ¡ng tá»± hÃ ng Ä‘áº§u</h1>
<p>query = &ldquo;HÃ nh tinh nÃ o Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá»?&rdquo;
results = vector_store.similarity_search_with_score(query, k=3)</p>
<h1 id="in-káº¿t-quáº£">In káº¿t quáº£</h1>
<p>for doc, score in results:
print(f&quot;VÄƒn báº£n: {doc.page_content} (Ä‘iá»ƒm sá»‘: {score:.4f})&rdquo;)
&quot;&rdquo;&rdquo;
VÄƒn báº£n: Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.6359)
VÄƒn báº£n: Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t. (Ä‘iá»ƒm sá»‘: 0.4930)
VÄƒn báº£n: Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.4889)
&quot;&rdquo;&rdquo;</p>
<ul>
<li><a href="https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html">TÃ i liá»‡u vá» HuggingFaceEmbeddings cá»§a LangChain</a></li>
</ul>
<h3 id="llamaindex">LlamaIndex</h3>
<p>EmbeddingGemma cÅ©ng Ä‘Æ°á»£c há»— trá»£ trong LlamaIndex vÃ¬ nÃ³ sá»­ dá»¥ng Sentence Transformers á»Ÿ cháº¿ Ä‘á»™ ná»n. Äá»ƒ cÃ³ hÃ nh vi chÃ­nh xÃ¡c, báº¡n cáº§n chá»‰ Ä‘á»‹nh cÃ¡c lá»i nháº¯c truy váº¥n vÃ  tÃ i liá»‡u nhÆ° Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong cáº¥u hÃ¬nh mÃ´ hÃ¬nh. Náº¿u khÃ´ng, hiá»‡u suáº¥t cá»§a báº¡n sáº½ khÃ´ng tá»‘i Æ°u. Táº­p lá»‡nh nÃ y cho tháº¥y má»™t vÃ­ dá»¥ sÆ¡ khai vá» cÃ¡ch sá»­ dá»¥ng EmbeddingGemma vá»›i LlamaIndex, nhÆ°ng báº¡n cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng lá»›p <code>HuggingFaceEmbedding</code> trong cÃ¡c cÃ i Ä‘áº·t khÃ³ hÆ¡n.</p>
<p>Báº¡n sáº½ cáº§n cÃ i Ä‘áº·t cÃ¡c gÃ³i sau:</p>
<p>pip install git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview
pip install sentence-transformers
pip install llama-index
pip install llama-index-embeddings-huggingface
pip install llama-index-vector-stores-faiss</p>
<p>python
import faiss
from llama_index.core.schema import TextNode
from llama_index.core.vector_stores import VectorStoreQuery
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.faiss import FaissVectorStore</p>
<h1 id="táº£i-xuá»‘ng-tá»«--hub-ngoÃ i-ra-hÃ£y-chá»‰-Ä‘á»‹nh-cÃ¡c-lá»i-nháº¯c-truy-váº¥n-vÃ -tÃ i-liá»‡u-nhÆ°">Táº£i xuá»‘ng tá»« ğŸ¤— Hub. NgoÃ i ra, hÃ£y chá»‰ Ä‘á»‹nh cÃ¡c lá»i nháº¯c truy váº¥n vÃ  tÃ i liá»‡u nhÆ°</h1>
<h1 id="Ä‘Æ°á»£c-xÃ¡c-Ä‘á»‹nh-trong-cáº¥u-hÃ¬nh-mÃ´-hÃ¬nh-vÃ¬-llamaindex-khÃ´ng-tá»±-Ä‘á»™ng-táº£i-chÃºng">Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong cáº¥u hÃ¬nh mÃ´ hÃ¬nh, vÃ¬ LlamaIndex khÃ´ng tá»± Ä‘á»™ng táº£i chÃºng.</h1>
<h1 id="xem-1">Xem <a href="https://huggingface.co/google/embeddinggemma-300m/blob/main/config_sentence_transformers.json">https://huggingface.co/google/embeddinggemma-300m/blob/main/config_sentence_transformers.json</a></h1>
<p>embeddings = HuggingFaceEmbedding(
model_name=&ldquo;google/embeddinggemma-300m&rdquo;,
query_instruction=&ldquo;task: search result | query: &ldquo;,
text_instruction=&ldquo;title: none | text: &ldquo;,
)</p>
<p>data = [
&ldquo;Sao Kim thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  song sinh cá»§a TrÃ¡i Äáº¥t vÃ¬ kÃ­ch thÆ°á»›c vÃ  khoáº£ng cÃ¡ch tÆ°Æ¡ng tá»±.&rdquo;,
&ldquo;Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá».&rdquo;,
&ldquo;Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t.&rdquo;,
&ldquo;Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá».&rdquo;
]</p>
<h1 id="táº¡o-má»™t-kho-vectÆ¡-máº«u">Táº¡o má»™t kho vectÆ¡ máº«u</h1>
<p>store = FaissVectorStore(faiss_index=faiss.IndexFlatIP(768))
store.add([TextNode(id=i, text=text, embedding=embeddings.get_text_embedding(text)) for i, text in enumerate(data)])</p>
<h1 id="tÃ¬m-kiáº¿m-k-tÃ i-liá»‡u-tÆ°Æ¡ng-tá»±-hÃ ng-Ä‘áº§u">TÃ¬m kiáº¿m k tÃ i liá»‡u tÆ°Æ¡ng tá»± hÃ ng Ä‘áº§u</h1>
<p>query = &ldquo;HÃ nh tinh nÃ o Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá»?&rdquo;
query_embedding = embeddings.get_query_embedding(query)
results = store.query(VectorStoreQuery(query_embedding=query_embedding, similarity_top_k=3))</p>
<h1 id="in-káº¿t-quáº£-1">In káº¿t quáº£</h1>
<p>for idx, score in zip(results.ids, results.similarities):
print(f&quot;VÄƒn báº£n: {data[int(idx)]} (Ä‘iá»ƒm sá»‘: {score:.4f})&rdquo;)
&quot;&rdquo;&rdquo;
VÄƒn báº£n: Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.6359)
VÄƒn báº£n: Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t. (Ä‘iá»ƒm sá»‘: 0.4930)
VÄƒn báº£n: Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.4889)
&quot;&rdquo;&rdquo;</p>
<ul>
<li><a href="https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface/">TÃ i liá»‡u vá» HuggingFaceEmbedding cá»§a LlamaIndex</a></li>
</ul>
<h3 id="haystack">Haystack</h3>
<p>EmbeddingGemma cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i Haystack, má»™t framework Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c á»©ng dá»¥ng ngÃ´n ngá»¯ vÃ  tÃ¬m kiáº¿m sáºµn sÃ ng cho sáº£n xuáº¥t. Giá»‘ng nhÆ° LangChain vÃ  LlamaIndex, Haystack sá»­ dá»¥ng Sentence Transformers á»Ÿ cháº¿ Ä‘á»™ ná»n vÃ  yÃªu cáº§u báº¡n chá»‰ Ä‘á»‹nh cÃ¡c lá»i nháº¯c thÃ­ch há»£p. VÃ­ dá»¥ sau Ä‘Ã¢y cho tháº¥y cÃ¡ch thiáº¿t láº­p má»™t quy trÃ¬nh truy xuáº¥t cÆ¡ báº£n báº±ng EmbeddingGemma vá»›i Haystack.</p>
<p>Báº¡n sáº½ cáº§n cÃ i Ä‘áº·t cÃ¡c gÃ³i sau:</p>
<p>pip install git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview
pip install sentence-transformers
pip install haystack-ai</p>
<p>python
from haystack import Document, Pipeline
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder
from haystack.components.retrievers import InMemoryEmbeddingRetriever
from haystack.document_stores.in_memory import InMemoryDocumentStore</p>
<h1 id="khá»Ÿi-táº¡o-kho-tÃ i-liá»‡u">Khá»Ÿi táº¡o kho tÃ i liá»‡u</h1>
<p>document_store = InMemoryDocumentStore()</p>
<h1 id="khá»Ÿi-táº¡o-cÃ¡c-embedder-tÃ i-liá»‡u-vÃ -truy-váº¥n">Khá»Ÿi táº¡o cÃ¡c embedder tÃ i liá»‡u vÃ  truy váº¥n</h1>
<p>document_embedder = SentenceTransformersDocumentEmbedder(
model=&ldquo;google/embeddinggemma-300m&rdquo;, encode_kwargs={&ldquo;prompt_name&rdquo;: &ldquo;document&rdquo;}
)
query_embedder = SentenceTransformersTextEmbedder(
model=&ldquo;google/embeddinggemma-300m&rdquo;, encode_kwargs={&ldquo;prompt_name&rdquo;: &ldquo;query&rdquo;}
)
document_embedder.warm_up()
query_embedder.warm_up()</p>
<p>data = [
&ldquo;Sao Kim thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  song sinh cá»§a TrÃ¡i Äáº¥t vÃ¬ kÃ­ch thÆ°á»›c vÃ  khoáº£ng cÃ¡ch tÆ°Æ¡ng tá»±.&rdquo;,
&ldquo;Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá».&rdquo;,
&ldquo;Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t.&rdquo;,
&ldquo;Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá».&rdquo;,
]</p>
<h1 id="chuyá»ƒn-Ä‘á»•i-thÃ nh-tÃ i-liá»‡u-haystack-vÃ -ghi-vÃ o-kho-tÃ i-liá»‡u">Chuyá»ƒn Ä‘á»•i thÃ nh tÃ i liá»‡u Haystack vÃ  ghi vÃ o kho tÃ i liá»‡u</h1>
<p>documents = [Document(content=text, id=str(i)) for i, text in enumerate(data)]
documents_with_embeddings = document_embedder.run(documents=documents)[&ldquo;documents&rdquo;]
document_store.write_documents(documents_with_embeddings)</p>
<h1 id="táº¡o-má»™t-quy-trÃ¬nh-truy-váº¥n-báº±ng-cÃ¡ch-sá»­-dá»¥ng-embedder-truy-váº¥n-vÃ -trÃ¬nh-truy-xuáº¥t-tÆ°Æ¡ng-thÃ­ch">Táº¡o má»™t quy trÃ¬nh truy váº¥n báº±ng cÃ¡ch sá»­ dá»¥ng embedder truy váº¥n vÃ  trÃ¬nh truy xuáº¥t tÆ°Æ¡ng thÃ­ch</h1>
<p>query_pipeline = Pipeline()
query_pipeline.add_component(&ldquo;text_embedder&rdquo;, query_embedder)
query_pipeline.add_component(&ldquo;retriever&rdquo;, InMemoryEmbeddingRetriever(document_store=document_store, top_k=3))
query_pipeline.connect(&ldquo;text_embedder.embedding&rdquo;, &ldquo;retriever.query_embedding&rdquo;)</p>
<h1 id="tÃ¬m-kiáº¿m-3-tÃ i-liá»‡u-tÆ°Æ¡ng-tá»±-hÃ ng-Ä‘áº§u-1">TÃ¬m kiáº¿m 3 tÃ i liá»‡u tÆ°Æ¡ng tá»± hÃ ng Ä‘áº§u</h1>
<p>query = &ldquo;HÃ nh tinh nÃ o Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá»?&rdquo;
results = query_pipeline.run({&ldquo;text_embedder&rdquo;: {&ldquo;text&rdquo;: query}})</p>
<h1 id="in-káº¿t-quáº£-2">In káº¿t quáº£</h1>
<p>for document in results[&ldquo;retriever&rdquo;][&ldquo;documents&rdquo;]:
print(f&quot;VÄƒn báº£n: {document.content} (Ä‘iá»ƒm sá»‘: {document.score:.4f})&rdquo;)
&quot;&rdquo;&rdquo;
VÄƒn báº£n: Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.6359)
VÄƒn báº£n: Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t. (Ä‘iá»ƒm sá»‘: 0.4930)
VÄƒn báº£n: Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.4889)
&quot;&rdquo;&rdquo;</p>
<ul>
<li><a href="https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever">TÃ i liá»‡u vá» InMemoryEmbeddingRetriever cá»§a Haystack</a></li>
</ul>
<h3 id="txtai">txtai</h3>
<p>txtai cÅ©ng tÆ°Æ¡ng thÃ­ch vá»›i EmbeddingGemma. Giá»‘ng nhÆ° cÃ¡c framework khÃ¡c, txtai sá»­ dá»¥ng Sentence Transformers á»Ÿ cháº¿ Ä‘á»™ ná»n vÃ  cáº§n cÃ¡c lá»i nháº¯c thÃ­ch há»£p Ä‘á»ƒ cÃ³ hiá»‡u suáº¥t tá»‘i Æ°u vá»›i EmbeddingGemma. VÃ­ dá»¥ sau Ä‘Ã¢y trÃ¬nh bÃ y cÃ¡ch thiáº¿t láº­p má»™t há»‡ thá»‘ng truy xuáº¥t cÆ¡ báº£n vá»›i txtai.</p>
<p>Báº¡n sáº½ cáº§n cÃ i Ä‘áº·t cÃ¡c gÃ³i sau:</p>
<p>pip install git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview
pip install sentence-transformers
pip install txtai</p>
<p>python
from txtai import Embeddings</p>
<h1 id="táº£i-xuá»‘ng-tá»«--hub-ngoÃ i-ra-hÃ£y-chá»‰-Ä‘á»‹nh-cÃ¡c-lá»i-nháº¯c-truy-váº¥n-vÃ -tÃ i-liá»‡u-nhÆ°-1">Táº£i xuá»‘ng tá»« ğŸ¤— Hub. NgoÃ i ra, hÃ£y chá»‰ Ä‘á»‹nh cÃ¡c lá»i nháº¯c truy váº¥n vÃ  tÃ i liá»‡u nhÆ°</h1>
<h1 id="Ä‘Æ°á»£c-xÃ¡c-Ä‘á»‹nh-trong-cáº¥u-hÃ¬nh-mÃ´-hÃ¬nh-vÃ¬-txtai-khÃ´ng-tá»±-Ä‘á»™ng-táº£i-chÃºng">Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong cáº¥u hÃ¬nh mÃ´ hÃ¬nh, vÃ¬ txtai khÃ´ng tá»± Ä‘á»™ng táº£i chÃºng.</h1>
<h1 id="xem-2">Xem <a href="https://huggingface.co/google/embeddinggemma-300m/blob/main/config_sentence_transformers.json">https://huggingface.co/google/embeddinggemma-300m/blob/main/config_sentence_transformers.json</a></h1>
<p>embeddings = Embeddings(
path=&ldquo;google/embeddinggemma-300m&rdquo;,
method=&ldquo;sentence-transformers&rdquo;,
instructions={
&ldquo;query&rdquo;: &ldquo;task: search result | query: &ldquo;,
&ldquo;data&rdquo;: &ldquo;title: none | text: &ldquo;,
}
)</p>
<p>data = [
&ldquo;Sao Kim thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  song sinh cá»§a TrÃ¡i Äáº¥t vÃ¬ kÃ­ch thÆ°á»›c vÃ  khoáº£ng cÃ¡ch tÆ°Æ¡ng tá»±.&rdquo;,
&ldquo;Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá».&rdquo;,
&ldquo;Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t.&rdquo;,
&ldquo;Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá».&rdquo;,
]</p>
<h1 id="táº¡o-má»™t-kho-vectÆ¡-máº«u-1">Táº¡o má»™t kho vectÆ¡ máº«u</h1>
<p>embeddings.index(data)</p>
<h1 id="tÃ¬m-kiáº¿m-k-tÃ i-liá»‡u-tÆ°Æ¡ng-tá»±-hÃ ng-Ä‘áº§u-1">TÃ¬m kiáº¿m k tÃ i liá»‡u tÆ°Æ¡ng tá»± hÃ ng Ä‘áº§u</h1>
<p>query = &ldquo;HÃ nh tinh nÃ o Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá»?&rdquo;
results = embeddings.search(query, 3)</p>
<h1 id="in-káº¿t-quáº£-3">In káº¿t quáº£</h1>
<p>for idx, score in results:
print(f&quot;VÄƒn báº£n: {data[int(idx)]} (Ä‘iá»ƒm sá»‘: {score:.4f})&rdquo;)
&quot;&rdquo;&rdquo;
VÄƒn báº£n: Sao Há»a, Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i váº» ngoÃ i hÆ¡i Ä‘á», thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.6359)
VÄƒn báº£n: Sao Má»™c, hÃ nh tinh lá»›n nháº¥t trong há»‡ máº·t trá»i cá»§a chÃºng ta, cÃ³ má»™t váº¿t Ä‘á» ná»•i báº­t. (Ä‘iá»ƒm sá»‘: 0.4930)
VÄƒn báº£n: Sao Thá»•, ná»•i tiáº¿ng vá»›i cÃ¡c vÃ nh Ä‘ai, Ä‘Ã´i khi bá»‹ nháº§m vá»›i HÃ nh tinh Äá». (Ä‘iá»ƒm sá»‘: 0.4889)
&quot;&rdquo;&rdquo;</p>
<ul>
<li><a href="https://docs.haystack.deepset.ai/docs/inmemoryembeddingretriever">TÃ i liá»‡u vá» InMemoryEmbeddingRetriever cá»§a Haystack</a></li>
</ul>
<h3 id="transformersjs">Transformers.js</h3>
<p>Báº¡n tháº­m chÃ­ cÃ³ thá»ƒ cháº¡y EmbeddingGemma cá»¥c bá»™ 100% trong trÃ¬nh duyá»‡t cá»§a báº¡n vá»›i <a href="https://huggingface.co/docs/transformers.js/en/index">Transformers.js</a>! Náº¿u báº¡n chÆ°a cÃ³, báº¡n cÃ³ thá»ƒ cÃ i Ä‘áº·t thÆ° viá»‡n tá»« <a href="https://www.npmjs.com/package/@huggingface/transformers">NPM</a> báº±ng</p>
<h3 id="link-bÃ i-viáº¿t-gá»‘c"><a href="https://huggingface.co/blog/embeddinggemma">Link bÃ i viáº¿t gá»‘c</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/september-4-2025/">September 4, 2025</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-27/a5ab6d/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/faster-transformers/thumbnail.png" alt="CÃ¡c thá»§ thuáº­t tá»« OpenAI gpt-oss mÃ  Báº N ğŸ«µ cÃ³ thá»ƒ sá»­ dá»¥ng vá»›i transformers" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-09-27T00:00:00&#43;00:00">Sep 27, 2025</time>

		<h3 class="my-4 text-2xl font-bold">CÃ¡c thá»§ thuáº­t tá»« OpenAI gpt-oss mÃ  Báº N ğŸ«µ cÃ³ thá»ƒ sá»­ dá»¥ng vá»›i transformers</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2"></p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-27/777761/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/riskrubric/thumbnail.png" alt="DÃ¢n chá»§ hÃ³a An toÃ n AI vá»›i RiskRubric.ai" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-09-27T00:00:00&#43;00:00">Sep 27, 2025</time>

		<h3 class="my-4 text-2xl font-bold">DÃ¢n chá»§ hÃ³a An toÃ n AI vá»›i RiskRubric.ai</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2"></p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-16/4423db/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://lh3.googleusercontent.com/_ys2ESbxOZmEx8DpK8yKDikkqRuN_b_Z674d5WRSnC2gvHKdLZFo3tfoGjSoJVs2X0kruqz_uG3ww5Xo4JmdRViU0cJLT5I3RfZBoH2Pa4pj4eo3-Q=w400-h225-n-nu" alt="ÄÆ°a AI Ä‘áº¿n tháº¿ há»‡ nÄƒng lÆ°á»£ng nhiá»‡t háº¡ch tiáº¿p theo" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">ÄÆ°a AI Ä‘áº¿n tháº¿ há»‡ nÄƒng lÆ°á»£ng nhiá»‡t háº¡ch tiáº¿p theo</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-16/882956/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png" alt="GPT OSS trÃªn Google Cloud C4 mang láº¡i cáº£i thiá»‡n 70% TCO trÃªn GPT OSS vá»›i Intel vÃ  Hugging Face" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">GPT OSS trÃªn Google Cloud C4 mang láº¡i cáº£i thiá»‡n 70% TCO trÃªn GPT OSS vá»›i Intel vÃ  Hugging Face</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-14/f9c7fe/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6905c83d0735e1bc430025fdd1748d1406079036-1000x1000.svg" alt="Anthropic vÃ  Salesforce má»Ÿ rá»™ng quan há»‡ Ä‘á»‘i tÃ¡c Ä‘á»ƒ Ä‘Æ°a Claude Ä‘áº¿n cÃ¡c ngÃ nh cÃ´ng nghiá»‡p Ä‘Æ°á»£c quáº£n lÃ½" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Anthropic vÃ  Salesforce má»Ÿ rá»™ng quan há»‡ Ä‘á»‘i tÃ¡c Ä‘á»ƒ Ä‘Æ°a Claude Ä‘áº¿n cÃ¡c ngÃ nh cÃ´ng nghiá»‡p Ä‘Æ°á»£c quáº£n lÃ½</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-14/3d6226/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www.microsoft.com/en-us/ai/blog/wp-content/uploads/2025/10/From-Vision-to-Impact-Advancing-Public-Finance-Transformation-Through-AI-and-Ecosystem-Collaboration-Featured-1024x575.jpg" alt="Tá»« táº§m nhÃ¬n Ä‘áº¿n tÃ¡c Ä‘á»™ng- ThÃºc Ä‘áº©y chuyá»ƒn Ä‘á»•i tÃ i chÃ­nh cÃ´ng thÃ´ng qua AI vÃ  há»£p tÃ¡c há»‡ sinh thÃ¡i" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Tá»« táº§m nhÃ¬n Ä‘áº¿n tÃ¡c Ä‘á»™ng- ThÃºc Ä‘áº©y chuyá»ƒn Ä‘á»•i tÃ i chÃ­nh cÃ´ng thÃ´ng qua AI vÃ  há»£p tÃ¡c há»‡ sinh thÃ¡i</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-10-10/883183/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">AI21â€™s Jamba Reasoning 3B tÃ¡i Ä‘á»‹nh nghÄ©a &#39;Nhá»&#39; cÃ³ nghÄ©a lÃ  gÃ¬ trong LLM â€” Bá»‘i cáº£nh 250K trÃªn MÃ¡y tÃ­nh xÃ¡ch tay</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo dÃµi cÃ¡c tiáº¿n bá»™ má»›i nháº¥t vá» TrÃ­ tuá»‡ nhÃ¢n táº¡o.<br>Trá»±c tiáº¿p tá»« cÃ¡c nhÃ  phÃ¡t hÃ nh AI trÃªn tháº¿ giá»›i.
      </p>

      <p>Äem trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘áº¿n má»i ngÆ°á»i dÃ¢n, doanh nghiá»‡p Viá»‡t, gÃ³p pháº§n giÃºp Viá»‡t Nam phÃ¡t triá»ƒn máº¡nh máº½ trong ká»· nguyÃªn sá»‘. Ná»™i dung Ä‘Æ°á»£c cáº­p nháº­t tá»± Ä‘á»™ng báº±ng mÃ¡y.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright Â© 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>