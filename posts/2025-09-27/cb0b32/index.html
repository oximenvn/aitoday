<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>mmBERT- ModernBERT trá»Ÿ nÃªn Ä‘a ngÃ´n ngá»¯ | AI Today - SkyAI</title>

<meta name="description" content="">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['â¯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['â¯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">mmBERT- ModernBERT trá»Ÿ nÃªn Ä‘a ngÃ´n ngá»¯</h1>

      <div id="lead" class="my-6">

        <p class="font-bold"> </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['â€¢'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-09-27T00:00:00&#43;00:00">September 27, 2025</time>
          </li>

          <li class="before:content-['â€¢'] before:mr-2 before:opacity-50 my-2">
            18 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://huggingface.co/blog/assets/mmbert/thumbnail.png" alt="mmBERT- ModernBERT trá»Ÿ nÃªn Ä‘a ngÃ´n ngá»¯">
        <figcaption class="text-center italic text-xs"></figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="mmbert-modernbert-vÆ°Æ¡n-mÃ¬nh-ra-Ä‘a-ngÃ´n-ngá»¯">mmBERT: ModernBERT vÆ°Æ¡n mÃ¬nh ra Äa ngÃ´n ngá»¯</h1>
<p>BÃ i viáº¿t nÃ y giá»›i thiá»‡u <a href="https://huggingface.co/collections/jhu-clsp/mmbert-a-modern-multilingual-encoder-68b725831d7c6e3acc435ed4">mmBERT</a>, má»™t mÃ´ hÃ¬nh mÃ£ hÃ³a Ä‘a ngÃ´n ngá»¯ lá»›n hiá»‡n Ä‘áº¡i, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn hÆ¡n 3 nghÃ¬n tá»· token vÄƒn báº£n á»Ÿ hÆ¡n 1800 ngÃ´n ngá»¯. NÃ³ cho tháº¥y sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» hiá»‡u suáº¥t vÃ  tá»‘c Ä‘á»™ so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘a ngÃ´n ngá»¯ trÆ°á»›c Ä‘Ã¢y, lÃ  mÃ´ hÃ¬nh Ä‘áº§u tiÃªn cáº£i thiá»‡n XLM-R, Ä‘á»“ng thá»i phÃ¡t triá»ƒn cÃ¡c chiáº¿n lÆ°á»£c má»›i Ä‘á»ƒ há»c hiá»‡u quáº£ cÃ¡c ngÃ´n ngá»¯ Ã­t tÃ i nguyÃªn. mmBERT xÃ¢y dá»±ng dá»±a trÃªn ModernBERT cho má»™t kiáº¿n trÃºc cá»±c nhanh vÃ  thÃªm cÃ¡c thÃ nh pháº§n má»›i Ä‘á»ƒ cho phÃ©p há»c Ä‘a ngÃ´n ngá»¯ hiá»‡u quáº£.</p>
<p>Náº¿u báº¡n quan tÃ¢m Ä‘áº¿n viá»‡c tá»± mÃ¬nh thá»­ cÃ¡c mÃ´ hÃ¬nh, má»™t sá»‘ boilerplate vÃ­ dá»¥ cÃ³ sáºµn <a href="#usage-examples">á»Ÿ cuá»‘i bÃ i Ä‘Äƒng trÃªn blog nÃ y!</a></p>
<h2 id="tldr">TL;DR</h2>
<ul>
<li>mmBERT lÃ  má»™t mÃ´ hÃ¬nh mÃ£ hÃ³a Ä‘a ngÃ´n ngá»¯ hiá»‡n Ä‘áº¡i, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn hÆ¡n 3 nghÃ¬n tá»· token á»Ÿ hÆ¡n 1800 ngÃ´n ngá»¯.</li>
<li>mmBERT cho tháº¥y sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» hiá»‡u suáº¥t vÃ  tá»‘c Ä‘á»™ so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘a ngÃ´n ngá»¯ trÆ°á»›c Ä‘Ã¢y.</li>
<li>mmBERT phÃ¡t triá»ƒn cÃ¡c chiáº¿n lÆ°á»£c má»›i Ä‘á»ƒ há»c hiá»‡u quáº£ cÃ¡c ngÃ´n ngá»¯ Ã­t tÃ i nguyÃªn.</li>
</ul>
<h2 id="dá»¯-liá»‡u-huáº¥n-luyá»‡n">Dá»¯ liá»‡u huáº¥n luyá»‡n</h2>
<!-- raw HTML omitted -->
<p>mmBERT Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p dá»¯ liá»‡u Ä‘a ngÃ´n ngá»¯ Ä‘Æ°á»£c tuyá»ƒn chá»n cáº©n tháº­n vá»›i tá»•ng cá»™ng hÆ¡n 3T token qua ba giai Ä‘oáº¡n huáº¥n luyá»‡n riÃªng biá»‡t. Ná»n táº£ng cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a chÃºng tÃ´i bao gá»“m ba láº§n thu tháº­p dá»¯ liá»‡u web nguá»“n má»Ÿ vÃ  cháº¥t lÆ°á»£ng cao chÃ­nh, cho phÃ©p cáº£ Ä‘á»™ bao phá»§ Ä‘a ngÃ´n ngá»¯ vÃ  cháº¥t lÆ°á»£ng dá»¯ liá»‡u:</p>
<p><strong>DCLM vÃ  DCLM Ä‘Æ°á»£c lá»c</strong> cung cáº¥p ná»™i dung tiáº¿ng Anh cháº¥t lÆ°á»£ng cao nháº¥t hiá»‡n cÃ³, Ä‘Ã³ng vai trÃ² lÃ  xÆ°Æ¡ng sá»‘ng cho hiá»‡u suáº¥t tiáº¿ng Anh máº¡nh máº½ (vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c lá»c Ä‘áº¿n tá»« <a href="https://huggingface.co/datasets/allenai/dolmino-mix-1124">Dolmino</a>). Táº­p dá»¯ liá»‡u nÃ y thá»ƒ hiá»‡n cÃ¡c ká»¹ thuáº­t lá»c web hiá»‡n Ä‘áº¡i vÃ  táº¡o thÃ nh má»™t thÃ nh pháº§n quan trá»ng. Do cháº¥t lÆ°á»£ng cao cá»§a dá»¯ liá»‡u nÃ y, chÃºng tÃ´i sá»­ dá»¥ng tá»· lá»‡ tiáº¿ng Anh cao hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£ hÃ³a Ä‘a ngÃ´n ngá»¯ tháº¿ há»‡ trÆ°á»›c (lÃªn Ä‘áº¿n 18%).</p>
<p><strong>FineWeb2</strong> cung cáº¥p ná»™i dung web Ä‘a ngÃ´n ngá»¯ rá»™ng lá»›n <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-2">multilingual web content</a> bao gá»“m hÆ¡n 1.800 ngÃ´n ngá»¯. Táº­p dá»¯ liá»‡u nÃ y cho phÃ©p Ä‘á»™ bao phá»§ Ä‘a ngÃ´n ngá»¯ má»Ÿ rá»™ng cá»§a chÃºng tÃ´i trong khi váº«n duy trÃ¬ cÃ¡c tiÃªu chuáº©n cháº¥t lÆ°á»£ng há»£p lÃ½ trÃªn cÃ¡c há» ngÃ´n ngá»¯ vÃ  báº£ng chá»¯ cÃ¡i Ä‘a dáº¡ng.</p>
<p><strong>FineWeb2-HQ</strong> bao gá»“m má»™t <a href="https://huggingface.co/datasets/epfml/FineWeb2-HQ">filtered subset of FineWeb2</a> táº­p trung vÃ o 20 ngÃ´n ngá»¯ cÃ³ nhiá»u tÃ i nguyÃªn. PhiÃªn báº£n Ä‘Æ°á»£c lá»c nÃ y cung cáº¥p ná»™i dung Ä‘a ngÃ´n ngá»¯ cháº¥t lÆ°á»£ng cao hÆ¡n, thu háº¹p khoáº£ng cÃ¡ch giá»¯a dá»¯ liá»‡u Ä‘Æ°á»£c lá»c chá»‰ báº±ng tiáº¿ng Anh vÃ  Ä‘á»™ bao phá»§ Ä‘a ngÃ´n ngá»¯ rá»™ng rÃ£i.</p>
<p>Dá»¯ liá»‡u huáº¥n luyá»‡n cÅ©ng káº¿t há»£p cÃ¡c kho ngá»¯ liá»‡u chuyÃªn dá»¥ng tá»« <a href="https://arxiv.org/abs/2402.00159">Dolma</a>, <a href="https://arxiv.org/abs/2508.03828">MegaWika v2</a>, <a href="https://arxiv.org/abs/2410.02660">ProLong</a> vÃ  hÆ¡n tháº¿ ná»¯a: kho mÃ£ (StarCoder, ProLong), ná»™i dung há»c thuáº­t (ArXiv, PeS2o), tÃ i liá»‡u tham kháº£o (Wikipedia, sÃ¡ch giÃ¡o khoa) vÃ  tháº£o luáº­n cá»™ng Ä‘á»“ng (StackExchange), cÃ¹ng vá»›i hÆ°á»›ng dáº«n vÃ  táº­p dá»¯ liá»‡u toÃ¡n há»c.</p>
<p>Äá»•i má»›i quan trá»ng trong phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n dá»¯ liá»‡u cá»§a chÃºng tÃ´i lÃ  <strong>chiáº¿n lÆ°á»£c bao gá»“m ngÃ´n ngá»¯ lÅ©y tiáº¿n</strong> Ä‘Æ°á»£c hiá»ƒn thá»‹ trong <a href="#figure1">HÃ¬nh 1</a>. á» má»—i giai Ä‘oáº¡n, chÃºng tÃ´i láº¥y máº«u dáº§n dáº§n tá»« phÃ¢n phá»‘i <em>pháº³ng hÆ¡n</em> (tá»©c lÃ  gáº§n vá»›i Ä‘á»“ng nháº¥t hÆ¡n), Ä‘á»“ng thá»i thÃªm cÃ¡c ngÃ´n ngá»¯ má»›i. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ¡c ngÃ´n ngá»¯ cÃ³ nhiá»u tÃ i nguyÃªn nhÆ° tiáº¿ng Nga báº¯t Ä‘áº§u vá»›i tá»· lá»‡ dá»¯ liá»‡u cao (tá»©c lÃ  9%) vÃ  sau Ä‘Ã³ trong giai Ä‘oáº¡n huáº¥n luyá»‡n cuá»‘i cÃ¹ng káº¿t thÃºc khoáº£ng má»™t ná»­a tá»· lá»‡ Ä‘Ã³. ChÃºng tÃ´i báº¯t Ä‘áº§u vá»›i 60 ngÃ´n ngá»¯ cÃ³ nhiá»u tÃ i nguyÃªn trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n trÆ°á»›c, má»Ÿ rá»™ng lÃªn 110 ngÃ´n ngá»¯ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n giá»¯a vÃ  cuá»‘i cÃ¹ng bao gá»“m táº¥t cáº£ 1.833 ngÃ´n ngá»¯ tá»« FineWeb2 trong giai Ä‘oáº¡n phÃ¢n rÃ£. Äiá»u nÃ y cho phÃ©p chÃºng tÃ´i tá»‘i Ä‘a hÃ³a tÃ¡c Ä‘á»™ng cá»§a dá»¯ liá»‡u ngÃ´n ngá»¯ Ã­t tÃ i nguyÃªn háº¡n cháº¿ mÃ  khÃ´ng cáº§n láº·p láº¡i quÃ¡ má»©c vÃ  Ä‘á»“ng thá»i duy trÃ¬ cháº¥t lÆ°á»£ng dá»¯ liá»‡u tá»•ng thá»ƒ cao.</p>
<h2 id="cÃ´ng-thá»©c-huáº¥n-luyá»‡n-vÃ -cÃ¡c-thÃ nh-pháº§n-má»›i">CÃ´ng thá»©c huáº¥n luyá»‡n vÃ  cÃ¡c thÃ nh pháº§n má»›i</h2>
<p>mmBERT xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n trÃºc <a href="https://huggingface.co/blog/modernbert">ModernBERT</a> nhÆ°ng giá»›i thiá»‡u má»™t sá»‘ Ä‘á»•i má»›i chÃ­nh Ä‘á»ƒ há»c Ä‘a ngÃ´n ngá»¯:</p>
<h3 id="kiáº¿n-trÃºc">Kiáº¿n trÃºc</h3>
<p>ChÃºng tÃ´i sá»­ dá»¥ng cÃ¹ng má»™t kiáº¿n trÃºc cá»‘t lÃµi vá»›i ModernBERT-base vá»›i 22 lá»›p vÃ  1152 kÃ­ch thÆ°á»›c trung gian, nhÆ°ng chuyá»ƒn sang bá»™ mÃ£ hÃ³a thÃ´ng bÃ¡o Gemma 2 Ä‘á»ƒ xá»­ lÃ½ vÄƒn báº£n Ä‘a ngÃ´n ngá»¯ tá»‘t hÆ¡n. MÃ´ hÃ¬nh cÆ¡ sá»Ÿ cÃ³ 110 triá»‡u tham sá»‘ khÃ´ng nhÃºng (tá»•ng cá»™ng 307 triá»‡u do tá»« vá»±ng lá»›n hÆ¡n), trong khi biáº¿n thá»ƒ nhá» cÃ³ 42 triá»‡u tham sá»‘ khÃ´ng nhÃºng (tá»•ng cá»™ng 140 triá»‡u).</p>
<h3 id="phÆ°Æ¡ng-phÃ¡p-huáº¥n-luyá»‡n-ba-giai-Ä‘oáº¡n">PhÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n ba giai Ä‘oáº¡n</h3>
<p>QuÃ¡ trÃ¬nh huáº¥n luyá»‡n cá»§a chÃºng tÃ´i tuÃ¢n theo má»™t lá»‹ch trÃ¬nh ba giai Ä‘oáº¡n Ä‘Æ°á»£c thiáº¿t káº¿ cáº©n tháº­n:</p>
<ol>
<li><strong>Huáº¥n luyá»‡n trÆ°á»›c (2,3T token)</strong>: Khá»Ÿi Ä‘á»™ng vÃ  giai Ä‘oáº¡n tá»‘c Ä‘á»™ há»c á»•n Ä‘á»‹nh sá»­ dá»¥ng 60 ngÃ´n ngá»¯ vá»›i tá»· lá»‡ che phá»§ 30%</li>
<li><strong>Huáº¥n luyá»‡n giá»¯a (600B token)</strong>: Má»Ÿ rá»™ng ngá»¯ cáº£nh lÃªn 8192 token, dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao hÆ¡n, má»Ÿ rá»™ng lÃªn 110 ngÃ´n ngá»¯ vá»›i tá»· lá»‡ che phá»§ 15%</li>
<li><strong>Giai Ä‘oáº¡n phÃ¢n rÃ£ (100B token)</strong>: PhÃ¢n rÃ£ tá»‘c Ä‘á»™ há»c cÄƒn báº­c hai nghá»‹ch Ä‘áº£o, bao gá»“m táº¥t cáº£ 1.833 ngÃ´n ngá»¯ vá»›i tá»· lá»‡ che phá»§ 5%</li>
</ol>
<h3 id="ká»¹-thuáº­t-huáº¥n-luyá»‡n-má»›i">Ká»¹ thuáº­t huáº¥n luyá»‡n má»›i</h3>
<p><strong>Lá»‹ch trÃ¬nh Tá»· lá»‡ Che phá»§ Nghá»‹ch Ä‘áº£o</strong>: Thay vÃ¬ sá»­ dá»¥ng tá»· lá»‡ che phá»§ cá»‘ Ä‘á»‹nh, chÃºng tÃ´i giáº£m dáº§n tá»· lá»‡ che phá»§ tá»« 30% â†’ 15% â†’ 5% trong cÃ¡c giai Ä‘oáº¡n huáº¥n luyá»‡n. Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c biá»ƒu diá»…n cÆ¡ báº£n vá»›i Ä‘á»™ che phá»§ cao hÆ¡n sá»›m hÆ¡n, sau Ä‘Ã³ táº­p trung vÃ o sá»± hiá»ƒu biáº¿t sáº¯c thÃ¡i hÆ¡n vá»›i tá»· lá»‡ che phá»§ tháº¥p hÆ¡n.</p>
<p><strong>Há»c NgÃ´n ngá»¯ TÃ´i luyá»‡n</strong>: ChÃºng tÃ´i Ä‘iá»u chá»‰nh Ä‘á»™ng nhiá»‡t Ä‘á»™ Ä‘á»ƒ láº¥y máº«u dá»¯ liá»‡u Ä‘a ngÃ´n ngá»¯ tá»« Ï„=0,7 â†’ 0,5 â†’ 0,3. Äiá»u nÃ y táº¡o ra má»™t sá»± tiáº¿n triá»ƒn tá»« Ä‘á»™ lá»‡ch ngÃ´n ngá»¯ tÃ i nguyÃªn cao sang láº¥y máº«u Ä‘á»“ng Ä‘á»u hÆ¡n, cho phÃ©p mÃ´ hÃ¬nh xÃ¢y dá»±ng ná»n táº£ng Ä‘a ngÃ´n ngá»¯ máº¡nh máº½ trÆ°á»›c khi há»c cÃ¡c ngÃ´n ngá»¯ Ã­t tÃ i nguyÃªn.</p>
<p><strong>Bá»• sung NgÃ´n ngá»¯ LÅ©y tiáº¿n</strong>: Thay vÃ¬ huáº¥n luyá»‡n trÃªn táº¥t cáº£ cÃ¡c ngÃ´n ngá»¯ Ä‘á»“ng thá»i, chÃºng tÃ´i thÃªm má»™t cÃ¡ch chiáº¿n lÆ°á»£c cÃ¡c ngÃ´n ngá»¯ á»Ÿ má»—i giai Ä‘oáº¡n (60 â†’ 110 â†’ 1.833). Äiá»u nÃ y tá»‘i Ä‘a hÃ³a hiá»‡u quáº£ há»c táº­p báº±ng cÃ¡ch trÃ¡nh cÃ¡c ká»· nguyÃªn quÃ¡ má»©c trÃªn dá»¯ liá»‡u Ã­t tÃ i nguyÃªn háº¡n cháº¿ trong khi váº«n Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t máº¡nh máº½.</p>
<p><strong>Há»£p nháº¥t MÃ´ hÃ¬nh</strong>: ChÃºng tÃ´i huáº¥n luyá»‡n ba biáº¿n thá»ƒ khÃ¡c nhau trong giai Ä‘oáº¡n phÃ¢n rÃ£ (táº­p trung vÃ o tiáº¿ng Anh, 110 ngÃ´n ngá»¯ vÃ  táº¥t cáº£ ngÃ´n ngá»¯) vÃ  sá»­ dá»¥ng há»£p nháº¥t TIES Ä‘á»ƒ káº¿t há»£p cÃ¡c Ä‘iá»ƒm máº¡nh cá»§a chÃºng vÃ o mÃ´ hÃ¬nh cuá»‘i cÃ¹ng.</p>
<h2 id="káº¿t-quáº£">Káº¿t quáº£</h2>
<h3 id="hiá»ƒu-ngÃ´n-ngá»¯-tá»±-nhiÃªn-nlu">Hiá»ƒu NgÃ´n ngá»¯ Tá»± nhiÃªn (NLU)</h3>
<!-- raw HTML omitted -->
<p><strong>Hiá»‡u suáº¥t Tiáº¿ng Anh</strong>: TrÃªn Ä‘iá»ƒm chuáº©n GLUE tiáº¿ng Anh (Báº£ng 1), mmBERT base Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t máº¡nh máº½, vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘a ngÃ´n ngá»¯ khÃ¡c nhÆ° XLM-R (Ä‘a ngÃ´n ngá»¯ RoBERTa) base vÃ  mGTE base, Ä‘á»“ng thá»i váº«n cáº¡nh tranh vá»›i cÃ¡c mÃ´ hÃ¬nh chá»‰ báº±ng tiáº¿ng Anh máº·c dÃ¹ Ã­t hÆ¡n 25% dá»¯ liá»‡u huáº¥n luyá»‡n mmBERT lÃ  tiáº¿ng Anh.</p>
<!-- raw HTML omitted -->
<p><strong>Hiá»‡u suáº¥t Äa ngÃ´n ngá»¯</strong>: mmBERT cho tháº¥y nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trÃªn Ä‘iá»ƒm chuáº©n XTREME so vá»›i XLM-R nhÆ° Ä‘Æ°á»£c chá»©ng minh trong Báº£ng 2. Nhá»¯ng lá»£i Ã­ch Ä‘Ã¡ng chÃº Ã½ bao gá»“m hiá»‡u suáº¥t máº¡nh máº½ trÃªn phÃ¢n loáº¡i XNLI, nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong cÃ¡c nhiá»‡m vá»¥ tráº£ lá»i cÃ¢u há»i nhÆ° TyDiQA vÃ  káº¿t quáº£ cáº¡nh tranh trÃªn PAWS-X vÃ  XCOPA Ä‘á»ƒ hiá»ƒu Ä‘a ngÃ´n ngá»¯.</p>
<p>MÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t trÃªn háº§u háº¿t cÃ¡c danh má»¥c, ngoáº¡i trá»« má»™t sá»‘ nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n cÃ³ cáº¥u trÃºc nhÆ° NER vÃ  gáº¯n tháº» POS, cÃ³ thá»ƒ lÃ  do sá»± khÃ¡c biá»‡t vá» bá»™ mÃ£ hÃ³a thÃ´ng bÃ¡o áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c phÃ¡t hiá»‡n ranh giá»›i tá»«. TrÃªn cÃ¡c danh má»¥c nÃ y, nÃ³ hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± nhÆ° tháº¿ há»‡ trÆ°á»›c, nhÆ°ng cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho nhiá»u ngÃ´n ngá»¯ hÆ¡n.</p>
<h3 id="hiá»‡u-suáº¥t-truy-xuáº¥t">Hiá»‡u suáº¥t truy xuáº¥t</h3>
<!-- raw HTML omitted -->
<p><strong>Truy xuáº¥t Tiáº¿ng Anh</strong>: Máº·c dÃ¹ mmBERT Ä‘Æ°á»£c thiáº¿t káº¿ cho cÃ¡c cÃ i Ä‘áº·t Ä‘a ngÃ´n ngá»¯ lá»›n, nhÆ°ng trong Ä‘iá»ƒm chuáº©n MTEB v2 tiáº¿ng Anh (Báº£ng 3), mmBERT cho tháº¥y nhá»¯ng lá»£i Ã­ch Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘a ngÃ´n ngá»¯ trÆ°á»›c Ä‘Ã¢y vÃ  tháº­m chÃ­ ngang báº±ng vá»›i kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh chá»‰ báº±ng tiáº¿ng Anh nhÆ° ModernBERT!</p>
<!-- raw HTML omitted -->
<p><strong>Truy xuáº¥t Äa ngÃ´n ngá»¯</strong>: mmBERT cho tháº¥y nhá»¯ng cáº£i thiá»‡n nháº¥t quÃ¡n trÃªn Ä‘iá»ƒm chuáº©n MTEB v2 Ä‘a ngÃ´n ngá»¯ so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c (Báº£ng 4).</p>
<!-- raw HTML omitted -->
<p><strong>Truy xuáº¥t MÃ£</strong>: Do bá»™ mÃ£ hÃ³a thÃ´ng bÃ¡o hiá»‡n Ä‘áº¡i (dá»±a trÃªn Gemma 2), mmBERT cÅ©ng cho tháº¥y hiá»‡u suáº¥t mÃ£ hÃ³a máº¡nh máº½ (Báº£ng 5), khiáº¿n mmBERT phÃ¹ há»£p vá»›i báº¥t ká»³ loáº¡i dá»¯ liá»‡u vÄƒn báº£n nÃ o. MÃ´ hÃ¬nh duy nháº¥t hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n nÃ³ lÃ  EuroBERT, cÃ³ thá»ƒ sá»­ dá»¥ng táº­p dá»¯ liá»‡u Stack v2 khÃ´ng thá»ƒ truy cáº­p cÃ´ng khai.</p>
<h2 id="há»c-ngÃ´n-ngá»¯-trong-giai-Ä‘oáº¡n-phÃ¢n-rÃ£">Há»c ngÃ´n ngá»¯ trong giai Ä‘oáº¡n phÃ¢n rÃ£</h2>
<p>Má»™t trong nhá»¯ng tÃ­nh nÄƒng má»›i quan trá»ng nháº¥t cá»§a mmBERT lÃ  chá»©ng minh ráº±ng cÃ¡c ngÃ´n ngá»¯ Ã­t tÃ i nguyÃªn cÃ³ thá»ƒ Ä‘Æ°á»£c há»c hiá»‡u quáº£ trong giai Ä‘oáº¡n phÃ¢n rÃ£ ngáº¯n cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n. ChÃºng tÃ´i Ä‘Ã£ xÃ¡c nháº­n phÆ°Æ¡ng phÃ¡p nÃ y báº±ng cÃ¡ch kiá»ƒm tra trÃªn cÃ¡c ngÃ´n ngá»¯ chá»‰ Ä‘Æ°á»£c giá»›i thiá»‡u trong giai Ä‘oáº¡n phÃ¢n rÃ£ 100B token cuá»‘i cÃ¹ng.</p>
<!-- raw HTML omitted -->
<p><strong>Lá»£i Ã­ch Hiá»‡u suáº¥t ÄÃ¡ng ká»ƒ</strong>: Kiá»ƒm tra trÃªn TiQuaD (Tigrinya) vÃ  FoQA (Faroese), chÃºng tÃ´i quan sÃ¡t tháº¥y nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ khi cÃ¡c ngÃ´n ngá»¯ nÃ y Ä‘Æ°á»£c bao gá»“m trong giai Ä‘oáº¡n phÃ¢n rÃ£, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2. Káº¿t quáº£ chá»©ng minh tÃ­nh hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p há»c ngÃ´n ngá»¯ lÅ©y tiáº¿n cá»§a chÃºng tÃ´i.</p>
<p><strong>Cáº¡nh tranh vá»›i cÃ¡c MÃ´ hÃ¬nh Lá»›n</strong>: Máº·c dÃ¹ chá»‰ nhÃ¬n tháº¥y cÃ¡c ngÃ´n ngá»¯ nÃ y trong giai Ä‘oáº¡n huáº¥n luyá»‡n cuá»‘i cÃ¹ng, mmBERT Ä‘áº¡t Ä‘Æ°á»£c má»©c hiá»‡u suáº¥t vÆ°á»£t quÃ¡ cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n nhiá»u. Vá» cÃ¢u tráº£ lá»i cÃ¢u há»i Faroese, nÆ¡i LLM Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡, mmBERT hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n Google Gemini 2.5 Pro vÃ  OpenAI o3.</p>
<p><strong>CÆ¡ cháº¿ Há»c Táº­p Nhanh chÃ³ng</strong>: Sá»± thÃ nh cÃ´ng cá»§a viá»‡c há»c ngÃ´n ngá»¯ trong giai Ä‘oáº¡n phÃ¢n rÃ£ xuáº¥t phÃ¡t tá»« kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh táº­n dá»¥ng ná»n táº£ng Ä‘a ngÃ´n ngá»¯ máº¡nh máº½ cá»§a nÃ³ Ä‘Æ°á»£c xÃ¢y dá»±ng trong cÃ¡c giai Ä‘oáº¡n trÆ°á»›c Ä‘Ã³. Khi tiáº¿p xÃºc vá»›i cÃ¡c ngÃ´n ngá»¯ má»›i, mÃ´ hÃ¬nh cÃ³ thá»ƒ nhanh chÃ³ng Ä‘iá»u chá»‰nh cÃ¡c biá»ƒu diá»…n Ä‘a ngÃ´n ngá»¯ hiá»‡n cÃ³ thay vÃ¬ há»c tá»« Ä‘áº§u.</p>
<p><strong>Lá»£i Ã­ch Há»£p nháº¥t MÃ´ hÃ¬nh</strong>: CÃ¡c mÃ´ hÃ¬nh mmBERT cuá»‘i cÃ¹ng giá»¯ láº¡i thÃ nh cÃ´ng háº§u háº¿t cÃ¡c cáº£i tiáº¿n trong giai Ä‘oáº¡n phÃ¢n rÃ£ trong khi Ä‘Æ°á»£c hÆ°á»Ÿng lá»£i tá»« cÃ¡c biáº¿n thá»ƒ táº­p trung vÃ o tiáº¿ng Anh vÃ  tÃ i nguyÃªn cao thÃ´ng qua há»£p nháº¥t TIES.</p>
<h2 id="cáº£i-thiá»‡n-hiá»‡u-quáº£">Cáº£i thiá»‡n hiá»‡u quáº£</h2>
<p>mmBERT mang láº¡i nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» hiá»‡u quáº£ so vá»›i cÃ¡c mÃ´ hÃ¬nh mÃ£ hÃ³a Ä‘a ngÃ´n ngá»¯ trÆ°á»›c Ä‘Ã³ thÃ´ng qua nhá»¯ng cáº£i tiáº¿n kiáº¿n trÃºc Ä‘Æ°á»£c káº¿ thá»«a tá»« ModernBERT:</p>
<!-- raw HTML omitted -->
<p><strong>Hiá»‡u suáº¥t ThÃ´ng lÆ°á»£ng</strong>: mmBERT xá»­ lÃ½ vÄƒn báº£n nhanh hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘a ngÃ´n ngá»¯ hiá»‡n cÃ³ trÃªn cÃ¡c Ä‘á»™ dÃ i chuá»—i khÃ¡c nhau, nhÆ° Ä‘Æ°á»£c chá»©ng minh trong HÃ¬nh 3. Cáº£ mÃ´ hÃ¬nh nhá» vÃ  mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘á»u cho tháº¥y nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» tá»‘c Ä‘á»™ so vá»›i bá»™ mÃ£ hÃ³a Ä‘a ngÃ´n ngá»¯ trÆ°á»›c Ä‘Ã¢y.</p>
<p><strong>Lá»£i Ã­ch cá»§a Kiáº¿n trÃºc Hiá»‡n Ä‘áº¡i</strong>: CÃ¡c lá»£i Ã­ch vá» hiá»‡u quáº£ Ä‘áº¿n tá»« hai cáº£i tiáº¿n ká»¹ thuáº­t chÃ­nh:</p>
<ul>
<li><strong>Flash Attention 2</strong>: TÃ­nh toÃ¡n chÃº Ã½ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘á»ƒ sá»­ dá»¥ng bá»™ nhá»› vÃ  tá»‘c Ä‘á»™ tá»‘t hÆ¡n</li>
<li><strong>Ká»¹ thuáº­t bá» Ä‘á»‡m</strong>: Loáº¡i bá» cÃ¡c mÃ£ thÃ´ng bÃ¡o Ä‘á»‡m khÃ´ng cáº§n thiáº¿t trong quÃ¡ trÃ¬nh xá»­ lÃ½</li>
</ul>
<p><strong>Tá»· lá»‡ Äá»™ dÃ i Chuá»—i</strong>: KhÃ´ng giá»‘ng nhÆ° cÃ¡c mÃ´ hÃ¬nh cÅ© hÆ¡n giá»›i háº¡n á»Ÿ 512 token, mmBERT xá»­ lÃ½ hiá»‡u quáº£ tá»›i 8.192 token trong khi váº«n duy trÃ¬ thÃ´ng lÆ°á»£ng cao. Äiá»u nÃ y lÃ m cho nÃ³ phÃ¹ há»£p vá»›i cÃ¡c tÃ¡c vá»¥ xá»­ lÃ½ tÃ i liá»‡u dÃ i hÆ¡n ngÃ y cÃ ng phá»• biáº¿n trong cÃ¡c á»©ng dá»¥ng Ä‘a ngÃ´n ngá»¯.</p>
<p><strong>Hiá»‡u quáº£ NÄƒng lÆ°á»£ng</strong>: Sá»± káº¿t há»£p giá»¯a thÃ´ng lÆ°á»£ng tá»‘t hÆ¡n vÃ  kiáº¿n trÃºc hiá»‡n Ä‘áº¡i dáº«n Ä‘áº¿n chi phÃ­ tÃ­nh toÃ¡n tháº¥p hÆ¡n cho suy luáº­n, lÃ m cho mmBERT thiáº¿t thá»±c hÆ¡n cho cÃ¡c triá»ƒn khai sáº£n xuáº¥t nÆ¡i cáº§n há»— trá»£ Ä‘a ngÃ´n ngá»¯ á»Ÿ quy mÃ´ lá»›n.</p>
<p>Nhá»¯ng cáº£i thiá»‡n vá» hiá»‡u quáº£ nÃ y lÃ m cho mmBERT khÃ´ng chá»‰ chÃ­nh xÃ¡c hÆ¡n bá»™ mÃ£ hÃ³a Ä‘a ngÃ´n ngá»¯ trÆ°á»›c Ä‘Ã¢y, mÃ  cÃ²n thiáº¿t thá»±c hÆ¡n Ä‘Ã¡ng ká»ƒ cho viá»‡c sá»­ dá»¥ng thá»±c táº¿.</p>
<h2 id="vÃ­-dá»¥-sá»­-dá»¥ng">VÃ­ dá»¥ sá»­ dá»¥ng</h2>
<p>Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh nÃ y chá»‰ vá»›i má»™t vÃ i dÃ²ng mÃ£!</p>
<p>python
from transformers import AutoTokenizer, AutoModelForMaskedLM
import torch</p>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;jhu-clsp/mmBERT-base&rdquo;)
model = AutoModelForMaskedLM.from_pretrained(&ldquo;jhu-clsp/mmBERT-base&rdquo;)</p>
<p>def predict_masked_token(text):
inputs = tokenizer(text, return_tensors=&ldquo;pt&rdquo;)
with torch.no_grad():
outputs = model(**inputs)
mask_indices = torch.where(inputs[&ldquo;input_ids&rdquo;] == tokenizer.mask_token_id)
predictions = outputs.logits[mask_indices]
top_tokens, top_indices = torch.topk(predictions, 5, dim=-1)
return [tokenizer.decode(token) for token in top_indices[0]]</p>
<h1 id="hoáº¡t-Ä‘á»™ng-trÃªn-cÃ¡c-ngÃ´n-ngá»¯">Hoáº¡t Ä‘á»™ng trÃªn cÃ¡c ngÃ´n ngá»¯</h1>
<p>texts = [
&ldquo;The capital of France is <!-- raw HTML omitted -->.&rdquo;,
&ldquo;La capital de EspaÃ±a es <!-- raw HTML omitted -->.&rdquo;,
&ldquo;Die Hauptstadt von Deutschland ist <!-- raw HTML omitted -->.&rdquo;,
]</p>
<p>for text in texts:
predictions = predict_masked_token(text)
print(f&quot;Text: {text}&quot;)
print(f&quot;Predictions: {predictions}\n&quot;)</p>
<h2 id="vÃ­-dá»¥-tinh-chá»‰nh">VÃ­ dá»¥ tinh chá»‰nh</h2>
<h3 id="bá»™-mÃ£-hÃ³a">Bá»™ mÃ£ hÃ³a</h3>
<!-- raw HTML omitted -->
<p>python
import argparse</p>
<p>from datasets import load_dataset
from sentence_transformers import (
SentenceTransformer,
SentenceTransformerTrainer,
SentenceTransformerTrainingArguments,
)
from sentence_transformers.evaluation import TripletEvaluator
from sentence_transformers.losses import CachedMultipleNegativesRankingLoss
from sentence_transformers.training_args import BatchSamplers</p>
<p>def main():
# phÃ¢n tÃ­ch cÃº phÃ¡p lr &amp; tÃªn mÃ´ hÃ¬nh
parser = argparse.ArgumentParser()
parser.add_argument(&quot;&ndash;lr&quot;, type=float, default=8e-5)
parser.add_argument(&quot;&ndash;model_name&quot;, type=str, default=&ldquo;jhu-clsp/mmBERT-small&rdquo;)
args = parser.parse_args()
lr = args.lr
model_name = args.model_name
model_shortname = model_name.split(&quot;/&quot;)[-1]</p>
<pre><code># 1. Táº£i má»™t mÃ´ hÃ¬nh Ä‘á»ƒ tinh chá»‰nh
model = SentenceTransformer(model_name)

# 2. Táº£i má»™t táº­p dá»¯ liá»‡u Ä‘á»ƒ tinh chá»‰nh trÃªn
dataset = load_dataset(
    &quot;sentence-transformers/msmarco-co-condenser-margin-mse-sym-mnrl-mean-v1&quot;,
    &quot;triplet-hard&quot;,
    split=&quot;train&quot;,
)
dataset_dict = dataset.train_test_split(test_size=1_000, seed=12)
train_dataset = dataset_dict[&quot;train&quot;].select(range(1_250_000))
eval_dataset = dataset_dict[&quot;test&quot;]

# 3. XÃ¡c Ä‘á»‹nh má»™t hÃ m máº¥t mÃ¡t
loss = CachedMultipleNegativesRankingLoss(model, mini_batch_size=16)  # TÄƒng mini_batch_size náº¿u báº¡n cÃ³ Ä‘á»§ VRAM

run_name = f&quot;{model_shortname}-DPR-{lr}&quot;
# 4. (TÃ¹y chá»n) Chá»‰ Ä‘á»‹nh cÃ¡c Ä‘á»‘i sá»‘ huáº¥n luyá»‡n
args = SentenceTransformerTrainingArguments(
    # Tham sá»‘ báº¯t buá»™c:
    output_dir=f&quot;output/{model_shortname}/{run_name}&quot;,
    # CÃ¡c tham sá»‘ huáº¥n luyá»‡n tÃ¹y chá»n:
    num_train_epochs=1,
    per_device_train_batch_size=512,
    per_device_eval_batch_size=512,
    warmup_ratio=0.05,
    fp16=False,  # Äáº·t thÃ nh False náº¿u GPU khÃ´ng thá»ƒ xá»­ lÃ½ FP16
    bf16=True,  # Äáº·t thÃ nh True náº¿u GPU há»— trá»£ BF16
    batch_sampler=BatchSamplers.NO_DUPLICATES,  # (Cached) MultipleNegativesRankingLoss hÆ°á»Ÿng lá»£i tá»« viá»‡c khÃ´ng cÃ³ báº£n sao
    learning_rate=lr,
    # CÃ¡c tham sá»‘ theo dÃµi/gá»¡ lá»—i tÃ¹y chá»n:
    save_strategy=&quot;steps&quot;,
    save_steps=500,
    save_total_limit=2,
    logging_steps=500,
    run_name=run_name,  # ÄÆ°á»£c sá»­ dá»¥ng trong `wandb`, `tensorboard`, `neptune`, v.v. náº¿u Ä‘Æ°á»£c cÃ i Ä‘áº·t
)

# 5. (TÃ¹y chá»n) Táº¡o má»™t trÃ¬nh Ä‘Ã¡nh giÃ¡ &amp; Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cÆ¡ sá»Ÿ
dev_evaluator = TripletEvaluator(
    anchors=eval_dataset[&quot;query&quot;],
    positives=eval_dataset[&quot;positive&quot;],
    negatives=eval_dataset[&quot;negative&quot;],
    name=&quot;msmarco-co-condenser-dev&quot;,
)
dev_evaluator(model)

# 6. Táº¡o má»™t trÃ¬nh huáº¥n luyá»‡n &amp; huáº¥n luyá»‡n
trainer = SentenceTransformerTrainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    loss=loss,
    evaluator=dev_evaluator,
)
trainer.train()

# 7. (TÃ¹y chá»n) ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn trÃ¬nh Ä‘Ã¡nh giÃ¡ sau khi huáº¥n luyá»‡n
dev_evaluator(model)

# 8. LÆ°u mÃ´ hÃ¬nh
model.save_pretrained(f&quot;output/{model_shortname}/{run_name}/final&quot;)

# 9. (TÃ¹y chá»n) Äáº©y nÃ³ lÃªn Hugging Face Hub
model.push_to_hub(run_name, private=False)
</code></pre>
<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:
main()</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>python
from datasets import load_dataset
from pylate import losses, models, utils
from sentence_transformers import (
SentenceTransformerTrainer,
SentenceTransformerTrainingArguments,
)</p>
<p>def main():
# Táº£i cÃ¡c táº­p dá»¯ liá»‡u cáº§n thiáº¿t cho chÆ°ng cáº¥t kiáº¿n thá»©c (huáº¥n luyá»‡n, truy váº¥n, tÃ i liá»‡u)
train = load_dataset(
path=&ldquo;lightonai/ms-marco-en-bge&rdquo;,
name=&ldquo;train&rdquo;,
)</p>
<pre><code>queries = load_dataset(
    path=&quot;lightonai/ms-marco-en-bge&quot;,
    name=&quot;queries&quot;,
)

documents = load_dataset(
    path=&quot;lightonai/ms-marco-en-bge&quot;,
    name=&quot;documents&quot;,
)

# Äáº·t biáº¿n Ä‘á»•i Ä‘á»ƒ táº£i cÃ¡c vÄƒn báº£n tÃ i liá»‡u/truy váº¥n báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c id tÆ°Æ¡ng á»©ng má»™t cÃ¡ch nhanh chÃ³ng
train.set_transform(
    utils.KDProcessing(queries=queries, documents=documents).transform,
)

# XÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, cÃ¡c tham sá»‘ huáº¥n luyá»‡n vÃ  thÆ° má»¥c Ä‘áº§u ra
num_train_epochs = 1
lr = 8e-5
batch_size = 16
accum_steps = 1
model_name = &quot;jhu-clsp/mmBERT-small&quot;
model_shortname = model_name.split(&quot;/&quot;)[-1]

# Äáº·t tÃªn cháº¡y cho má»¥c Ä‘Ã­ch ghi nháº­t kÃ½ vÃ  thÆ° má»¥c Ä‘áº§u ra
run_name = f&quot;{model_shortname}-colbert-KD-{lr}&quot;
output_dir = f&quot;output/{model_shortname}/{run_name}&quot;

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh ColBERT tá»« mÃ´ hÃ¬nh cÆ¡ sá»Ÿ
model = models.ColBERT(model_name_or_path=model_name)

# Äá»‹nh cáº¥u hÃ¬nh cÃ¡c Ä‘á»‘i sá»‘ huáº¥n luyá»‡n (vÃ­ dá»¥: sá»‘ epoch, kÃ­ch thÆ°á»›c lÃ´, tá»‘c Ä‘á»™ há»c)
args = SentenceTransformerTrainingArguments(
    output_dir=output_dir,
    num_train_epochs=num_train_epochs,
    per_device_train_batch_size=batch_size,
    fp16=False,  # Äáº·t thÃ nh False náº¿u báº¡n gáº·p lá»—i ráº±ng GPU cá»§a báº¡n khÃ´ng thá»ƒ cháº¡y trÃªn FP16
    bf16=True,  # Äáº·t thÃ nh True náº¿u báº¡n cÃ³ GPU há»— trá»£ BF16
    run_name=run_name,
    logging_steps=10,
    learning_rate=lr,
    gradient_accumulation_steps=accum_steps,
    warmup_ratio=0.05,
)

# Sá»­ dá»¥ng hÃ m máº¥t mÃ¡t ChÆ°ng cáº¥t cho huáº¥n luyá»‡n
train_loss = losses.Distillation(model=model)

# Khá»Ÿi táº¡o trÃ¬nh huáº¥n luyá»‡n
trainer = SentenceTransformerTrainer(
    model=model,
    args=args,
    train_dataset=train,
    loss=train_loss,
    data_collator=utils.ColBERTCollator(tokenize_fn=model.tokenize),
)

# Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh huáº¥n luyá»‡n
trainer.train()

model.save_pretrained(f&quot;{output_dir}/final&quot;)
</code></pre>
<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:
main()</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>python
import logging</p>
<p>from datasets import load_dataset</p>
<p>from sentence_transformers import (
SparseEncoder,
SparseEncoderModelCardData,
SparseEncoderTrainer,
SparseEncoderTrainingArguments,
)
from sentence_transformers.sparse_encoder.evaluation import SparseNanoBEIREvaluator
from sentence_transformers.sparse_encoder.losses import SparseMultipleNegativesRankingLoss, SpladeLoss
from sentence_transformers.training_args import BatchSamplers</p>
<p>logging.basicConfig(format=&quot;%(asctime)s - %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot;, level=logging.INFO)</p>
<h1 id="1-táº£i-má»™t-mÃ´-hÃ¬nh-Ä‘á»ƒ-tinh-chá»‰nh-vá»›i-2-tÃ¹y-chá»n-dá»¯-liá»‡u-tháº»-mÃ´-hÃ¬nh">1. Táº£i má»™t mÃ´ hÃ¬nh Ä‘á»ƒ tinh chá»‰nh vá»›i 2. (TÃ¹y chá»n) dá»¯ liá»‡u tháº» mÃ´ hÃ¬nh</h1>
<p>model = SparseEncoder(
&ldquo;jhu-clsp/mmBERT-small&rdquo;,
model_card_data=SparseEncoderModelCardData(
language=&ldquo;en&rdquo;,
license=&ldquo;apache-2.0&rdquo;,
)
)</p>
<h1 id="3-táº£i-má»™t-táº­p-dá»¯-liá»‡u-Ä‘á»ƒ-tinh-chá»‰nh-trÃªn">3. Táº£i má»™t táº­p dá»¯ liá»‡u Ä‘á»ƒ tinh chá»‰nh trÃªn</h1>
<p>full_dataset = load_dataset(&ldquo;sentence-transformers/natural-questions&rdquo;, split=&ldquo;train&rdquo;).select(range(100_000))
dataset_dict = full_dataset.train_test_split(test_size=1_000, seed=12)
train_dataset = dataset_dict[&ldquo;train&rdquo;]
eval_dataset = dataset_dict[&ldquo;test&rdquo;]</p>
<h1 id="4-xÃ¡c-Ä‘á»‹nh-má»™t-hÃ m-máº¥t-mÃ¡t">4. XÃ¡c Ä‘á»‹nh má»™t hÃ m máº¥t mÃ¡t</h1>
<p>loss = SpladeLoss(
model=model,
loss=SparseMultipleNegativesRankingLoss(model=model),
query_regularizer_weight=5e-5,
document_regularizer_weight=3e-5,
)</p>
<h1 id="5-tÃ¹y-chá»n-chá»‰-Ä‘á»‹nh-cÃ¡c-Ä‘á»‘i-sá»‘-huáº¥n-luyá»‡n">5. (TÃ¹y chá»n) Chá»‰ Ä‘á»‹nh cÃ¡c Ä‘á»‘i sá»‘ huáº¥n luyá»‡n</h1>
<p>run_name = &ldquo;splade-distilbert-base-uncased-nq&rdquo;
args = SparseEncoderTrainingArguments(
# Tham sá»‘ báº¯t buá»™c:
output_dir=f&quot;models/{run_name}&quot;,
# CÃ¡c tham sá»‘ huáº¥n luyá»‡n tÃ¹y chá»n:
num_train_epochs=1,
per_device_train_batch_size=16,
per_device_eval_batch_size=16,
learning_rate=2e-5,
warmup_ratio=0.1,
fp16=True,  # Äáº·t thÃ nh False náº¿u báº¡n gáº·p lá»—i ráº±ng GPU cá»§a báº¡n khÃ´ng thá»ƒ cháº¡y trÃªn FP16
bf16=False,  # Äáº·t thÃ nh True náº¿u báº¡n cÃ³ GPU há»— trá»£ BF16
batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss hÆ°á»Ÿng lá»£i tá»« viá»‡c khÃ´ng cÃ³ cÃ¡c máº«u trÃ¹ng láº·p trong má»™t lÃ´
# CÃ¡c tham sá»‘ theo dÃµi/gá»¡ lá»—i tÃ¹y chá»n:
eval_strategy=&ldquo;steps&rdquo;,
eval_steps=1000,
save_strategy=&ldquo;steps&rdquo;,
save_steps=1000,
save_total_limit=2,
logging_steps=200,
run_name=run_name,  # Sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng trong W&amp;B náº¿u <code>wandb</code> Ä‘Æ°á»£c cÃ i Ä‘áº·t
)</p>
<h1 id="6-tÃ¹y-chá»n-táº¡o-má»™t-trÃ¬nh-Ä‘Ã¡nh-giÃ¡--Ä‘Ã¡nh-giÃ¡-mÃ´-hÃ¬nh-cÆ¡-sá»Ÿ">6. (TÃ¹y chá»n) Táº¡o má»™t trÃ¬nh Ä‘Ã¡nh giÃ¡ &amp; Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cÆ¡ sá»Ÿ</h1>
<p>dev_evaluator = SparseNanoBEIREvaluator(dataset_names=[&ldquo;msmarco&rdquo;, &ldquo;nfcorpus&rdquo;, &ldquo;nq&rdquo;], batch_size=16)</p>
<h1 id="7-táº¡o-má»™t-trÃ¬nh-huáº¥n-luyá»‡n--huáº¥n-luyá»‡n">7. Táº¡o má»™t trÃ¬nh huáº¥n luyá»‡n &amp; huáº¥n luyá»‡n</h1>
<p>trainer = SparseEncoderTrainer(
model=model,
args=args,
train_dataset=train_dataset,
eval_dataset=eval_dataset,
loss=loss,
evaluator=dev_evaluator,
)
trainer.train()</p>
<h1 id="8-Ä‘Ã¡nh-giÃ¡-láº¡i-hiá»‡u-suáº¥t-mÃ´-hÃ¬nh-sau-khi-huáº¥n-luyá»‡n">8. ÄÃ¡nh giÃ¡ láº¡i hiá»‡u suáº¥t mÃ´ hÃ¬nh sau khi huáº¥n luyá»‡n</h1>
<p>dev_evaluator(model)</p>
<h1 id="9-lÆ°u-mÃ´-hÃ¬nh-Ä‘Ã£-huáº¥n-luyá»‡n">9. LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n</h1>
<p>model.save_pretrained(f&quot;models/{run_name}/final&quot;)</p>
<h1 id="10-tÃ¹y-chá»n-Ä‘áº©y-nÃ³-lÃªn-hugging-face-hub">10. (TÃ¹y chá»n) Äáº©y nÃ³ lÃªn Hugging Face Hub</h1>
<p>model.push_to_hub(run_name)</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>python
import logging
import traceback</p>
<p>import torch
from datasets import load_dataset</p>
<p>from sentence_transformers import SentenceTransformer
from sentence_transformers.cross_encoder import (
CrossEncoder,
CrossEncoderModelCardData,
CrossEncoderTrainer,
CrossEncoderTrainingArguments,
)
from sentence_transformers.cross_encoder.evaluation import (
CrossEncoderNanoBEIREvaluator,
CrossEncoderRerankingEvaluator,
)
from sentence_transformers.cross_encoder.losses import BinaryCrossEntropyLoss
from sentence_transformers.evaluation import SequentialEvaluator
from sentence_transformers.util import mine_hard_negatives</p>
<h1 id="Ä‘áº·t-má»©c-ghi-nháº­t-kÃ½-thÃ nh-info-Ä‘á»ƒ-cÃ³-thÃªm-thÃ´ng-tin">Äáº·t má»©c ghi nháº­t kÃ½ thÃ nh INFO Ä‘á»ƒ cÃ³ thÃªm thÃ´ng tin</h1>
<p>logging.basicConfig(format=&quot;%(asctime)s - %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot;, level=logging.INFO)</p>
<p>def main():
model_name = &ldquo;jhu-clsp/mmBERT-small&rdquo;</p>
<pre><code>train_batch_size = 64
num_epochs = 1
num_hard_negatives = 5  # CÃ³ bao nhiÃªu sá»‘ Ã¢m khÃ³ nÃªn Ä‘Æ°á»£c khai thÃ¡c cho má»—i cáº·p cÃ¢u há»i-tráº£ lá»i

# 1a. Táº£i má»™t mÃ´ hÃ¬nh Ä‘á»ƒ tinh chá»‰nh vá»›i 1b. (TÃ¹y chá»n) dá»¯ liá»‡u tháº» mÃ´ hÃ¬nh
model = CrossEncoder(
    model_name,
    model_card_data=CrossEncoderModelCardData(
        language=&quot;en&quot;,
        license=&quot;apache-2.0&quot;,
    ),
)
print(&quot;Model max length:&quot;, model.max_length)
print(&quot;Model num labels:&quot;, model.num_labels)

# 2a. Táº£i táº­p dá»¯ liá»‡u GooAQ: https://huggingface.co/datasets/sentence-transformers/gooaq
logging.info(&quot;Äá»c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n gooaq&quot;)
full_dataset = load_dataset(&quot;sentence-transformers/gooaq&quot;, split=&quot;train&quot;).select(range(100_000))
dataset_dict = full_dataset.train_test_split(test_size=1_000, seed=12)
train_dataset = dataset_dict[&quot;train&quot;]
eval_dataset = dataset_dict[&quot;test&quot;]
logging.info(train_dataset)
logging.info(eval_dataset)

# 2b. Sá»­a Ä‘á»•i táº­p dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a chÃºng tÃ´i Ä‘á»ƒ bao gá»“m cÃ¡c sá»‘ Ã¢m khÃ³ báº±ng cÃ¡ch sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh nhÃºng ráº¥t hiá»‡u quáº£
embedding_model = SentenceTransformer(&quot;sentence-transformers/static-retrieval-mrl-en-v1&quot;, device=&quot;cpu&quot;)
hard_train_dataset = mine_hard_negatives(
    train_dataset,
    embedding_model,
    num_negatives=num_hard_negatives,  # CÃ³ bao nhiÃªu sá»‘ Ã¢m trÃªn má»—i cáº·p cÃ¢u há»i-tráº£ lá»i
    margin=0,  # Má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a truy váº¥n vÃ  cÃ¡c máº«u Ã¢m nÃªn tháº¥p hÆ¡n x so vá»›i má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a truy váº¥n-dÆ°Æ¡ng
    range_min=0,  # Bá» qua x máº«u tÆ°Æ¡ng tá»± nháº¥t
    range_max=100,  # Chá»‰ xem xÃ©t x máº«u tÆ°Æ¡ng tá»± nháº¥t
    sampling_strategy=&quot;top&quot;,  # Láº¥y máº«u cÃ¡c sá»‘ Ã¢m hÃ ng Ä‘áº§u tá»« pháº¡m vi
    batch_size=4096,  # Sá»­ dá»¥ng kÃ­ch thÆ°á»›c lÃ´ lÃ  4096 cho mÃ´ hÃ¬nh nhÃºng
    output_format=&quot;labeled-pair&quot;,  # Äá»‹nh dáº¡ng Ä‘áº§u ra lÃ  (truy váº¥n, Ä‘oáº¡n vÄƒn, nhÃ£n), nhÆ° Ä‘Æ°á»£c yÃªu cáº§u bá»Ÿi BinaryCrossEntropyLoss
    use_faiss=True,
)
logging.info(hard_train_dataset)

# 2c. (TÃ¹y chá»n) LÆ°u táº­p dá»¯ liá»‡u huáº¥n luyá»‡n khÃ³ vÃ o Ä‘Ä©a
# hard_train_dataset.save_to_disk(&quot;gooaq-hard-train&quot;)
# Táº£i láº¡i vá»›i:
# hard_train_dataset = load_from_disk(&quot;gooaq-hard-train&quot;)

# 3. XÃ¡c Ä‘á»‹nh hÃ m máº¥t mÃ¡t huáº¥n luyá»‡n cá»§a chÃºng tÃ´i.
# pos_weight Ä‘Æ°á»£c khuyáº¿n nghá»‹ Ä‘áº·t lÃ m tá»· lá»‡ giá»¯a dÆ°Æ¡ng tÃ­nh vÃ  Ã¢m tÃ­nh, hay cÃ²n gá»i lÃ  `num_hard_negatives`
loss = BinaryCrossEntropyLoss(model=model, pos_weight=torch.tensor(num_hard_negatives))

# 4a. XÃ¡c Ä‘á»‹nh trÃ¬nh Ä‘Ã¡nh giÃ¡. ChÃºng tÃ´i sá»­ dá»¥ng CrossEncoderNanoBEIREvaluator, Ä‘Ã¢y lÃ  má»™t trÃ¬nh Ä‘Ã¡nh giÃ¡ nháº¹ cho viá»‡c xáº¿p háº¡ng láº¡i tiáº¿ng Anh
nano_beir_evaluator = CrossEncoderNanoBEIREvaluator(
    dataset_names=[&quot;msmarco&quot;, &quot;nfcorpus&quot;, &quot;nq&quot;],
    batch_size=train_batch_size,
)

# 4b. XÃ¡c Ä‘á»‹nh má»™t trÃ¬nh Ä‘Ã¡nh giÃ¡ xáº¿p háº¡ng láº¡i báº±ng cÃ¡ch khai thÃ¡c cÃ¡c sá»‘ Ã¢m khÃ³ cho cÃ¡c cáº·p cÃ¢u há»i-tráº£ lá»i
# ChÃºng tÃ´i bao gá»“m cÃ¢u tráº£ lá»i dÆ°Æ¡ng tÃ­nh trong danh sÃ¡ch cÃ¡c sá»‘ Ã¢m, vÃ¬ váº­y trÃ¬nh Ä‘Ã¡nh giÃ¡ cÃ³ thá»ƒ sá»­ dá»¥ng hiá»‡u suáº¥t cá»§a
# mÃ´ hÃ¬nh nhÃºng lÃ m Ä‘Æ°á»ng cÆ¡ sá»Ÿ.
hard_eval
</code></pre>
<h3 id="link-bÃ i-viáº¿t-gá»‘c"><a href="https://huggingface.co/blog/mmbert">Link bÃ i viáº¿t gá»‘c</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/september-9-2025/">September 9, 2025</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-27/9008f5/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/embeddinggemma/thumbnail.png" alt="ChÃ o má»«ng EmbeddingGemma, mÃ´ hÃ¬nh nhÃºng hiá»‡u quáº£ má»›i cá»§a Google" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-09-27T00:00:00&#43;00:00">Sep 27, 2025</time>

		<h3 class="my-4 text-2xl font-bold">ChÃ o má»«ng EmbeddingGemma, mÃ´ hÃ¬nh nhÃºng hiá»‡u quáº£ má»›i cá»§a Google</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2"></p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-09-27/a5ab6d/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://huggingface.co/blog/assets/faster-transformers/thumbnail.png" alt="CÃ¡c thá»§ thuáº­t tá»« OpenAI gpt-oss mÃ  Báº N ğŸ«µ cÃ³ thá»ƒ sá»­ dá»¥ng vá»›i transformers" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-09-27T00:00:00&#43;00:00">Sep 27, 2025</time>

		<h3 class="my-4 text-2xl font-bold">CÃ¡c thá»§ thuáº­t tá»« OpenAI gpt-oss mÃ  Báº N ğŸ«µ cÃ³ thá»ƒ sá»­ dá»¥ng vá»›i transformers</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2"></p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-22/a45b2c/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/66dca5d6f7d6d9129031431a/1igNGyjLni1PuZnPT4Bnf.jpeg" alt="20x Fine-tuning TRL nhanh hÆ¡n vá»›i RapidFire AI" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">20x Fine-tuning TRL nhanh hÆ¡n vá»›i RapidFire AI</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-22/d40979/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www.anthropic.com" alt="Anthropic Ä‘áº§u tÆ° 50 tá»· Ä‘Ã´ la vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng AI cá»§a Má»¹" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Anthropic Ä‘áº§u tÆ° 50 tá»· Ä‘Ã´ la vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng AI cá»§a Má»¹</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-22/6cc940/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://www.anthropic.com" alt="Bang Maryland há»£p tÃ¡c vá»›i Anthropic Ä‘á»ƒ phá»¥c vá»¥ ngÆ°á»i dÃ¢n tá»‘t hÆ¡n" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Bang Maryland há»£p tÃ¡c vá»›i Anthropic Ä‘á»ƒ phá»¥c vá»¥ ngÆ°á»i dÃ¢n tá»‘t hÆ¡n</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-22/07808c/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/6384db7fb2906edaf835a91d/MOTXxaOmjlTZ8wONYifnD.jpeg" alt="Báº£ng xáº¿p háº¡ng Open ASR- Xu hÆ°á»›ng vÃ  cÃ¡i nhÃ¬n sÃ¢u sáº¯c vá»›i cÃ¡c Track Äa ngÃ´n ngá»¯ &amp; DÃ i háº¡n má»›i" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Báº£ng xáº¿p háº¡ng Open ASR- Xu hÆ°á»›ng vÃ  cÃ¡i nhÃ¬n sÃ¢u sáº¯c vá»›i cÃ¡c Track Äa ngÃ´n ngá»¯ &amp; DÃ i háº¡n má»›i</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-22/7781a3/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://lh3.googleusercontent.com/ipGH8HHMSu49DthGP28XZZ5J8trwbBeVwbkxHoxipOBB1rLI_MRjUeU2zswaIkPgWKRHu5eJGZmUIQWidxCPJ2vVB0KUqy7NwCtLjxu9FU71B-rxcg=w1440-h1440-n-nu" alt="Báº¯t Ä‘áº§u xÃ¢y dá»±ng vá»›i Gemini 3" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Báº¯t Ä‘áº§u xÃ¢y dá»±ng vá»›i Gemini 3</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo dÃµi cÃ¡c tiáº¿n bá»™ má»›i nháº¥t vá» TrÃ­ tuá»‡ nhÃ¢n táº¡o.<br>Trá»±c tiáº¿p tá»« cÃ¡c nhÃ  phÃ¡t hÃ nh AI trÃªn tháº¿ giá»›i.
      </p>

      <p>Äem trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘áº¿n má»i ngÆ°á»i dÃ¢n, doanh nghiá»‡p Viá»‡t, gÃ³p pháº§n giÃºp Viá»‡t Nam phÃ¡t triá»ƒn máº¡nh máº½ trong ká»· nguyÃªn sá»‘. Ná»™i dung Ä‘Æ°á»£c cáº­p nháº­t tá»± Ä‘á»™ng báº±ng mÃ¡y.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright Â© 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>