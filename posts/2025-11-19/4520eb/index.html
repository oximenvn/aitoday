<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Th·ª≠ th√°ch 1 t·ª∑ token- T√¨m ki·∫øm s·ª± k·∫øt h·ª£p ti·ªÅn hu·∫•n luy·ªán ho√†n h·∫£o | AI Today - SkyAI</title>

<meta name="description" content="Th·ª≠ th√°ch 1 t·ª∑ token- T√¨m ki·∫øm s·ª± k·∫øt h·ª£p ti·ªÅn hu·∫•n luy·ªán ho√†n h·∫£o">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['‚ùØ'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['‚ùØ'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">Th·ª≠ th√°ch 1 t·ª∑ token- T√¨m ki·∫øm s·ª± k·∫øt h·ª£p ti·ªÅn hu·∫•n luy·ªán ho√†n h·∫£o</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">Th·ª≠ th√°ch 1 t·ª∑ token- T√¨m ki·∫øm s·ª± k·∫øt h·ª£p ti·ªÅn hu·∫•n luy·ªán ho√†n h·∫£o </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['‚Ä¢'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-11-19T00:00:00&#43;00:00">November 19, 2025</time>
          </li>

          <li class="before:content-['‚Ä¢'] before:mr-2 before:opacity-50 my-2">
            10 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1677134945205-62f32eab52ad88c930bb3f3b.png" alt="Th·ª≠ th√°ch 1 t·ª∑ token- T√¨m ki·∫øm s·ª± k·∫øt h·ª£p ti·ªÅn hu·∫•n luy·ªán ho√†n h·∫£o">
        <figcaption class="text-center italic text-xs">Th·ª≠ th√°ch 1 t·ª∑ token- T√¨m ki·∫øm s·ª± k·∫øt h·ª£p ti·ªÅn hu·∫•n luy·ªán ho√†n h·∫£o</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="the-1-billion-token-challenge-finding-the-perfect-pre-training-mix">The 1 Billion Token Challenge: Finding the Perfect Pre-training Mix</h1>
<p><strong>Training GPT-2 on a Budget: 90%+ Performance with 1/10th the Data</strong></p>
<p>Most modern language models are trained on 1 trillion+ tokens of data, requiring massive computational resources and months of training time. But what if you could achieve over 90% of the performance with just 1/10th of the training data? Through over <strong>50+ systematic experiments</strong>, we discovered the optimal recipe for creating efficient pre-training datasets.</p>
<p>This is the story of how we trained <strong>codelion/gpt-2-70m</strong> using a carefully crafted 1 billion token dataset, achieving performance comparable to the original GPT-2 while using dramatically less data. Along the way, we uncovered critical insights about dataset mixing strategies, discovered catastrophic failure modes in curriculum learning, and identified the &ldquo;goldilocks zone&rdquo; for synthetic content.</p>
<p><strong>TL;DR:</strong> We found that a static <strong>50% finePDFs + 30% DCLM-baseline + 20% FineWeb-Edu</strong> mixture consistently outperforms complex curriculum strategies, avoiding catastrophic failures while maintaining excellent generalization.</p>
<h2 id="the-problem-can-we-train-smarter-not-harder">The Problem: Can We Train Smarter, Not Harder?</h2>
<p>Training large language models has become an arms race of scale. Modern models consume trillions of tokens during pre-training, with training runs lasting months and costing millions of dollars. The assumption is simple: more data = better models.</p>
<p>But this raises a crucial question: <strong>Is all that data equally valuable?</strong></p>
<p>We suspected the answer was no. Recent research on synthetic data and careful curation suggested that <strong>dataset quality matters as much as quantity</strong>. The challenge was finding the optimal composition: the perfect balance between different types of training data.</p>
<p>Our goal: Create a 1 billion token dataset that could train a GPT-2-sized model to match the performance of models trained on 10x more data.</p>
<h2 id="our-approach-systematic-dataset-mixing-experiments">Our Approach: Systematic Dataset Mixing Experiments</h2>
<p>We conducted <strong>over 50 controlled experiments</strong> using a GPT-2 architecture with 70 million parameters, systematically testing different combinations of three data sources from our <a href="https://huggingface.co/collections/codelion/pre-training-dataset-samples">pre-training dataset collection</a>:</p>
<p><strong>Dataset Types:</strong></p>
<ol>
<li><strong>finePDFs</strong> (500M tokens) - High-quality textbook-style educational PDFs</li>
<li><strong>DCLM-baseline</strong> (300M tokens) - Filtered, diverse web content</li>
<li><strong>FineWeb-Edu</strong> (200M tokens) - Curated educational web resources</li>
</ol>
<p>These dataset samples were created from their much larger source datasets using <strong>reservoir sampling</strong>, an algorithm that guarantees statistically unbiased random samples. This ensures our experimental results at 10M, 100M, and 1B token scales are representative of the full datasets&rsquo; characteristics, allowing us to rapidly iterate on mixing strategies without processing terabytes of data.</p>
<p>We evaluated performance using two key metrics:</p>
<ul>
<li><strong>Validation Perplexity</strong>: In-domain performance (lower is better)</li>
<li><strong>FineWiki Perplexity</strong>: Out-of-domain generalization (lower is better)</li>
</ul>
<p>The experiments progressed through phases:</p>
<ol>
<li><strong>Phase 1</strong>: Rapid exploration at 10M tokens (15 experiments)</li>
<li><strong>Phase 2</strong>: Detailed analysis at 100M tokens with static mixtures (25+ experiments)</li>
<li><strong>Phase 3</strong>: Curriculum learning strategies at 100M tokens (15 experiments)</li>
<li><strong>Final Training</strong>: Scaled winning 50-30-20 mixture to 1B tokens to train GPT-2-70M</li>
</ol>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/02-s_i3Ppys6q9ELEMycb.png" alt="Screenshot 2025-11-02 at 11.45.48 PM"></p>
<h2 id="discovery-1-the-50-30-20-sweet-spot">Discovery #1: The 50-30-20 Sweet Spot</h2>
<p>After testing ratios ranging from 0% to 100% synthetic content, we discovered the optimal composition:</p>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/Da5Hwf_gO0J8ipXHlCLHn.png" alt="Screenshot 2025-11-02 at 11.46.38 PM"></p>
<p><strong>50% finePDFs + 30% DCLM-baseline + 20% FineWeb-Edu</strong></p>
<p>This configuration achieved:</p>
<ul>
<li><strong>27.38 validation perplexity</strong> (excellent in-domain performance)</li>
<li><strong>346 FineWiki perplexity</strong> (best generalization across all experiments)</li>
<li><strong>12.6x generalization ratio</strong> (validation to FineWiki)</li>
</ul>
<p>Why does this work so well? The mixture balances three competing objectives:</p>
<ol>
<li><strong>finePDFs (50%)</strong>: Provides high-quality, grammatically perfect examples with clear structure. This anchors the model&rsquo;s understanding of language structure and correctness.</li>
<li><strong>DCLM-baseline (30%)</strong>: Introduces diversity and real-world language patterns. Prevents the model from overfitting to synthetic patterns while maintaining reasonable quality.</li>
<li><strong>FineWeb-Edu (20%)</strong>: Bridges the gap between synthetic perfection and web messiness. Provides domain-specific knowledge in natural writing styles.</li>
</ol>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/MGP_gXPPii2JBKtGQpdYv.png" alt="performance_comparison"></p>
<h2 id="discovery-2-the-validation-generalization-tradeoff">Discovery #2: The Validation-Generalization Tradeoff</h2>
<p>One of our most important insights was understanding the fundamental tradeoff between validation performance (how well the model fits the training distribution) and generalization (how well it performs on unseen data).</p>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/LiMZPlOHztAfzIkhUdO_o.png" alt="validation_vs_generalization"></p>
<p><strong>Pure finePDFs</strong> achieves incredible validation performance (6.76 PPL) but catastrophically fails at generalization (4,846 FineWiki PPL), a 717x ratio! The model essentially memorizes the synthetic patterns but can&rsquo;t transfer to natural text.</p>
<p><strong>Pure DCLM-baseline</strong> shows the opposite pattern: decent generalization (994 PPL) but poor validation performance (126.76 PPL). The model sees diverse examples but struggles to learn clear patterns.</p>
<p><strong>The 50-30-20 mixture</strong> sits at the optimal point on the pareto frontier:</p>
<ul>
<li>4x worse validation than pure synthetic (27.38 vs 6.76)</li>
<li>But 14x better generalization (346 vs 4,846)</li>
</ul>
<p>This taught us a crucial lesson: <strong>You can&rsquo;t have both &lt;10 validation PPL AND &lt;500 FineWiki PPL.</strong> The sweet spot is accepting 20-30 validation PPL to achieve 300-400 FineWiki PPL.</p>
<h2 id="discovery-3-the-hard-cutoff-catastrophe">Discovery #3: The Hard Cutoff Catastrophe</h2>
<p>We initially hypothesized that curriculum learning (gradually changing the data distribution during training) would outperform static mixing. After all, humans learn by starting with simple concepts and progressing to complex ones.</p>
<p><strong>We were wrong.</strong> In fact, most curriculum strategies performed significantly worse than simple static mixing.</p>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/CLITk8tMSNZiW54ZsU7mb.png" alt="curriculum_failure"></p>
<p>We discovered two systematic failure modes:</p>
<h3 id="forward-catastrophe-quality--diverse">Forward Catastrophe (Quality ‚Üí Diverse)</h3>
<p>Training on 100M tokens of pure finePDFs followed by 100M tokens of DCLM-baseline caused <strong>catastrophic forgetting</strong>:</p>
<ul>
<li>Stage 1: 17.84 PPL (excellent!)</li>
<li>Stage 2: 103.83 PPL (6x worse!)</li>
</ul>
<p>The model overfit to synthetic patterns and then &ldquo;forgot&rdquo; them when exposed to diverse data, similar to catastrophic forgetting in continual learning research.</p>
<h3 id="reverse-catastrophe-diverse--quality">Reverse Catastrophe (Diverse ‚Üí Quality)</h3>
<p>Training on 100M tokens of DCLM-baseline followed by 100M tokens of finePDFs caused <strong>catastrophic overfitting</strong>:</p>
<ul>
<li>Validation PPL: 16.28 (best ever!)</li>
<li>FineWiki PPL: 5,955 (worst ever!)</li>
<li>Generalization ratio: 366x (catastrophic)</li>
</ul>
<p>The model achieved excellent validation scores but completely failed to generalize. 100M tokens of pure synthetic content was simply too much.</p>
<p><strong>The key insight</strong>: Hard transitions between data distributions are harmful. If you must use curriculum learning, limit pure synthetic exposure to 20-25M tokens maximum and use gradual transitions (changing ratios by ‚â§20% per phase).</p>
<h2 id="discovery-4-static-mixing-beats-curricula">Discovery #4: Static Mixing Beats Curricula</h2>
<p>Comparing our best static mixture (50-30-20) against the best curriculum approach (annealing strategy):</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Strategy</th>
          <th style="text-align: left">Validation PPL</th>
          <th style="text-align: left">FineWiki PPL</th>
          <th style="text-align: left">Training Time</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>50-30-20 Static</strong></td>
          <td style="text-align: left"><strong>27.38</strong></td>
          <td style="text-align: left"><strong>346</strong></td>
          <td style="text-align: left">0.73h</td>
      </tr>
      <tr>
          <td style="text-align: left">Best Curriculum</td>
          <td style="text-align: left">49.82</td>
          <td style="text-align: left">930</td>
          <td style="text-align: left">1.58h</td>
      </tr>
  </tbody>
</table>
<p>Static mixing is:</p>
<ul>
<li><strong>1.8x better on validation</strong></li>
<li><strong>2.7x better on generalization</strong></li>
<li><strong>2x faster to train</strong></li>
</ul>
<p>Why does static mixing work so well?</p>
<ol>
<li><strong>No distribution shift</strong>: The model sees a consistent data distribution throughout training, avoiding adaptation challenges</li>
<li><strong>Natural curriculum emerges</strong>: The model naturally learns easier patterns first (web data) before tackling harder patterns (synthetic structure) with no manual intervention needed</li>
<li><strong>Computational efficiency</strong>: Single training run with no phase boundaries to tune</li>
<li><strong>Simplicity</strong>: Easy to implement, scale, and reproduce</li>
</ol>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/r-SkCmdI8Afa5jU43II00.png" alt="Screenshot 2025-11-02 at 11.48.52 PM"></p>
<h2 id="the-result-gpt-2-70m">The Result: GPT-2-70M</h2>
<p>Armed with our optimal 50-30-20 mixture, we scaled to 1 billion tokens and trained <strong>codelion/gpt-2-70m</strong>:</p>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/M6mYdu2ifEe8TxZetb68B.png" alt="gpt2_comparison"></p>
<p><strong>Model specifications:</strong></p>
<ul>
<li><strong>Parameters</strong>: 70M (64,085,504 actual)</li>
<li><strong>Architecture</strong>: 12 layers, 512 hidden dimensions, 8 attention heads</li>
<li><strong>Training tokens</strong>: 1 billion (vs 10 billion for original GPT-2)</li>
<li><strong>Context window</strong>: 1024 tokens</li>
<li><strong>Training time</strong>: ~8 hours on single A100 GPU</li>
</ul>
<p><strong>Benchmark Performance:</strong></p>
<p>We evaluated GPT-2-70M on the HuggingFace Open LLM Leaderboard (6 standard benchmarks) to measure how it compares to the original GPT-2:</p>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/UjuKs6QWVsKZ1agHJxvA9.png" alt="benchmark_comparison"></p>
<p><strong>Key Results:</strong></p>
<ul>
<li><strong>Average score: 38.15%</strong> (vs GPT-2&rsquo;s 39.13%) - only <strong>0.98 percentage points behind</strong></li>
<li>Achieves <strong>over 90% of GPT-2&rsquo;s performance</strong> despite 44% fewer parameters</li>
<li>Trained on <strong>10x less data</strong> (1B vs 10B tokens)</li>
<li><strong>Actually wins on TruthfulQA</strong>: 47.31% vs GPT-2&rsquo;s 40.69% (thanks to 50% finePDFs content)</li>
<li><strong>50x cheaper</strong> to train (~$50 vs $2500+ for full GPT-2 replication)</li>
</ul>
<p><strong>Detailed Benchmark Breakdown:</strong></p>
<ul>
<li><strong>MMLU</strong> (academic knowledge): 24.11% vs 26.09% (-1.98 pp)</li>
<li><strong>HellaSwag</strong> (commonsense): 27.03% vs 31.14% (-4.11 pp)</li>
<li><strong>ARC-Challenge</strong> (science): 21.67% vs 22.70% (-1.03 pp)</li>
<li><strong>PIQA</strong> (physical reasoning): 57.29% vs 62.51% (-5.22 pp)</li>
<li><strong>WinoGrande</strong> (pronoun resolution): 51.46% vs 51.62% (-0.16 pp)</li>
<li><strong>TruthfulQA</strong> (factual accuracy): <strong>47.31% vs 40.69% (+6.62 pp)</strong> ‚ú® Winner!</li>
</ul>
<p>This demonstrates the power of thoughtful dataset curation: <strong>with the right 50-30-20 mixture, you can achieve near-identical performance to a model with 2x the parameters trained on 10x more data.</strong></p>
<h2 id="the-optimal-recipe-for-1b-token-datasets">The Optimal Recipe for 1B Token Datasets</h2>
<p>Based on our findings, here&rsquo;s our recommended approach for creating pre-training datasets:</p>
<p><img src="https://cdn-uploads.huggingface.co/production/uploads/62f32eab52ad88c930bb3f3b/tAqzeldbMnftXN7sf2Yju.png" alt="dataset_composition_pie"></p>
<h3 id="composition-50-30-20-mix">Composition (50-30-20 Mix)</h3>
<p><strong>500M tokens: finePDFs ( <a href="https://huggingface.co/datasets/codelion/finepdfs-1B">codelion/finepdfs-1B</a> )</strong></p>
<ul>
<li>High-quality textbook-style PDFs</li>
<li>Academic papers and educational materials</li>
<li>Structured explanations and pedagogically sound content</li>
<li>Grammatically perfect with clear organization</li>
</ul>
<p><strong>300M tokens: DCLM-baseline ( <a href="https://huggingface.co/datasets/codelion/dclm-baseline-1B">codelion/dclm-baseline-1B</a> )</strong></p>
<ul>
<li>Filtered, diverse web content</li>
<li>Quality-filtered while maintaining natural language patterns</li>
<li>Broad topic coverage for generalization</li>
<li>Real-world text diversity</li>
</ul>
<p><strong>200M tokens: FineWeb-Edu ( <a href="https://huggingface.co/datasets/codelion/fineweb-edu-1B">codelion/fineweb-edu-1B</a> )</strong></p>
<ul>
<li>Curated educational web resources</li>
<li>Natural writing style with educational focus</li>
<li>Domain-specific learning materials</li>
<li>Bridge between textbook quality and web diversity</li>
</ul>
<h3 id="training-strategy">Training Strategy</h3>
<p><strong>Use static mixing</strong> (recommended for most use cases):</p>
<ul>
<li>Shuffle all data together with the 50-30-20 ratio</li>
<li>Train for the full 1B tokens without changing distribution</li>
<li>Simple, fast, and proven effective</li>
</ul>
<h2 id="key-takeaways">Key Takeaways</h2>
<p>After 50+ experiments and countless hours of GPU time, here are the lessons we learned:</p>
<ol>
<li><strong>Dataset composition is crucial</strong>: The right mixture matters more than total data volume. Our 1B token dataset with optimal mixing outperforms naive 10B token datasets.</li>
<li><strong>50-30-20 is the sweet spot</strong>: This ratio balances validation performance with generalization better than any other configuration we tested.</li>
<li><strong>Static mixing &gt; Curriculum learning</strong>: Simple static mixtures consistently outperform complex curriculum strategies while being faster and easier to implement.</li>
<li><strong>Hard cutoffs cause catastrophic failures</strong>: Abrupt changes in data distribution lead to either catastrophic forgetting or severe overfitting. If using curricula, transition gradually.</li>
<li><strong>The 90/10 efficiency rule</strong>: With careful dataset curation (50-30-20 mixing), you can achieve 90%+ of model performance with just 10% of the training data.</li>
<li><strong>Generalization requires diversity</strong>: Pure finePDFs achieves low perplexity but fails catastrophically on real-world text. The 30% DCLM-baseline + 20% FineWeb-Edu components are essential.</li>
</ol>
<h2 id="try-it-yourself">Try It Yourself</h2>
<p>We&rsquo;re releasing both our <a href="https://huggingface.co/collections/codelion/pre-training-dataset-samples">pre-training dataset collection</a> and the trained <a href="https://huggingface.co/codelion/gpt-2-70m">GPT-2-70M model</a> for the community to use and build upon.</p>
<h3 id="quick-start-use-the-model">Quick Start: Use the Model</h3>
<p>python
from transformers import AutoTokenizer, AutoModelForCausalLM</p>
<h1 id="load-model-and-tokenizer">Load model and tokenizer</h1>
<p>tokenizer = AutoTokenizer.from_pretrained(&ldquo;codelion/gpt-2-70m&rdquo;)
model = AutoModelForCausalLM.from_pretrained(&ldquo;codelion/gpt-2-70m&rdquo;)</p>
<h1 id="generate-text-with-better-sampling-parameters">Generate text with better sampling parameters</h1>
<p>inputs = tokenizer(&ldquo;The future of AI is&rdquo;, return_tensors=&ldquo;pt&rdquo;)
outputs = model.generate(
**inputs,
max_length=50,
do_sample=True,           # Enable sampling
temperature=0.8,          # Control randomness
top_p=0.9,               # Nucleus sampling
pad_token_id=tokenizer.eos_token_id
)
print(tokenizer.decode(outputs[0]))</p>
<h3 id="create-your-own-dataset">Create Your Own Dataset</h3>
<p>Explore our <a href="https://huggingface.co/collections/codelion/pre-training-dataset-samples">pre-training dataset collection</a> to see examples of high-quality finePDFs, DCLM-baseline, and FineWeb-Edu content. Use these as references for creating your own optimally-mixed pre-training datasets.</p>
<p>python
from datasets import load_dataset</p>
<h1 id="load-samples-from-our-collection">Load samples from our collection</h1>
<p>finepdfs = load_dataset(&ldquo;codelion/finepdfs-1B&rdquo;, split=&ldquo;train&rdquo;)
dclm = load_dataset(&ldquo;codelion/dclm-baseline-1B&rdquo;, split=&ldquo;train&rdquo;)
fineweb_edu = load_dataset(&ldquo;codelion/fineweb-edu-1B&rdquo;, split=&ldquo;train&rdquo;)</p>
<h1 id="mix-in-50-30-20-ratio">Mix in 50-30-20 ratio</h1>
<p>Community</p>
<p>Nice job üëè</p>
<p>Incredible work!!!</p>
<p>Great, what about different language ? What minimal mix is required for bilingual, trilingual &hellip;</p>
<p>Also, adding a new language to a existing model ? Or coding skills ?</p>
<p>If you took your GPT2 model and tried to make it talk 16+language, would continued training on a new static mix work or does it need to be started from scratch ? Catastrophic risks ?</p>
<p>Thanks</p>
<blockquote>
<p>This would be a great follow up work to explore. FineWeb 2 has a good corpus of multilingual pretraining data we can use - <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-2">https://huggingface.co/datasets/HuggingFaceFW/fineweb-2</a></p></blockquote>
<p>Great work, super interesting article! You mention that the best curriculum is an annealing strategy. Is that between two or multiple datasets and did you also test annealing between different mixtures? Thanks!</p>
<blockquote>
<p>yes, we did test annealing strategies as part of our curriculum learning experiments.</p>
<p>The &ldquo;annealing strategy&rdquo; we refer involved gradual transitions between mixing ratios across all three datasets (finePDFs, DCLM-baseline, and FineWeb-Edu). Rather than hard cutoffs (like going from 100% one dataset to 100% another), we tested annealing where we changed the mixture ratios by adjusting &lt; 20% per phase.</p>
<p>For example, one annealing approach was:</p>
<ul>
<li>Phase 1 (25M tokens): 70-20-10 (heavy on finePDFs)</li>
<li>Phase 2 (50M tokens): 60-25-15 (transitioning)</li>
<li>Phase 3 (25M tokens): 50-30-20 (final mixture)</li>
</ul>
<p>We tested several variations including:</p>
<ol>
<li>Forward annealing (starting synthetic-heavy ‚Üí more diverse)</li>
<li>Reverse annealing (starting diverse ‚Üí more synthetic)</li>
<li>Multi-phase gradual transitions between different ratios</li>
</ol>
<p>However, even our best annealing strategy (49.82 validation PPL, 930 FineWiki PPL) significantly underperformed the simple static 50-30-20 mixture (27.38 validation PPL, 346 FineWiki PPL) - about 1.8x worse on validation and 2.7x worse on generalization.</p></blockquote>
<p>Super interesting experiments, thanks for sharing!</p>
<p>Company
TOS Privacy About Jobs Models Datasets Spaces Pricing Docs</p>
<h3 id="link-b√†i-vi·∫øt-g·ªëc"><a href="https://huggingface.co/blog/codelion/optimal-dataset-mixing">Link b√†i vi·∫øt g·ªëc</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/16-days-ago/">16 Days Ago</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-19/4af950/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/63d3095c2727d7888cbb54e2/Uv-Lx8PVGviqokfOyYlCN.png" alt="Apriel-H1- Ch√¨a kh√≥a b·∫•t ng·ªù ƒë·ªÉ ch∆∞ng c·∫•t c√°c m√¥ h√¨nh suy lu·∫≠n hi·ªáu qu·∫£" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-11-19T00:00:00&#43;00:00">Nov 19, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Apriel-H1- Ch√¨a kh√≥a b·∫•t ng·ªù ƒë·ªÉ ch∆∞ng c·∫•t c√°c m√¥ h√¨nh suy lu·∫≠n hi·ªáu qu·∫£</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Apriel-H1- Ch√¨a kh√≥a b·∫•t ng·ªù ƒë·ªÉ ch∆∞ng c·∫•t c√°c m√¥ h√¨nh suy lu·∫≠n hi·ªáu qu·∫£</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-19/992936/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/680ff4388f704be391757780/-9cmzdDMCol0OfkTYK8jF.png" alt="B·∫£n ƒë·ªì Pharmome- b·ªô d·ªØ li·ªáu c√¥ng khai to√†n di·ªán ƒë·ªÉ m√¥ h√¨nh h√≥a t∆∞∆°ng t√°c thu·ªëc-m·ª•c ti√™u" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-11-19T00:00:00&#43;00:00">Nov 19, 2025</time>

		<h3 class="my-4 text-2xl font-bold">B·∫£n ƒë·ªì Pharmome- b·ªô d·ªØ li·ªáu c√¥ng khai to√†n di·ªán ƒë·ªÉ m√¥ h√¨nh h√≥a t∆∞∆°ng t√°c thu·ªëc-m·ª•c ti√™u</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">B·∫£n ƒë·ªì Pharmome- b·ªô d·ªØ li·ªáu c√¥ng khai to√†n di·ªán ƒë·ªÉ m√¥ h√¨nh h√≥a t∆∞∆°ng t√°c thu·ªëc-m·ª•c ti√™u</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-05/207ec8/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://image-link" alt="C√°c t√πy ch·ªçn m·ªõi cho s·ª± ƒë·ªïi m·ªõi, kh·∫£ nƒÉng ph·ª•c h·ªìi v√† ki·ªÉm so√°t ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi AI v·ªõi Microsoft Azure" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">C√°c t√πy ch·ªçn m·ªõi cho s·ª± ƒë·ªïi m·ªõi, kh·∫£ nƒÉng ph·ª•c h·ªìi v√† ki·ªÉm so√°t ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi AI v·ªõi Microsoft Azure</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-05/540afb/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1736321480545-NTEWKRUMLWKSC1ET6D7E/SPAR3D_Hero&#43;Thumbnail_Blog&#43;1_1.png" alt="Gi·ªõi thi·ªáu Stable Point Aware 3D- Ch·ªânh s·ª≠a Th·ªùi gian th·ª±c v√† T·∫°o C·∫•u tr√∫c ƒê·ªëi t∆∞·ª£ng Ho√†n ch·ªânh" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Gi·ªõi thi·ªáu Stable Point Aware 3D- Ch·ªânh s·ª≠a Th·ªùi gian th·ª±c v√† T·∫°o C·∫•u tr√∫c ƒê·ªëi t∆∞·ª£ng Ho√†n ch·ªânh</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-05/a63c95/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://image-link" alt="Gi·ªõi thi·ªáu swift-huggingface- Kh√°ch h√†ng Swift Ho√†n ch·ªânh cho Hugging Face" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Gi·ªõi thi·ªáu swift-huggingface- Kh√°ch h√†ng Swift Ho√†n ch·ªânh cho Hugging Face</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-05/249485/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://lh3.googleusercontent.com/dF_B69Wgk_ysh-ORrRzwA3AopqFCySf3EFFuAHicRIg_4md882y8LnN8bbrw-FXpmRQe7fbg5u4Z7lzz7iqLs13KzCwbWBmhfPFd6L4Upiz4eQbsZgU=w1440-h1440-n-nu" alt="K·ªπ thu·∫≠t t·∫°o ra c√¢y tr·ªìng ch·ªëng ch·ªãu t·ªët h∆°n cho kh√≠ h·∫≠u n√≥ng l√™n" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">K·ªπ thu·∫≠t t·∫°o ra c√¢y tr·ªìng ch·ªëng ch·ªãu t·ªët h∆°n cho kh√≠ h·∫≠u n√≥ng l√™n</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-05/ec2ad1/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1757434073418-3UO9SI02NHKCQV49WUCQ/StableAudio2.5_Thumbnail_1x1_v5&#43;%281%29.png" alt="Stability AI gi·ªõi thi·ªáu Stable Audio 2.5, M√¥ h√¨nh √Çm thanh ƒê·∫ßu ti√™n ƒê∆∞·ª£c X√¢y d·ª±ng cho S·∫£n xu·∫•t √Çm thanh Doanh nghi·ªáp Quy m√¥ l·ªõn" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Stability AI gi·ªõi thi·ªáu Stable Audio 2.5, M√¥ h√¨nh √Çm thanh ƒê·∫ßu ti√™n ƒê∆∞·ª£c X√¢y d·ª±ng cho S·∫£n xu·∫•t √Çm thanh Doanh nghi·ªáp Quy m√¥ l·ªõn</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo d√µi c√°c ti·∫øn b·ªô m·ªõi nh·∫•t v·ªÅ Tr√≠ tu·ªá nh√¢n t·∫°o.<br>Tr·ª±c ti·∫øp t·ª´ c√°c nh√† ph√°t h√†nh AI tr√™n th·∫ø gi·ªõi.
      </p>

      <p>ƒêem tr√≠ tu·ªá nh√¢n t·∫°o ƒë·∫øn m·ªçi ng∆∞·ªùi d√¢n, doanh nghi·ªáp Vi·ªát, g√≥p ph·∫ßn gi√∫p Vi·ªát Nam ph√°t tri·ªÉn m·∫°nh m·∫Ω trong k·ª∑ nguy√™n s·ªë. N·ªôi dung ƒë∆∞·ª£c c·∫≠p nh·∫≠t t·ª± ƒë·ªông b·∫±ng m√°y.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright ¬© 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>