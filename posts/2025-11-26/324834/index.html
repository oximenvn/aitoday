<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Batching liên tục từ những nguyên tắc cơ bản | AI Today - SkyAI</title>

<meta name="description" content="Batching liên tục từ những nguyên tắc cơ bản">
      <link rel="stylesheet" href="/css/main.min.584aed796ba9d245f84009d57da9662e9c02059611972780263728b442fc25ff.css" integrity="sha256-WErteWup0kX4QAnVfalmLpwCBZYRlyeAJjcotEL8Jf8=" crossorigin="anonymous">

<link rel="icon" type="image/svg+xml" href="https://aitoday.skyai.vn/favicon.svg"> 
<link rel="icon" type="image/x-icon" href="https://aitoday.skyai.vn/favicon.ico"> 
<link rel="icon" type="image/png" sizes="16x16" href="https://aitoday.skyai.vn/favicon.png"> 
<link rel="icon" type="image/png" sizes="32x32" href="https://aitoday.skyai.vn/favicon-32.png"> 
<link rel="icon" type="image/png" sizes="64x64" href="https://aitoday.skyai.vn/favicon-64.png"> 

</head>
<body>
  <header class="py-6 border-b"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8 flex flex-col">
	<div class="flex items-center">
		<div class="flex items-center">
			<button class="flex items-center space-x-2 rounded-full border py-1 pr-[5px] pl-3 group bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="menu-bar">
				<svg width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
					<path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z"></path>
				</svg>
				<span class="bg-blue-500 fill-white rounded-full p-1.5">
					<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-spin bi bi-egg-fried fill-white" viewBox="0 0 16 16">
						<path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"></path>
						<path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"></path>
					</svg>
				</span>
			</button>
			<div class="relative rounded-full py-1.5 px-6 bg-zinc-100 hover:bg-zinc-200 text-xl font-bold uppercase mx-2">
				<h2><a class="before:content-[''] before:z-10 before:top-0 before:right-0 before:left-0 before:bottom-0 before:absolute before:pointer-events-auto" href="https://aitoday.skyai.vn/">AI Today - SkyAI</a></h2>
			</div>
		</div>
		<div class="flex items-center ml-auto">
			<button class="flex items-center rounded-full p-3 bg-zinc-100 hover:bg-zinc-200 toggle-button" data-target="search-bar">
				<svg width="18" height="18" fill="currentColor" viewBox="0 0 16 16">
					<path id="path1" class="transition-all ease-linear" d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
					<path id="path2" class="transition-all ease-linear hidden" d="M2.146 2.854a.5.5 0 1 1 .708-.708L8 7.293l5.146-5.147a.5.5 0 0 1 .708.708L8.707 8l5.147 5.146a.5.5 0 0 1-.708.708L8 8.707l-5.146 5.147a.5.5 0 0 1-.708-.708L7.293 8 2.146 2.854Z"></path>
				</svg>
			</button>
		</div>
	</div>
  <nav id="menu-bar" class="block mt-3 close">
    <ul class="flex items-center flex flex-nowrap whitespace-nowrap overflow-x-auto space-x-4">
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/">Home</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200">About</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Tags</a>
    </li>
    <li class="my-2">
      <a class="rounded-full border px-6 py-2 bg-zinc-100 hover:bg-zinc-200" href="/tags/">Taxonomy</a>
    </li>
    </ul>
  </nav>
<div id="search-bar" class="block mt-3 close">
	<form id="search" class="flex items-stretch">
		<input class="w-full block px-6 py-2 rounded-l-full focus:outline-none border border-zinc-200" type="text" placeholder="Search...">
		<button class="flex items-center px-7 py-2.5 rounded-r-full border border-zinc-200 ">
			<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" class="group-hover:animate-pulse" viewBox="0 0 16 16">
				<path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"></path>
			</svg>
		</button>
	</form>
</div>
</div></header>
  <main class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8"><div id="breadcrumb" class="max-w-7xl mx-auto py-8">
	<ul class="flex space-x-4 text-sm text-zinc-500">
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/">AI Today - SkyAI</a>
		</li>
		<li class="after:content-['❯'] after:ml-4 after:opacity-30 last:after:content-none uppercase">
			<a href="https://aitoday.skyai.vn/posts/">Posts</a>
		</li>
	</ul>
</div><div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-14">

  <article class="md:col-span-2 prose lg:prose-lg">

    <header class="not-prose">
      
      <h1 id="title" class="text-4xl font-bold leading-normal">Batching liên tục từ những nguyên tắc cơ bản</h1>

      <div id="lead" class="my-6">

        <p class="font-bold">Batching liên tục từ những nguyên tắc cơ bản </p>

      </div>
      
      <div id="writer" class="flex items-center space-x-4"><ul class="flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">
          
          <li class="font-semibold my-2"></li>
          
          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2"><time datetime="2025-11-26T00:00:00&#43;00:00">November 26, 2025</time>
          </li>

          <li class="before:content-['•'] before:mr-2 before:opacity-50 my-2">
            19 min read
          </li>

        </ul>

      </div>
      
    </header>

    <figure id="featureimage" class="rounded-xl aspect-video">

          <img class="rounded-lg" src="https://cdn-avatars.huggingface.co/v1/production/uploads/6123945a0ed258ebc83f3d56/8wMHFQHEV24G_ljl4kPxQ.jpeg" alt="Batching liên tục từ những nguyên tắc cơ bản">
        <figcaption class="text-center italic text-xs">Batching liên tục từ những nguyên tắc cơ bản</figcaption>

    </figure>

    <div id="content" class="mb-14">
      <h1 id="continuous-batching-từ-nguyên-lý-đầu-tiên">Continuous batching từ nguyên lý đầu tiên</h1>
<p><em>TL;DR: Trong bài đăng này, bắt đầu từ các cơ chế attention và KV caching, chúng tôi dẫn xuất continuous batching bằng cách tối ưu hóa thông lượng.</em></p>
<p>Nếu bạn đã từng sử dụng Qwen, Claude hoặc bất kỳ chatbot AI nào khác, bạn có thể đã nhận thấy điều gì đó: phải mất một lúc để từ đầu tiên của phản hồi xuất hiện, và sau đó các từ xuất hiện lần lượt trên màn hình của bạn với tần suất đều đặn và nhanh chóng (hy vọng là vậy). Đó là bởi vì về cốt lõi, tất cả các LLM chỉ là những bộ dự đoán token tiếp theo rất tốt. Một LLM trước tiên xử lý toàn bộ prompt của bạn để tạo ra một token mới. Sau đó, nó tiếp tục thêm các token từng cái một, mỗi lần đọc lại mọi thứ đã xảy ra trước đó, cho đến khi nó quyết định quá trình tạo đã hoàn tất.</p>
<p>Quá trình tạo này tốn nhiều tài nguyên tính toán: nó yêu cầu truyền đầu vào qua hàng tỷ tham số cho mỗi token được tạo ra. Để làm cho các mô hình này trở nên thiết thực cho các ứng dụng trong thế giới thực, đặc biệt là khi phục vụ nhiều người dùng đồng thời, các nhà nghiên cứu và kỹ sư đã phát triển một loạt các kỹ thuật suy luận hiệu quả. Một trong những tối ưu hóa có tác động nhất là <strong>continuous batching</strong>, một kỹ thuật cố gắng tối đa hóa hiệu suất bằng cách xử lý nhiều cuộc trò chuyện song song và hoán đổi chúng ra khi hoàn thành.</p>
<p>Để hiểu cách continuous batching hoạt động và tại sao nó lại hiệu quả trong các tình huống phục vụ tải cao, chúng ta sẽ xây dựng dựa trên các nguyên tắc cơ bản về cách LLM xử lý token.</p>
<h2 id="attention">Attention</h2>
<p>Cơ chế attention là phần trung tâm của cách LLM hoạt động. Một mô hình ngôn ngữ xử lý văn bản bằng cách chia nó thành các phần mà chúng ta gọi là token. Chúng ta có thể coi &ldquo;token&rdquo; là &ldquo;từ&rdquo;, nhưng đôi khi một từ có thể bao gồm nhiều token. Đối với mỗi chuỗi token, mạng tính toán một dự đoán về token tiếp theo nên là gì.</p>
<p>Nhiều thao tác trong mạng là <strong>token-wise</strong> (theo từng token): mỗi token được xử lý độc lập, và đầu ra cho một token nhất định chỉ phụ thuộc vào nội dung của token đó, không phụ thuộc vào bất kỳ token nào khác trong chuỗi. Các thao tác như vậy bao gồm chuẩn hóa lớp hoặc nhân ma trận. Tuy nhiên, để tạo kết nối giữa các từ trong một câu, chúng ta cần các thao tác mà các token có thể ảnh hưởng lẫn nhau.</p>
<p>Đây là nơi cơ chế attention phát huy tác dụng. <strong>Các lớp attention là nơi duy nhất mà các token khác nhau tương tác với nhau</strong>. Hiểu cách một mạng kết nối các token với nhau có nghĩa là hiểu cơ chế attention.</p>
<p>Hãy xem cách điều này hoạt động trong thực tế, trong trường hợp chỉ có một prompt đầu vào.</p>
<p>Hãy xem xét prompt ban đầu <code>I am sure this project</code>, được token hóa thành 7 token: <code>[&amp;lt;bos&amp;gt;, I, am, sure, this, pro, ject]</code>. Token <code>&amp;lt;bos&amp;gt;</code>, hay &ldquo;Beginning of Sequence&rdquo; (Bắt đầu chuỗi), là một token đặc biệt mà chúng ta thêm vào đầu prompt để báo cho mô hình ngôn ngữ rằng một cuộc trò chuyện mới bắt đầu tại đây.</p>
<p>Mỗi token được biểu diễn bên trong mạng với một vector có độ dài <code>d</code> (là <!-- raw HTML omitted -->hidden dimension<!-- raw HTML omitted -->). Do đó, bảy token đầu vào tạo thành một tensor $x$ với hình dạng $[1, 7, d]$. $1$ là số lượng chuỗi, hoặc kích thước batch, chỉ là một trong trường hợp của chúng ta. $7$ là độ dài chuỗi, và $d$ là hidden dimension, hoặc kích thước của mỗi biểu diễn token. Chúng ta sẽ sử dụng $n$ thay vì $7$ làm độ dài chuỗi trong các ví dụ tiếp theo.</p>
<p>Tensor đầu vào $x$ sau đó được chiếu bởi ba ma trận: phép chiếu query $W_q$, phép chiếu key $W_k$ và phép chiếu value $W_v$. Điều này tạo ra ba tensor $Q$, $K$ và $V$, tất cả đều có hình dạng $[1, n, A]$, trong đó $A$ là chiều của đầu attention. Chúng ta gọi chúng là các trạng thái <!-- raw HTML omitted -->query, key và value<!-- raw HTML omitted -->, tương ứng. Điều này được biểu diễn ở bên trái trong hình dưới đây.</p>
<!-- raw HTML omitted -->
<p>Tiếp theo, các tensor $Q$ và $K$ được nhân với nhau để đo lường sự tương đồng giữa các token, tạo ra một tensor có hình dạng $[1, n, n]$. Đây là lý do tại sao chúng ta nói rằng attention có độ phức tạp bậc hai theo độ dài chuỗi. Việc tính $QK^T$ yêu cầu $O(n^2 d)$ thao tác, vì vậy chi phí là bình phương của độ dài chuỗi $n$. Nó được biểu diễn ở bên phải trong hình trên.</p>
<p>Sau đó, chúng ta áp dụng một <!-- raw HTML omitted -->attention mask<!-- raw HTML omitted --> boolean cho $QK^T$ để kiểm soát token nào có thể tương tác, như được biểu diễn trong hình dưới đây. Trong hình này, attention mask là <!-- raw HTML omitted -->causal mask<!-- raw HTML omitted -->, có nghĩa là mỗi token chỉ tương tác với các token đi trước nó. Điều này tuân theo trực giác rằng một nguyên nhân phải đi trước kết quả của nó, do đó có tên là causal mask. Attention mask rất quan trọng vì nó quyết định tất cả các tương tác token trong mạng. <strong>Đặt tất cả các giá trị attention mask thành False và không token nào có thể tương tác với token nào khác trong toàn bộ mạng.</strong> Chúng ta sẽ xem xét kỹ hơn các attention mask trong vài đoạn nữa.</p>
<!-- raw HTML omitted -->
<p>Cuối cùng, sau khi áp dụng attention mask, chúng ta áp dụng softmax theo từng token (tương đương với softmax theo từng hàng) và nhân kết quả với phép chiếu value $V$ để nhận đầu ra của một đầu attention, có hình dạng $[1, n, A]$. Chúng ta cung cấp một bản tóm tắt trực quan về toàn bộ quy trình trong hình sau đây.</p>
<!-- raw HTML omitted -->
<p>Chúng ta sẽ sử dụng nhiều hình ảnh attention trong bài đăng này, vì vậy để đơn giản hóa mọi thứ, chúng ta sẽ cô đọng hình trên lại một chút.</p>
<p><strong>Tại sao điều này quan trọng:</strong> Trong continuous batching, $Q$, $K$, và $V$ có thể có số lượng token khác nhau vì, như chúng ta sẽ thấy, chúng ta sẽ xử lý các giai đoạn khác nhau (prefill và decode) cùng một lúc. Để làm cho nó tổng quát hơn, hãy nói rằng $Q$ có hình dạng $[1, n_Q, A]$, $K$ có hình dạng $[1, n_K, A]$, và $V$ có hình dạng $[1, n_V, A]$.</p>
<p>Các điểm attention $QK^T$ sau đó có hình dạng $[1, n_Q, n_K]$, và attention mask có cùng hình dạng vì nó được áp dụng theo điểm tới các điểm. Thay vì biểu diễn điểm attention, chúng ta sẽ biểu diễn attention mask vào vị trí của nó. Cuối cùng, vì $Q$, $K$ và $V$ là các phép chiếu trực tiếp của $x$, không cần biểu diễn $x$. Điều này mang lại hình ảnh đơn giản hóa, nơi chúng ta chỉ biểu diễn $Q$, $K$ và attention mask:</p>
<!-- raw HTML omitted -->
<p>Biểu diễn này cũng nhấn mạnh cách chúng ta có thể <!-- raw HTML omitted -->đọc một attention mask.<!-- raw HTML omitted --></p>
<p>Chúng ta đọc mask theo từng hàng, tương đương với việc đọc theo từng token: mỗi hàng tương ứng với phép tính attention của một token. Một <!-- raw HTML omitted -->ô màu xanh lá cây<!-- raw HTML omitted --> tại vị trí (hàng i, cột j) có nghĩa là <!-- raw HTML omitted -->True<!-- raw HTML omitted -->: token j có thể ảnh hưởng đến token i. Một <!-- raw HTML omitted -->ô màu trắng<!-- raw HTML omitted --> có nghĩa là <!-- raw HTML omitted -->False<!-- raw HTML omitted -->: không cho phép tương tác.</p>
<p>Ví dụ, hãy xem hàng thứ ba cho token &ldquo;<!-- raw HTML omitted -->am<!-- raw HTML omitted -->&rdquo;. Cột &ldquo;<!-- raw HTML omitted -->I<!-- raw HTML omitted -->&rdquo; có màu xanh lá cây, vì vậy &ldquo;<!-- raw HTML omitted -->I<!-- raw HTML omitted -->&rdquo; ảnh hưởng đến việc tính toán &ldquo;<!-- raw HTML omitted -->am<!-- raw HTML omitted -->&rdquo;. Cột &ldquo;<!-- raw HTML omitted -->pro<!-- raw HTML omitted -->&rdquo; có màu trắng, vì vậy &ldquo;<!-- raw HTML omitted -->pro<!-- raw HTML omitted -->&rdquo; không ảnh hưởng đến &ldquo;<!-- raw HTML omitted -->am<!-- raw HTML omitted -->&rdquo;. Đây là cách causal masking hoạt động: các token trong tương lai không thể ảnh hưởng đến các token trong quá khứ.</p>
<p>Lớp cuối cùng của mô hình xuất ra dự đoán token cho mỗi token đầu vào. Trong bối cảnh của chúng ta, việc tạo ra phần tiếp theo của một prompt duy nhất, chúng ta chỉ quan tâm đến dự đoán token tiếp theo từ token cuối cùng. Token cuối cùng là &ldquo;<!-- raw HTML omitted -->ject<!-- raw HTML omitted -->&rdquo; trong hình trên, và dự đoán tương ứng là &ldquo;<!-- raw HTML omitted -->will<!-- raw HTML omitted -->&rdquo;.</p>
<p>Quá trình chúng ta vừa mô tả, nơi chúng ta lấy toàn bộ chuỗi đầu vào, truyền nó qua nhiều lớp attention và tính toán điểm cho token tiếp theo, được gọi là <!-- raw HTML omitted -->prefill<!-- raw HTML omitted -->. Đây là vì, như chúng ta sẽ thấy trong giây lát, phần lớn tính toán chúng ta đã thực hiện có thể được lưu trữ và tái sử dụng – do đó, chúng ta đang <!-- raw HTML omitted -->prefilling<!-- raw HTML omitted --> cache. Nhờ việc sử dụng cache này, việc tạo chuỗi có thể tiến hành với ít tính toán hơn trong giai đoạn được gọi là <!-- raw HTML omitted -->decoding<!-- raw HTML omitted -->. Trong giai đoạn decoding, việc tạo ra một token mới sẽ nhanh hơn nhiều so với phép tính toàn bộ chuỗi ban đầu. Hãy xem tại sao.</p>
<p>Để tiếp tục tạo, chúng ta bắt đầu một lượt truyền xuôi mới, mà theo cách thông thường sẽ trông như sau:</p>
<!-- raw HTML omitted -->
<p>Để tính toán điểm attention của token mới, chúng ta vẫn cần các phép chiếu key và value của các token trước đó. Vì vậy, chúng ta cần lặp lại phép nhân ma trận của các token cũ (màu xám trong hình trên) với $W_k$ và $W_v$ để lấy lại một kết quả đã được tính toán trước đó. Nói cách khác, chúng ta đang lãng phí tài nguyên tính toán. Hãy xem cách chúng ta có thể tránh điều đó.</p>
<h2 id="kv-cache">KV-cache</h2>
<p>Ngay lập tức, chúng ta nhận thấy rằng token cuối cùng không ảnh hưởng đến phép tính attention của các token khác:</p>
<!-- raw HTML omitted -->
<p>Điều này tuân theo ý tưởng của causal mask: vì &ldquo;<!-- raw HTML omitted -->will<!-- raw HTML omitted -->&rdquo; đến sau tất cả các token trước đó, nó không làm thay đổi phép tính attention của chúng.
Đối với việc tạo văn bản, causal attention là phổ biến nhất, vì vậy chúng ta sẽ tập trung vào trường hợp đó từ bây giờ. Hãy nhớ rằng các sơ đồ attention không gây ra (non-causal) cũng có thể được sử dụng, đặc biệt là khi xử lý hình ảnh.
Xem xét rằng chúng ta chỉ cần dự đoán token tiếp theo cho token &ldquo;<!-- raw HTML omitted -->will<!-- raw HTML omitted -->&rdquo;, chúng ta có thể đơn giản hóa cơ chế attention bằng cách chỉ tính toán đầu ra cho token này.</p>
<p>Hơn nữa, chúng ta đã tính toán các trạng thái $K$ và $V$ cho các token &ldquo;&lt;bos&gt;&rdquo;, … , &ldquo;ject&rdquo; trong lượt truyền xuôi trước đó: nếu chúng đã được lưu trữ, chúng ta không cần phải tính toán lại chúng. Đây là <!-- raw HTML omitted -->KV cache<!-- raw HTML omitted -->: danh sách các trạng thái key và value được tạo ra trong quá trình tạo. Về cơ bản, nó cho phép chúng ta giảm chi phí tính toán để tạo token $n+1$ từ $O(n^2)$ xuống $O(n)$ bằng cách tránh tính toán lại các phép chiếu key và value, trong khi phải trả chi phí bộ nhớ $O(n)$.</p>
<!-- raw HTML omitted -->
<p>Trong hình trên, chỉ các token màu trắng được tính toán: thay vì tính toán key và value cho 8 token, chúng ta tính cho 1 token. Bạn có thể thấy rằng thông qua KV caching, rất nhiều tài nguyên tính toán đã được tiết kiệm.
Bạn có thể xem <!-- raw HTML omitted -->bài đăng này<!-- raw HTML omitted --> để biết thêm hình ảnh về KV caching, hoặc <!-- raw HTML omitted -->bài này<!-- raw HTML omitted --> để biết ví dụ triển khai thực tế.</p>
<p>Hãy cụ thể hơn một chút về kích thước cache, vì đây là cơ hội tốt để kiểm tra các hình dạng có trong mô hình của chúng ta. Đối với một mô hình có $\mathcal{L}$ lớp attention và $H$ đầu attention với chiều đầu $A$, kích thước cache tổng cộng cần để lưu trữ một token sẽ là $2*\mathcal L * AH$ với hệ số $2$ để tính cả $K$ và $V$.
Ví dụ, Llama-2-7B với $\mathcal{L}=32$ lớp, $H=32$ đầu, và $A=128$ yêu cầu $2 \times 32 \times 128 = 8,192$ giá trị trên mỗi token trên mỗi lớp. Với độ chính xác <!-- raw HTML omitted -->float16<!-- raw HTML omitted -->, điều này tốn $2AH \times 2$ byte $= 16$ KB bộ nhớ.</p>
<p>KV caching rất hữu ích khi chúng ta muốn tạo token tiếp theo, một giai đoạn chúng ta gọi là <!-- raw HTML omitted -->decoding<!-- raw HTML omitted -->. Nhưng nó cũng có thể hữu ích trong giai đoạn <!-- raw HTML omitted -->prefill<!-- raw HTML omitted -->, khi chúng ta xử lý prompt ban đầu và có nhiều token đầu vào. Đặc biệt là khi có các prompt ban đầu lớn không vừa với bộ nhớ GPU cùng một lúc.</p>
<h2 id="chunked-prefill">Chunked Prefill</h2>
<p>Cho đến nay, chúng ta đã xem xét một ví dụ về prefill nơi chúng ta có $n=7$ token, nhưng trong thực tế các prompt ban đầu có thể dài hơn nhiều. Ví dụ, khi sử dụng Cursor, bạn có thể thêm kho lưu trữ của mình vào prompt, nơi nó hoạt động như một ngữ cảnh: điều này làm tăng đáng kể kích thước prompt. Trong những trường hợp như vậy, bộ nhớ cần thiết để lưu trữ các activation cho $n$ token có thể lớn hơn bộ nhớ có sẵn trên GPU. Do đó, chúng ta không thể thực hiện prefill trong một lần truyền xuôi duy nhất: chúng ta phải chia prefill thành các chunk. Điều này được gọi là <!-- raw HTML omitted -->chunked prefill<!-- raw HTML omitted -->, và nó sẽ là một trong những thành phần cần thiết để cho phép suy luận hiệu quả.</p>
<p>Hãy giả sử rằng bộ nhớ có sẵn bị giới hạn rất nhiều, và chúng ta chỉ có thể truyền $m=4$ token mỗi lượt truyền xuôi. Nếu chúng ta có một prompt ban đầu với $n=7$ token, chúng ta cần chia nó thành $\lceil n /m \rceil = 2$ chunk (làm tròn lên 7/4 = 1.75 thành 2). Chúng ta minh họa ví dụ dưới đây bằng cách sử dụng cùng các ký hiệu $n$ và $m$:</p>
<!-- raw HTML omitted -->
<p>Chúng ta có thể làm điều đó nhờ KV cache. Chúng ta lưu trữ các trạng thái KV trong lần chia prefill đầu tiên, và trong lần chia prefill thứ hai, chúng ta ghép các trạng thái KV đã lưu trữ vào đầu các trạng thái KV mới. Chúng ta cũng điều chỉnh attention mask tương ứng. Về mặt hình ảnh, nó trông giống như chúng ta chia prefill không phân chunk thành hai phần.</p>
<p>Ý tưởng chính: các trạng thái KV được lưu trữ cho phép chúng ta xử lý prompt một cách tăng dần mà không làm mất thông tin.</p>
<p>Mặc dù chúng ta đã cho thấy một ví dụ ở đây, nơi chúng ta chia prefill thành 2 chunk, chunked prefill có thể được sử dụng để chia prefill theo bất kỳ cách nào chúng ta muốn, thích ứng linh hoạt với các ràng buộc bộ nhớ.</p>
<p>Chúng ta cuối cùng đã trang bị đủ tất cả các công cụ cần thiết để hiểu về Continuous Batching.</p>
<h2 id="continuous-batching">Continuous batching</h2>
<p>Trong các ví dụ trước của chúng ta, chúng ta chỉ xem xét trường hợp kích thước batch là một, tức là chúng ta chỉ tạo token cho một prompt tại một thời điểm. Trong bối cảnh đánh giá hoặc phục vụ mô hình, chúng ta muốn tạo token cho một số lượng lớn các prompt. Để tăng <!-- raw HTML omitted -->thông lượng<!-- raw HTML omitted -->, là số lượng token được tạo ra mỗi giây, hành động tốt nhất là tạo token song song cho một batch gồm nhiều prompt.</p>
<p>Để batch các prompt lại với nhau, cách thông thường là thêm một trục vào cả hai tensor đầu vào: chuỗi token và attention mask. Tuy nhiên, điều này đi kèm với một ràng buộc về hình dạng của đầu vào: chúng ta cần tất cả các prompt có cùng độ dài, vì các tensor phải có hình chữ nhật. Để đạt được điều này, chúng ta thường thêm padding ở bên trái để dự đoán token mới luôn đến từ token ở ngoài cùng bên phải. Chúng ta cũng sửa đổi attention mask của mỗi prompt tương ứng, như được hiển thị dưới đây:</p>
<!-- raw HTML omitted -->
<p>nơi các token padding <code>&amp;lt;pad&amp;gt;</code> có màu cam. Sau đó, chúng ta có thể thực hiện lượt truyền xuôi như trước đây, với thêm kích thước batch size. Điều này được gọi là <!-- raw HTML omitted -->batched generation<!-- raw HTML omitted -->: hiệu quả cho các prompt có cùng độ dài, nhưng lãng phí khi độ dài khác nhau.
Nó được minh họa dưới đây, thông qua 4 bước tạo: một bước prefilling (ở trên cùng) và 3 bước decoding (dưới mỗi dòng &ldquo;Forward pass&rdquo;).</p>
<!-- raw HTML omitted -->
<p>trong đó <code>&amp;lt;eos&amp;gt;</code> có nghĩa là &ldquo;End Of Sequence&rdquo; (Kết thúc chuỗi), đây là một token đặc biệt để chỉ ra rằng mô hình đã đạt đến cuối quá trình tạo cho chuỗi tương ứng.</p>
<p>Nhược điểm của batched generation là nếu một prompt hoàn thành quá trình tạo trước các prompt khác bằng cách tạo ra token <code>&amp;lt;eos&amp;gt;</code>, tất cả các token được tạo ra sau đó đều vô dụng. Và điều này tiếp tục cho đến khi yêu cầu dài nhất của batch hoàn thành. Tất nhiên, chúng ta có thể loại bỏ các prompt đã đạt đến token <code>&amp;lt;eos&amp;gt;</code> khỏi batch và tiết kiệm một số tài nguyên và bộ nhớ, nhưng mục tiêu ở đây không phải là tiết kiệm tài nguyên: mà là thông lượng.</p>
<p>Thay vì chỉ loại bỏ prompt đã hoàn thành khỏi batch, chúng ta có thể thay thế nó bằng một prompt đang chờ tạo. Chúng ta sẽ gọi đây là <!-- raw HTML omitted -->dynamic scheduling<!-- raw HTML omitted -->, hoặc dynamic batching. Dynamic scheduling rất tuyệt để duy trì thông lượng đồng thời đảm bảo bất kỳ token nào được tạo ra bởi một lượt truyền xuôi đều có liên quan. Nhưng do cách chúng ta đã batch các prompt lại với nhau, nó có một nhược điểm lớn: chúng ta cần rất nhiều padding khi hoán đổi prompt. Đó là bởi vì prompt được chèn mới cần phải trải qua quá trình prefill trong khi các prompt khác đang giải mã từng token một. Vì vậy, gần như có nhiều padding như có token trong prompt được chèn mới.</p>
<!-- raw HTML omitted -->
<p>Vấn đề càng trở nên tồi tệ hơn khi kích thước batch tăng lên và các prompt ban đầu dài. Chi phí padding tăng theo cấp số nhân với cả kích thước batch và độ dài prompt. Nếu chúng ta có một batch gồm $B$ prompt đang ở giai đoạn decoding và một prompt hoàn thành, việc đưa một prompt có $n$ token ban đầu vào batch một cách động đòi hỏi $(n-1)(B-1)$ token padding. Ví dụ, với $B=8$ và $n=100$, chúng ta sẽ cần $99 \times 7 = 693$ token padding!</p>
<p>Hơn nữa, các tối ưu hóa thực tế như CUDA graphs hoặc <!-- raw HTML omitted -->torch.compile<!-- raw HTML omitted --> yêu cầu các hình dạng tensor tĩnh. Điều này buộc chúng ta phải đệm tất cả các prompt đến một độ dài tối đa cố định, làm tăng đáng kể lãng phí padding.</p>
<p>Tại thời điểm này, vấn đề chính của chúng ta là padding, là hệ quả của trục mà chúng ta đã thêm để batch các câu lại với nhau. Do đó, cách lý tưởng là loại bỏ hoàn toàn trục này, một sự suy nghĩ lại triệt để về batching. Nếu chúng ta làm như vậy, cách duy nhất để batch các prompt lại với nhau là nối chúng lại:</p>
<!-- raw HTML omitted -->
<p>Nhưng chúng ta không muốn các token từ prompt 0 tương tác với các token của prompt 1! May mắn thay, chúng ta có một cách để kiểm soát cách các token tương tác với nhau: attention mask. Cách chúng ta làm điều đó được hiển thị dưới đây:</p>
<!-- raw HTML omitted -->
<p>Mặc dù chúng ta sử dụng các sắc thái xanh lá cây khác nhau để minh họa các phần khác nhau của attention mask, đây vẫn là một mask boolean với chỉ các màu xanh lá cây cho <!-- raw HTML omitted -->True<!-- raw HTML omitted --> và màu trắng cho <!-- raw HTML omitted -->False<!-- raw HTML omitted -->.
Cách batch các prompt này được gọi là <!-- raw HTML omitted -->ragged batching<!-- raw HTML omitted --> (vì độ dài chuỗi &ldquo;ragged&rdquo; hay không đều), và nó mang lại lợi ích về tăng thông lượng mà không cần thêm token padding.</p>
<p>Trong hình trên, chúng ta sử dụng ragged batching để kết hợp hai prompt đầy đủ với nhau, nhưng chúng ta có thể batch bao nhiêu tùy theo bộ nhớ cho phép. Giới hạn duy nhất là $m$, số lượng token mà chúng ta có thể đưa vào một batch, với $m$ phụ thuộc vào bộ nhớ có sẵn trên GPU.</p>
<p>Ragged batching là một trong những thành phần chính của continuous batching. Để tối đa hóa thông lượng, chúng ta có thể kết hợp các chuỗi prefill và decoding theo một thuật toán như sau:</p>
<ul>
<li>Chúng ta cố gắng luôn đạt được ngân sách bộ nhớ của chúng ta là $m$ token trên mỗi batch</li>
<li>Chúng ta trước tiên thêm tất cả các prompt ở giai đoạn decoding vào batch, mỗi prompt chiếm 1 token</li>
<li>Chúng ta lấp đầy không gian còn lại với các prompt ở giai đoạn prefill, dựa vào tính linh hoạt của chunked prefill để chia các đầu vào khi cần thiết</li>
</ul>
<p>Dynamic scheduling là mảnh ghép cuối cùng góp phần vào kỹ thuật <!-- raw HTML omitted -->continuous batching<!-- raw HTML omitted -->: chúng ta loại bỏ các prompt đã hoàn thành khỏi batch ngay khi chúng hoàn thành, và thay thế chúng bằng các prompt được phân chunk mới tương ứng với các yêu cầu đến.</p>
<p>Sự kết hợp giữa ragged batching và dynamic scheduling này được gọi là <!-- raw HTML omitted -->continuous batching<!-- raw HTML omitted -->, và đây là kỹ thuật cung cấp năng lượng cho các hệ thống phục vụ LLM hiện đại.</p>
<!-- raw HTML omitted -->
<h2 id="kết-luận">Kết luận</h2>
<p>Continuous batching kết hợp ba kỹ thuật chính để tối đa hóa thông lượng trong việc phục vụ LLM:</p>
<ol>
<li><!-- raw HTML omitted -->KV caching<!-- raw HTML omitted --> để tránh tính toán lại biểu diễn token trước đó</li>
<li><!-- raw HTML omitted -->Chunked prefill<!-- raw HTML omitted --> để xử lý các prompt có độ dài thay đổi trong giới hạn bộ nhớ</li>
<li><!-- raw HTML omitted -->Ragged batching với dynamic scheduling<!-- raw HTML omitted --> để loại bỏ lãng phí padding và giữ cho GPU được sử dụng tối đa</li>
</ol>
<p>Bằng cách loại bỏ chiều batch và sử dụng attention masks để kiểm soát tương tác token, continuous batching cho phép kết hợp các giai đoạn prefill và decode trong cùng một batch, cải thiện đáng kể hiệu quả khi phục vụ nhiều yêu cầu. Đây là lý do tại sao các dịch vụ như ChatGPT có thể xử lý hàng nghìn người dùng đồng thời một cách hiệu quả.</p>
<p>Trong bài viết tiếp theo trong loạt bài này, chúng ta sẽ khám phá quản lý KV cache hiệu quả thông qua <!-- raw HTML omitted -->paged attention<!-- raw HTML omitted -->. Nếu bạn muốn xem một phân tích sâu về các chủ đề continuous batching khác, vui lòng cho chúng tôi biết trong phần bình luận!</p>
<p><em>Ghi nhận: cảm ơn Arthur Zucker đã sản xuất ý tưởng ban đầu cho các hình ảnh được sử dụng trong bài viết này. Và cảm ơn Arthur Zucker, Luc Georges, Lysandre Debut, Merve Noyan và Pedro Cuenca đã cung cấp các bài đánh giá hữu ích.</em></p>
<h3 id="link-bài-viết-gốc"><a href="https://huggingface.co/blog/continuous_batching">Link bài viết gốc</a></h3>


    <ul id="taxonomy" class="not-prose flex items-center space-x-4 flex-nowrap whitespace-nowrap overflow-x-auto">

      <li class="font-semibold my-4">Tags:</li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/ai/">Ai</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/25-th%C3%A1ng-11-2025/">25 Tháng 11, 2025</a></li>
        <li ><a class="py-2 px-6 border rounded-full hover:bg-zinc-100 active:bg-zinc-300" href="/tags/huggingface.co/">Huggingface.co</a></li>
    </ul>
</div>

    <footer id="content-footer" class="not-prose">

      

      <div id="author-box" class="my-8 md:my-14 border p-8 bg-zinc-100 rounded-2xl">

        <img class="w-20 h-20 rounded-full" src="" alt="">

        <h2 class="text-xl font-bold my-4">Writter by : </h2>

        <p class="mb-4"></p>

        <ul class="flex flex-wrap space-x-4">
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                <path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
              </svg>
              <span class="ml-2">Facebook</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://facebook.com/luat.skyai/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
              </svg>
              <span class="ml-2">Twitter</span>
            </a>
          </li>
          <li>
            <a class="flex items-center decoration-auto hover:underline" href="https://luat.skyai.vn/" target="_blank" rel="noopener">
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"/>

              </svg>
              <span class="ml-2">Instagram</span>
            </a>
          </li>

        </ul>
        
      </div>

      <div id="related-post" class="">

        <h2 class="text-xl md:text-2xl font-bold mb-6 md:mb-8">Recommended for You</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-26/28000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/65c992424936ab38ecf706b0/aq7vuHFPO1S93fwJk0Cuq.jpeg" alt="DeLERP- Nội suy Tuyến tính Phân rã để Hợp nhất Mô hình" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-11-26T00:00:00&#43;00:00">Nov 26, 2025</time>

		<h3 class="my-4 text-2xl font-bold">DeLERP- Nội suy Tuyến tính Phân rã để Hợp nhất Mô hình</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">DeLERP- Nội suy Tuyến tính Phân rã để Hợp nhất Mô hình</p>

	</div>
</article><article class="relative group bg-zinc-100 hover:bg-blue-100 rounded-3xl">
	
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-11-26/d79799/"></a>

	<figure class="w-full aspect-video overflow-hidden rounded-3xl">

			<img class="object-cover group-hover:scale-105 transition duration-500 cursor-pointer" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1677857909367-624ef9ba9d608e459387b34e.jpeg" alt="Diffusers chào đón FLUX-2" style="width: 100%; height: 100%; object-fit: cover;">

	  </figure>

	<div class="p-6">

		<time datetime="2025-11-26T00:00:00&#43;00:00">Nov 26, 2025</time>

		<h3 class="my-4 text-2xl font-bold">Diffusers chào đón FLUX-2</h3>

		<p class="text-normal leading-normal text-zinc-500 line-clamp-2">Diffusers chào đón FLUX-2</p>

	</div>
</article>
          
        </div>
      </div>

    </footer>

  </article>

  
  <aside class="md:col-span-1"><div class="lg:sticky lg:top-8"><div class="rounded-2xl p-4 bg-zinc-100 mb-10">

		<img class="aspect-video rounded" src="/images/email-3249062_1280_by-Muhammad-Ribkhan-Pixabay.jpg" alt="Banner Email Marketing">

		<p class="text-right text-xs mt-2 leading-none text-zinc-500">Adversitiment</p>

</div><div class="space-y-6">

		<h2 class="font-bold text-xl mb-8">Recent Post</h2>

		<article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-10/619587/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://image-link" alt="Accenture và Anthropic ra mắt quan hệ đối tác nhiều năm để đưa các doanh nghiệp từ các dự án thử nghiệm AI sang sản xuất" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Accenture và Anthropic ra mắt quan hệ đối tác nhiều năm để đưa các doanh nghiệp từ các dự án thử nghiệm AI sang sản xuất</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-10/7a6465/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://images.ctfassets.net/jdtwqhzvc2n1/3ibU0O0ON6nC4NSVY5KYkP/e13a276f2bece890100148b10cbcf165/nuneybits_Vector_art_of_self-building_computer_isometric_ca3b7721-5759-4033-9885-e096e5d68ddc.webp?w=1000&amp;q=100" alt="AI của Quilter vừa thiết kế máy tính Linux gồm 843 bộ phận và nó đã khởi động ngay lần thử đầu tiên. Phần cứng sẽ không bao giờ như cũ." style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">AI của Quilter vừa thiết kế máy tính Linux gồm 843 bộ phận và nó đã khởi động ngay lần thử đầu tiên. Phần cứng sẽ không bao giờ như cũ.</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-10/2d3903/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://image-link" alt="Apriel-1.6-15b-Thinker- Hiệu suất đa phương thức tiên phong hiệu quả về chi phí" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Apriel-1.6-15b-Thinker- Hiệu suất đa phương thức tiên phong hiệu quả về chi phí</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-10/bb259b/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://images.ctfassets.net/jdtwqhzvc2n1/5OFBMkrEKqvqYY0hbPYaoF/e31f8e8b39af32f6197a402b42f96136/hud-code-dev-smk.jpg?w=1000&amp;q=100" alt="Cảm biến thời gian chạy của Hud cắt giảm thời gian phân loại từ 3 giờ xuống còn 10 phút" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">Cảm biến thời gian chạy của Hud cắt giảm thời gian phân loại từ 3 giờ xuống còn 10 phút</h3>
	</div>
</article><article class="relative group flex flex-row">
	<a class="insert-link" href="https://aitoday.skyai.vn/posts/2025-12-10/8f9e0c/"></a>
	<figure class="basis-1/3 aspect-square overflow-hidden rounded-2xl bg-zinc-100">

		  <img class="object-cover h-full w-full group-hover:scale-105 transition duration-500 cursor-pointer" src="http://image-link" alt="DeepMath- Một tác nhân suy luận toán học nhẹ với smolagents" style="width: 100%; height: 100%; object-fit: cover;" style="width: 100%; height: 100%; object-fit: cover;">

	</figure>
	<div class="basis-2/3 self-center ml-4">
		<h3 class="font-bold group-hover:underline decoration-auto">DeepMath- Một tác nhân suy luận toán học nhẹ với smolagents</h3>
	</div>
</article>
		
	</div>

</div>
</aside>

</div>
  
</main>
  <footer class="bg-zinc-100 py-10 md:py-14"><div class="max-w-7xl mx-auto px-4 md:px-6 lg:px-8">

  <div class="flex flex-wrap space-y-6 mb-4">

    <div class="w-full md:w-3/5 flex flex-col space-y-4 md:pr-8 lg:pr-10">

      <a class="flex items-center group" href="https://aitoday.skyai.vn/">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="mr-2 group-hover:animate-spin" viewBox="0 0 16 16">
          <path d="M8 11a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/>
          <path d="M13.997 5.17a5 5 0 0 0-8.101-4.09A5 5 0 0 0 1.28 9.342a5 5 0 0 0 8.336 5.109 3.5 3.5 0 0 0 5.201-4.065 3.001 3.001 0 0 0-.822-5.216zm-1-.034a1 1 0 0 0 .668.977 2.001 2.001 0 0 1 .547 3.478 1 1 0 0 0-.341 1.113 2.5 2.5 0 0 1-3.715 2.905 1 1 0 0 0-1.262.152 4 4 0 0 1-6.67-4.087 1 1 0 0 0-.2-1 4 4 0 0 1 3.693-6.61 1 1 0 0 0 .8-.2 4 4 0 0 1 6.48 3.273z"/>
        </svg>
        
        <span class="text-2xl font-semibold uppercase">AI Today - SkyAI</span>
      </a>

      <p class="font-semibold">
        Theo dõi các tiến bộ mới nhất về Trí tuệ nhân tạo.<br>Trực tiếp từ các nhà phát hành AI trên thế giới.
      </p>

      <p>Đem trí tuệ nhân tạo đến mọi người dân, doanh nghiệp Việt, góp phần giúp Việt Nam phát triển mạnh mẽ trong kỷ nguyên số. Nội dung được cập nhật tự động bằng máy.</p>

    </div>

    <div class="self-center flex flex-col w-full md:w-2/5">

<ul id="social-media" class="flex items-center space-x-4">
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.facebook.com/luat.skyai/" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
				<path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.twitter.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.github.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
			</svg>
		</a>
	</li>
	<li>
		<a class="w-12 h-12 rounded-full bg-white hover:bg-zinc-200 flex items-center justify-center p-2" href="https://www.instagram.com/#" target="_blank" rel="noopener noreferrer">
			<svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 16 16">
				  <path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.917 3.917 0 0 0-1.417.923A3.927 3.927 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.916 3.916 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.926 3.926 0 0 0-.923-1.417A3.911 3.911 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0h.003zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599.28.28.453.546.598.92.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.47 2.47 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.478 2.478 0 0 1-.92-.598 2.48 2.48 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233 0-2.136.008-2.388.046-3.231.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92.28-.28.546-.453.92-.598.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045v.002zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92zm-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217zm0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334z"></path>
			</svg>
		</a>
	</li>
</ul>

    </div>
    
  </div>

  <div class="my-8">
    <ul class="flex items-center space-x-4">
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/">Home</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="">About</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Tags</a></li>
      
        <li><a class="decoration-auto hover:underline font-semibold" href="/tags/">Taxonomy</a></li>
      
    </ul>
  </div>

  <div class="border-t pt-4">

    <p class="text-sm">Copyright © 2025. All rights reserved. <a href="https://home.skyai.vn/" target="_blank" rel="noopener">SkyAI.vn</a></p>

  </div>
  
</div>
</footer>
      <script defer src="/js/insertoggle.474f9b0e08021c6519cff4e46df14ccf148285b2d3a23d6321d6e10f25c291fb.js" integrity="sha256-R0&#43;bDggCHGUZz/TkbfFMzxSChbLToj1jIdbhDyXCkfs=" crossorigin="anonymous"></script>
</body>
</html>