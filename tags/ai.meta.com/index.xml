<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ai.meta.com on AI Today - SkyAI</title>
    <link>https://aitoday.skyai.vn/tags/ai.meta.com/</link>
    <description>Recent content in Ai.meta.com on AI Today - SkyAI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://aitoday.skyai.vn/tags/ai.meta.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mô hình hóa động lực hội thoại tự nhiên với Tương tác Liền mạch</title>
      <link>https://aitoday.skyai.vn/posts/2025-06-28/f6e3c8/</link>
      <pubDate>Sat, 28 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-06-28/f6e3c8/</guid>
      <description>&lt;h1 id=&#34;mô-hình-hóa-động-lực-hội-thoại-tự-nhiên-với-tương-tác-liền-mạch&#34;&gt;Mô hình hóa động lực hội thoại tự nhiên với Tương tác liền mạch&lt;/h1&gt;&#xA;&lt;h3 id=&#34;tóm-tắt&#34;&gt;Tóm tắt:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Khi chúng ta nỗ lực xây dựng tương lai của kết nối giữa con người và công nghệ hỗ trợ, chúng ta sẽ cần các mô hình có thể tạo ra biểu cảm khuôn mặt và cử chỉ cơ thể dựa trên các đầu vào nghe nhìn từ hai người. Meta Fundamental AI Research (FAIR) đang giới thiệu một loạt các mô hình chuyển động hành vi nghe nhìn để đáp ứng nhu cầu đó.&lt;/li&gt;&#xA;&lt;li&gt;Các mô hình của chúng tôi cho phép tạo ra các avatar hoàn toàn thể hiện trong video 2D và dưới dạng Codec Avatars 3D và có thể cho phép tạo ra các tác nhân ảo tự nhiên và tương tác hơn, những tác nhân này có thể tham gia vào các cuộc trò chuyện với các cử chỉ và biểu cảm giống con người, chuyển đổi công nghệ hiện diện từ xa trong cài đặt VR và AR.&lt;/li&gt;&#xA;&lt;li&gt;Chúng tôi cũng đang phát hành Bộ dữ liệu Tương tác Liền mạch, một bộ dữ liệu quy mô lớn với hơn 4.000 giờ tương tác giữa hai người và hơn 4.000 người tham gia duy nhất, mà chúng tôi đã sử dụng để đào tạo các mô hình của mình. Bộ dữ liệu của chúng tôi ghi lại một loạt các tương tác trực tiếp giữa hai cá nhân, cho phép các mô hình hành vi nghe nhìn của chúng tôi hiểu và tạo ra các hành vi xã hội giống con người.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;Giao tiếp giữa mọi người giống như một điệu nhảy, mỗi người liên tục điều chỉnh những gì họ nói, cách họ nói và cách họ ra hiệu. Mô hình hóa động lực hội thoại hai bên, hay còn gọi là nhị nguyên, đòi hỏi phải hiểu mối quan hệ đa phương thức giữa các tín hiệu xã hội bằng lời nói, giọng nói và hình ảnh — và các hành vi giữa các cá nhân giữa mọi người, chẳng hạn như lắng nghe, đồng bộ hóa trực quan và thay phiên nhau. Khi các tác nhân ảo trở thành những trợ lý quan trọng trong cuộc sống hàng ngày của chúng ta, điều quan trọng là các hệ thống này có thể hiển thị các mô hình hội thoại tự nhiên này. Hôm nay, nhóm Nghiên cứu AI Cơ bản Meta (FAIR) cùng với phòng thí nghiệm Codec Avatars của Meta và phòng thí nghiệm Core AI đang giới thiệu một loạt Mô hình Chuyển động Nhị nguyên khám phá các lĩnh vực mới của AI xã hội. Các mô hình này kết xuất lời nói do con người hoặc mô hình ngôn ngữ tạo ra giữa hai cá nhân thành các cử chỉ toàn thân đa dạng, biểu cảm và các hành vi lắng nghe tích cực, cho phép tạo ra các avatar hoàn toàn thể hiện trong video 2D và dưới dạng Codec Avatars 3D. Các mô hình xử lý các đầu vào âm thanh và hình ảnh để ghi lại các động lực hội thoại sắc thái với tiềm năng cuối cùng là tạo ra các tác nhân ảo tương tác, tự nhiên hơn, có thể tham gia vào các tương tác xã hội giống con người trên nhiều cài đặt nhập vai khác nhau.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Thông báo nhóm khởi nghiệp Llama khai mạc</title>
      <link>https://aitoday.skyai.vn/posts/2025-06-17/13d4bf/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-06-17/13d4bf/</guid>
      <description>&lt;h1 id=&#34;thông-báo-về-nhóm-khởi-nghiệp-đầu-tiên-của-chương-trình-llama-startup&#34;&gt;Thông báo về nhóm khởi nghiệp đầu tiên của Chương trình Llama Startup&lt;/h1&gt;&#xA;&lt;p&gt;Tại Meta, chúng tôi tin vào tiềm năng của các công ty khởi nghiệp giai đoạn đầu trong việc thúc đẩy sự đổi mới trên thị trường AI tạo sinh, và thông qua Chương trình Llama Startup, chúng tôi&amp;hellip;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bên trong Aria Gen 2- Khám phá công nghệ tiên tiến đằng sau thiết bị</title>
      <link>https://aitoday.skyai.vn/posts/2025-06-09/8ca294/</link>
      <pubDate>Mon, 09 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-06-09/8ca294/</guid>
      <description>&lt;h1 id=&#34;bên-trong-aria-gen-2-khám-phá-công-nghệ-tiên-tiến-đằng-sau-thiết-bị&#34;&gt;Bên trong Aria Gen 2: Khám phá công nghệ tiên tiến đằng sau thiết bị&lt;/h1&gt;&#xA;&lt;p&gt;Đầu năm nay, chúng tôi &lt;a href=&#34;https://www.meta.com/blog/project-aria-gen-2-next-generation-egocentric-research-glasses-reality-labs-ai-robotics/?srsltid=AfmBOor2wAWcDdtBh6tXU-WABa3nvlJU-fctFwwaBvoBCyn6vznNk0uq&#34;&gt;&lt;!-- raw HTML omitted --&gt;đã công bố&lt;!-- raw HTML omitted --&gt;&lt;/a&gt; kính nghiên cứu mới nhất của mình, Aria Gen 2, đánh dấu sự tiếp nối sứ mệnh của Dự án Aria trong việc cho phép các nhà nghiên cứu trên toàn thế giới nâng cao trình độ hiện đại trong nhận thức máy móc, AI theo ngữ cảnh và robot học thông qua quyền truy cập vào phần cứng nghiên cứu tiên tiến và các bộ dữ liệu, mô hình và công cụ nguồn mở. Hôm nay, chúng tôi rất vui mừng được chia sẻ thêm về công nghệ bên trong Aria Gen 2. Điều này bao gồm tổng quan chuyên sâu về hệ số hình thức, khả năng âm thanh, thời lượng pin, camera và cảm biến được nâng cấp, tính toán trên thiết bị, v.v.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Giới thiệu Chương trình Khởi nghiệp Llama</title>
      <link>https://aitoday.skyai.vn/posts/2025-05-21/270aee/</link>
      <pubDate>Wed, 21 May 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-05-21/270aee/</guid>
      <description>&lt;h1 id=&#34;giới-thiệu-chương-trình-khởi-nghiệp-llama&#34;&gt;Giới thiệu Chương trình Khởi nghiệp Llama&lt;/h1&gt;&#xA;&lt;p&gt;Chúng tôi rất vui mừng thông báo về Chương trình Khởi nghiệp Llama, một sáng kiến mới nhằm trao quyền cho các công ty khởi nghiệp giai đoạn đầu để đổi mới và xây dựng các ứng dụng AI tạo sinh với Llama. Các thành viên của Chương trình Khởi nghiệp Llama sẽ nhận được các nguồn lực và hỗ trợ từ các chuyên gia Llama trong suốt hành trình của họ, bao gồm trợ giúp để bắt đầu với Llama và các nguồn lực cần thiết để thành công và phát triển trong một bối cảnh cạnh tranh và phát triển nhanh chóng.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chia sẻ các công cụ bảo vệ mã nguồn mở mới và những tiến bộ trong bảo mật và quyền riêng tư của AI</title>
      <link>https://aitoday.skyai.vn/posts/2025-04-30/358000000000000000000000000000000000000000000000000000000000000000/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-04-30/358000000000000000000000000000000000000000000000000000000000000000/</guid>
      <description>&lt;h1 id=&#34;chia-sẻ-các-công-cụ-bảo-vệ-mã-nguồn-mở-mới-và-những-tiến-bộ-trong-bảo-mật-và-quyền-riêng-tư-ai&#34;&gt;Chia sẻ các công cụ bảo vệ mã nguồn mở mới và những tiến bộ trong bảo mật và quyền riêng tư AI&lt;/h1&gt;&#xA;&lt;p&gt;Hôm nay, chúng tôi phát hành các công cụ bảo vệ Llama mới cho cộng đồng AI mã nguồn mở.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tất cả những gì chúng tôi đã công bố tại LlamaCon đầu tiên</title>
      <link>https://aitoday.skyai.vn/posts/2025-04-30/6fe460/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-04-30/6fe460/</guid>
      <description>&lt;h1 id=&#34;tất-cả-những-gì-chúng-tôi-đã-công-bố-tại-llamacon-đầu-tiên&#34;&gt;Tất cả những gì chúng tôi đã công bố tại LlamaCon đầu tiên&lt;/h1&gt;&#xA;&lt;p&gt;Đây là cái nhìn về những gì chúng tôi đã công bố tại LlamaCon và cách bạn có thể bắt đầu với các bản phát hành mới nhất của chúng tôi.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cách Litmos đang sử dụng Llama để làm cho việc học tập của công ty trở nên trực quan hơn</title>
      <link>https://aitoday.skyai.vn/posts/2025-04-24/bf8fd8/</link>
      <pubDate>Thu, 24 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-04-24/bf8fd8/</guid>
      <description>&lt;h2 id=&#34;cách-litmos-sử-dụng-llama-để-làm-cho-việc-học-tập-trong-doanh-nghiệp-trực-quan-hơn&#34;&gt;Cách Litmos sử dụng Llama để làm cho việc học tập trong doanh nghiệp trực quan hơn&lt;/h2&gt;&#xA;&lt;p&gt;Litmos, một nền tảng học tập trong doanh nghiệp, đang thay đổi cách các tổ chức nâng cao kỹ năng cho lực lượng lao động của họ trên toàn thế giới, với 4.000 công ty tin tưởng vào phương pháp tiếp cận sáng tạo của nó. Hệ thống quản lý học tập (LMS) và thư viện nội dung của công ty cho phép các tổ chức cung cấp nội dung học tập cho 30 triệu người bằng 35 ngôn ngữ. Với một thư viện tài nguyên đa phương tiện rộng lớn, bao gồm video, âm thanh, PDF và các tệp Sharable Content Object Reference Model (SCORM), Litmos đơn giản hóa việc tạo, quản lý và kết nối nội dung để học tập trên nhiều định dạng khác nhau.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
