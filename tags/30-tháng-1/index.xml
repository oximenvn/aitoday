<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>30 Tháng 1 on AI Today - SkyAI</title>
    <link>https://aitoday.skyai.vn/tags/30-th%C3%A1ng-1/</link>
    <description>Recent content in 30 Tháng 1 on AI Today - SkyAI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://aitoday.skyai.vn/tags/30-th%C3%A1ng-1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>KV Caching được giải thích- Tối ưu hóa hiệu quả suy luận Transformer</title>
      <link>https://aitoday.skyai.vn/posts/2025-11-10/60eb7d/</link>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-11-10/60eb7d/</guid>
      <description>&lt;h1 id=&#34;kv-caching-explained-optimizing-transformer-inference-efficiency&#34;&gt;KV Caching Explained: Optimizing Transformer Inference Efficiency&lt;/h1&gt;&#xA;&lt;p&gt;Khi các mô hình AI tạo văn bản, chúng thường lặp đi lặp lại nhiều phép tính giống nhau, điều này có thể làm chậm quá trình. &lt;strong&gt;Key-Value caching (KV caching)&lt;/strong&gt; là một kỹ thuật giúp tăng tốc quá trình này bằng cách ghi nhớ các thông tin quan trọng từ các bước trước. Thay vì tính toán lại mọi thứ từ đầu, mô hình tái sử dụng những gì đã tính toán, giúp việc tạo văn bản nhanh hơn và hiệu quả hơn.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
