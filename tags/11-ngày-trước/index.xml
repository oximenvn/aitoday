<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>11 Ngày Trước on AI Today - SkyAI</title>
    <link>https://aitoday.skyai.vn/tags/11-ng%C3%A0y-tr%C6%B0%E1%BB%9Bc/</link>
    <description>Recent content in 11 Ngày Trước on AI Today - SkyAI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://aitoday.skyai.vn/tags/11-ng%C3%A0y-tr%C6%B0%E1%BB%9Bc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Căn chỉnh với cái gì? Suy nghĩ lại về Tổng quát hóa Tác nhân trong MiniMax M2</title>
      <link>https://aitoday.skyai.vn/posts/2025-11-10/dea53d/</link>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-11-10/dea53d/</guid>
      <description>&lt;h1 id=&#34;aligning-to-what-rethinking-agent-generalization-in-minimax-m2&#34;&gt;Aligning to What? Rethinking Agent Generalization in MiniMax M2&lt;/h1&gt;&#xA;&lt;p&gt;Bài viết này của MiniMax trên Hugging Face.&lt;/p&gt;&#xA;&lt;p&gt;Thật tuyệt vời khi thấy cộng đồng đã khám phá sâu về &lt;strong&gt;MiniMax M2&lt;/strong&gt; mới của chúng tôi, và nhiều người đã nhấn mạnh khả năng ấn tượng của nó trong các tác vụ phức điều hành phức tạp. Điều này đặc biệt thú vị đối với tôi, vì công việc của tôi tập trung vào khía cạnh căn chỉnh (alignment) của tác tử (agent) sau quá trình huấn luyện. Trong bài viết này, tôi muốn chia sẻ một số hiểu biết và bài học quan trọng mà chúng tôi đã rút ra trong quá trình đó.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Điều gì tạo nên dữ liệu suy luận tốt</title>
      <link>https://aitoday.skyai.vn/posts/2025-11-10/3d4666/</link>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-11-10/3d4666/</guid>
      <description>&lt;h1 id=&#34;điều-gì-tạo-nên-dữ-liệu-lý-luận-tốt&#34;&gt;Điều gì tạo nên dữ liệu lý luận tốt?&lt;/h1&gt;&#xA;&lt;p&gt;Artificial Analysis là một bài kiểm tra toàn diện phản ánh sự đa dạng trong khả năng lý luận của các mô hình. Mô hình mới ra mắt của chúng tôi, &lt;a href=&#34;https://huggingface.co/MiniMaxAI/MiniMax-M2&#34;&gt;MiniMax M2&lt;/a&gt;, đứng Top-1 trong các mô hình mã nguồn mở và Top-5 trong tất cả các mô hình.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tại sao MiniMax M2 lại trở thành một Mô hình Chú ý Toàn phần?</title>
      <link>https://aitoday.skyai.vn/posts/2025-11-10/d50c3b/</link>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://aitoday.skyai.vn/posts/2025-11-10/d50c3b/</guid>
      <description>&lt;h1 id=&#34;tại-sao-minimax-m2-lại-trở-thành-mô-hình-chú-ý-đầy-đủ&#34;&gt;Tại sao MiniMax M2 lại trở thành mô hình chú ý đầy đủ?&lt;/h1&gt;&#xA;&lt;p&gt;Sau khi ra mắt M2, chúng tôi đã nhận được nhiều câu hỏi từ cộng đồng về việc &amp;ldquo;Tại sao các bạn lại quay lại quá khứ và sử dụng chú ý đầy đủ với MiniMax M2?&amp;rdquo;. Chúng tôi có thể đưa ra cuộc tranh luận theo sách giáo khoa — dành một buổi chiều để giải thích tại sao bạn nên xây dựng chú ý tuyến tính hoặc thưa thớt, sau đó dành một buổi chiều khác để giải thích tại sao bạn không nên làm vậy. Nhưng cuối cùng, tất cả những lý thuyết đó cũng chỉ có vậy. Câu hỏi thực sự rất đơn giản: bạn có nên làm điều đó không?&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
